This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
.github/
  workflows/
    integration-tests.yml
    unit-tests.yml
src/
  react_agent/
    graphs/
      research.py
    prompts/
      __init__.py
      analysis.py
      market.py
      reflection.py
      research.py
      templates.py
      validation.py
    tools/
      jina.py
    utils/
      __init__.py
      llm.py
      logging.py
      validations.py
    __init__.py
    configuration.py
    state.py
tests/
  cassettes/
    103fe67e-a040-4e4e-aadb-b20a7057f904.yaml
  integration_tests/
    __init__.py
    test_graph.py
  unit_tests/
    __init__.py
    test_configuration.py
.gitignore
.repomixignore
langgraph.json
LICENSE
Makefile
pyproject.toml
README.md
repomix.config.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".github/workflows/integration-tests.yml">
# This workflow will run integration tests for the current project once per day

name: Integration Tests

on:
  schedule:
    - cron: "37 14 * * *" # Run at 7:37 AM Pacific Time (14:37 UTC) every day
  workflow_dispatch: # Allows triggering the workflow manually in GitHub UI

# If another scheduled run starts while this workflow is still running,
# cancel the earlier run in favor of the next run.
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  integration-tests:
    name: Integration Tests
    strategy:
      matrix:
        os: [ubuntu-latest]
        python-version: ["3.11", "3.12"]
    runs-on: ${{ matrix.os }}
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          uv venv
          uv pip install -r pyproject.toml
          uv pip install -U pytest-asyncio vcrpy
      - name: Run integration tests
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          TAVILY_API_KEY: ${{ secrets.TAVILY_API_KEY }}
          LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
          LANGSMITH_TRACING: true
          LANGSMITH_TEST_CACHE: tests/cassettes
        run: |
          uv run pytest tests/integration_tests
</file>

<file path=".github/workflows/unit-tests.yml">
# This workflow will run unit tests for the current project

name: CI

on:
  push:
    branches: ["main"]
  pull_request:
  workflow_dispatch: # Allows triggering the workflow manually in GitHub UI

# If another push to the same PR or branch happens while this workflow is still running,
# cancel the earlier run in favor of the next run.
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  unit-tests:
    name: Unit Tests
    strategy:
      matrix:
        os: [ubuntu-latest]
        python-version: ["3.11", "3.12"]
    runs-on: ${{ matrix.os }}
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          uv venv
          uv pip install -r pyproject.toml
      - name: Lint with ruff
        run: |
          uv pip install ruff
          uv run ruff check .
      - name: Lint with mypy
        run: |
          uv pip install mypy
          uv run mypy --strict src/
      - name: Check README spelling
        uses: codespell-project/actions-codespell@v2
        with:
          ignore_words_file: .codespellignore
          path: README.md
      - name: Check code spelling
        uses: codespell-project/actions-codespell@v2
        with:
          ignore_words_file: .codespellignore
          path: src/
      - name: Run tests with pytest
        run: |
          uv pip install pytest
          uv run pytest tests/unit_tests
</file>

<file path="src/react_agent/graphs/research.py">
"""Enhanced modular research framework using LangGraph.

This module implements a modular approach to the research process,
with specialized components for different research categories and
improved error handling and validation.
"""

from __future__ import annotations
import json
import asyncio
from typing import Any, Dict, List, Optional, Sequence, Union, cast, Tuple, Literal, Hashable
from datetime import datetime, timezone
from urllib.parse import urlparse

from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.constants import START
from langgraph.graph.state import CompiledStateGraph
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage
from langchain_core.runnables import RunnableConfig, ensure_config
from langchain_core.documents import Document
from typing_extensions import Annotated, TypedDict

from react_agent.utils.validations import is_valid_url
from react_agent.utils.llm import call_model, call_model_json
from react_agent.tools.jina import search, optimize_query
from react_agent.prompts.research import (
    QUERY_ANALYSIS_PROMPT,
    CLARIFICATION_PROMPT,
    EXTRACTION_PROMPTS,
    SYNTHESIS_PROMPT,
    VALIDATION_PROMPT,
    SEARCH_QUALITY_THRESHOLDS,
    get_extraction_prompt,
    get_default_extraction_result
)
from react_agent.utils.logging import get_logger, log_dict, info_highlight, warning_highlight, error_highlight, log_step

# Initialize logger
logger = get_logger(__name__)

# Define SearchType as a Literal type
SearchType = Literal['general', 'authoritative', 'recent', 'comprehensive', 'technical']

# --------------------------------------------------------------------
# 1. Define the modular state classes
# --------------------------------------------------------------------

class ResearchCategory(TypedDict):
    """State for a specific research category."""
    category: str  # The category being researched (market_dynamics, etc.)
    query: str  # The search query for this category
    search_results: List[Dict[str, Any]]  # Raw search results
    extracted_facts: List[Dict[str, Any]]  # Extracted facts
    sources: List[Dict[str, Any]]  # Source information
    complete: bool  # Whether this category is complete
    quality_score: float  # Quality score for this category (0.0-1.0)
    retry_count: int  # Number of retry attempts
    last_search_query: Optional[str]  # Last search query used
    status: str  # Status of this category (pending, in_progress, complete, failed)

class ResearchState(TypedDict):
    """Main research state with modular components."""
    # Basic conversation data
    messages: Annotated[Sequence[BaseMessage], add_messages]
    
    # Original query and analysis
    original_query: str
    query_analysis: Optional[Dict[str, Any]]
    
    # Clarity and context
    missing_context: List[str]
    needs_clarification: bool
    clarification_request: Optional[str]
    human_feedback: Optional[str]
    
    # Category-specific research
    categories: Dict[str, ResearchCategory]
    
    # Synthesis and validation
    synthesis: Optional[Dict[str, Any]]
    validation_result: Optional[Dict[str, Any]]
    
    # Overall status
    status: str
    error: Optional[Dict[str, Any]]
    complete: bool
    
# --------------------------------------------------------------------
# 2. Core control flow nodes
# --------------------------------------------------------------------

async def initialize_research(state: ResearchState) -> Dict[str, Any]:
    """Initialize the research process with the user's query."""
    log_step("Initializing research process", 1, 10)

    if not state["messages"]:
        warning_highlight("No messages found in state")
        return {"error": {"message": "No messages in state", "phase": "initialization"}}

    last_message = state["messages"][-1]
    query = last_message.content if isinstance(last_message, BaseMessage) else ""

    if not query:
        warning_highlight("Empty query")
        return {"error": {"message": "Empty query", "phase": "initialization"}}

    info_highlight(f"Initializing research for query: {query}")

    categories = {
        category: {
            "category": category,
            "query": "",  # Will be filled by query analysis
            "search_results": [],
            "extracted_facts": [],
            "sources": [],
            "complete": False,
            "quality_score": 0.0,
            "retry_count": 0,
            "last_search_query": None,
            "status": "pending",
        }
        for category in SEARCH_QUALITY_THRESHOLDS.keys()
    }
    return {
        "original_query": query,
        "status": "initialized",
        "categories": categories,
        "missing_context": [],
        "needs_clarification": False,
        "complete": False
    }

async def analyze_query(state: ResearchState, config: Optional[RunnableConfig] = None) -> Dict[str, Any]:
    """Analyze the query to determine research categories and search terms."""
    log_step("Analyzing research query", 2, 10)

    query = state["original_query"].strip()
    if not query:
        warning_highlight("No query to analyze")
        return {"error": {"message": "No query to analyze", "phase": "query_analysis"}}

    if human_feedback := state.get("human_feedback", ""):
        info_highlight(f"Including user feedback in analysis: {human_feedback}")
        query = f"{query}\n\nAdditional context: {human_feedback}"

    # Prepare the analysis prompt
    analysis_prompt = QUERY_ANALYSIS_PROMPT.format(query=query)

    try:
        analysis_result = await call_model_json(
            messages=[{"role": "human", "content": analysis_prompt}],
            config=ensure_config(config)
        )

        # Ensure the response has the required structure
        if not isinstance(analysis_result, dict):
            error_highlight("Invalid response format from query analysis")
            return {"error": {"message": "Invalid response format", "phase": "query_analysis"}}

        # Initialize default values
        analysis_result = {
            "unspsc_categories": analysis_result.get("unspsc_categories", []),
            "search_components": analysis_result.get("search_components", {
                "primary_topic": "",
                "industry": "",
                "product_type": "",
                "geographical_focus": ""
            }),
            "search_terms": analysis_result.get("search_terms", {
                "market_dynamics": [],
                "provider_landscape": [],
                "technical_requirements": [],
                "regulatory_landscape": [],
                "cost_considerations": [],
                "best_practices": [],
                "implementation_factors": []
            }),
            "boolean_query": analysis_result.get("boolean_query", ""),
            "missing_context": analysis_result.get("missing_context", [])
        }

        log_dict(analysis_result, title="Query Analysis Result")

        # Check for missing context
        missing_context = analysis_result.get("missing_context", [])
        needs_clarification = len(missing_context) >= 2  # Only request clarification for multiple missing elements

        # Update category queries based on analysis
        categories = state["categories"]
        for category, category_state in categories.items():
            search_terms = analysis_result.get("search_terms", {}).get(category, [])
            if search_terms:
                # Create optimized query for this category
                is_higher_ed = "higher ed" in query.lower() or "education" in query.lower()
                optimized_query = optimize_query(query, category, is_higher_ed)
                category_state["query"] = optimized_query
                info_highlight(f"Set query for {category}: {optimized_query}")
            else:
                # Use default query if no specific terms
                category_state["query"] = query

        return {
            "query_analysis": analysis_result,
            "categories": categories,
            "missing_context": missing_context,
            "needs_clarification": needs_clarification,
            "status": "analyzed"
        }
    except Exception as e:
        error_highlight(f"Error in query analysis: {str(e)}")
        return {"error": {"message": f"Error in query analysis: {str(e)}", "phase": "query_analysis"}}

async def request_clarification(state: ResearchState) -> Dict[str, Any]:
    """Request clarification from the user for missing context."""
    log_step("Requesting clarification", 3, 10)
    
    missing_context = state["missing_context"]
    if not missing_context:
        return {"needs_clarification": False}
    
    # Format the missing context items
    missing_sections = "\n".join([f"- {item}" for item in missing_context])
    
    # Get analysis data
    analysis = state.get("query_analysis", {})
    search_components = analysis.get("search_components", {}) if analysis else {}
    
    # Prepare the clarification request
    try:
        clarification_message = CLARIFICATION_PROMPT.format(
            query=state["original_query"],
            product_vs_service=search_components.get("product_type", "Unknown"),
            industry_context=search_components.get("industry", "Unknown"),
            geographical_focus=search_components.get("geographical_focus", "Unknown"),
            missing_sections=missing_sections
        )
        
        info_highlight("Generated clarification request")
        
        # Set up interrupt for user input
        return {
            "clarification_request": clarification_message,
            "__interrupt__": {
                "value": {
                    "question": clarification_message,
                    "missing_context": missing_context
                },
                "resumable": True,
                "ns": ["request_clarification"],
                "when": "during"
            }
        }
    except Exception as e:
        error_highlight(f"Error creating clarification request: {str(e)}")
        # Proceed without clarification in case of error
        return {"needs_clarification": False}

async def process_clarification(state: ResearchState) -> Dict[str, Any]:
    """Process user clarification and update the research context."""
    log_step("Processing clarification", 4, 10)
    
    if not state["messages"]:
        warning_highlight("No messages found for clarification")
        return {}
    
    # Get the latest message which should contain the user's clarification
    last_message = state["messages"][-1]
    clarification_content = str(last_message.content).strip()
    
    info_highlight(f"Processing user clarification: {clarification_content}")
    
    return {
        "human_feedback": clarification_content,
        "needs_clarification": False,
        "missing_context": [],
        "status": "clarified"
    }

# --------------------------------------------------------------------
# 3. Module-specific research nodes
# --------------------------------------------------------------------

async def execute_category_search(
    state: ResearchState, 
    category: str,
    config: Optional[RunnableConfig] = None
) -> Dict[str, Any]:
    """Execute search for a specific research category."""
    log_step(f"Executing search for category: {category}", 5, 10)
    
    categories = state["categories"]
    if category not in categories:
        warning_highlight(f"Unknown category: {category}")
        return {}
    
    category_state = categories[category]
    query = category_state["query"]
    
    if not query:
        warning_highlight(f"No query available for category: {category}")
        return {}
    
    # Update status
    category_state["status"] = "searching"
    category_state["retry_count"] += 1
    
    # Get category-specific search parameters
    thresholds = SEARCH_QUALITY_THRESHOLDS.get(category, {})
    recency_days = int(thresholds.get("recency_threshold_days", 365))
    
    # Configure search params based on category
    search_type_mapping: Dict[str, SearchType] = {
        "market_dynamics": "recent",  # Need fresh market data
        "provider_landscape": "comprehensive",  # Need diverse providers
        "technical_requirements": "technical",  # Technical content
        "regulatory_landscape": "authoritative",  # Authoritative sources
        "cost_considerations": "recent",  # Fresh pricing data
        "best_practices": "comprehensive",  # Diverse practices
        "implementation_factors": "comprehensive"  # Diverse approaches
    }
    
    search_type = search_type_mapping.get(category, "general")
    
    info_highlight(f"Executing {search_type} search for {category} with query: {query}")
    
    try:
        # Keep track of the query for retry tracking
        category_state["last_search_query"] = query
        
        # Execute the search
        search_results = await search(
            query=query,
            search_type=search_type,
            recency_days=recency_days,
            config=ensure_config(config)
        )
        
        if not search_results:
            warning_highlight(f"No search results for {category}")
            category_state["status"] = "search_failed"
            return {"categories": categories}
        
        # Convert to the expected format
        formatted_results = []
        for doc in search_results:
            result = {
                "url": doc.metadata.get("url", ""),
                "title": doc.metadata.get("title", ""),
                "snippet": doc.page_content,
                "source": doc.metadata.get("source", ""),
                "quality_score": doc.metadata.get("quality_score", 0.5),
                "published_date": doc.metadata.get("published_date")
            }
            formatted_results.append(result)
        
        # Update the category state
        category_state["search_results"] = formatted_results
        category_state["status"] = "searched"
        
        info_highlight(f"Found {len(formatted_results)} results for {category}")
        return {"categories": categories}
        
    except Exception as e:
        error_highlight(f"Error in search for {category}: {str(e)}")
        category_state["status"] = "search_failed"
        return {"categories": categories}

async def extract_category_information(
    state: ResearchState,
    category: str,
    config: Optional[RunnableConfig] = None
) -> Dict[str, Any]:
    """Extract information from search results for a specific category."""
    log_step(f"Extracting information for category: {category}", 6, 10)
    
    categories = state["categories"]
    if category not in categories:
        warning_highlight(f"Unknown category: {category}")
        return {}
    
    category_state = categories[category]
    search_results = category_state["search_results"]
    original_query = state["original_query"]
    
    if not search_results:
        warning_highlight(f"No search results to extract for {category}")
        category_state["status"] = "extraction_failed"
        return {"categories": categories}
    
    # Update status
    category_state["status"] = "extracting"
    
    # Extract facts from each search result
    extracted_facts = []
    sources = []
    
    for idx, result in enumerate(search_results):
        url = result.get("url", "")
        content = result.get("snippet", "")
        
        if not url or not content or not is_valid_url(url):
            warning_highlight(f"Skipping invalid or empty result at index {idx}")
            continue
        
        info_highlight(f"Extracting from {url} for {category}")
        
        try:
            # Get the appropriate extraction prompt for this category
            extraction_prompt = get_extraction_prompt(
                category=category,
                query=original_query,
                url=url,
                content=content
            )
            
            # Add more detailed logging
            info_highlight(f"Using extraction prompt for {category}: {extraction_prompt[:100]}...")
            
            # Call the model for extraction
            extraction_result = await call_model_json(
                messages=[{"role": "human", "content": extraction_prompt}],
                config=ensure_config(config)
            )
            
            # Validate the extraction result
            if not extraction_result or not isinstance(extraction_result, dict):
                warning_highlight(f"Invalid extraction result format for {url}: {type(extraction_result)}")
                # Use default empty structure
                extraction_result = get_default_extraction_result(category)
                
            # Get relevance score
            relevance_score = extraction_result.get("relevance_score", 0.0)
            
            # Only include if relevant
            if relevance_score < 0.3:
                info_highlight(f"Low relevance ({relevance_score}) for {url}, skipping")
                continue
            
            # Get extracted facts based on category
            if category == "market_dynamics":
                facts = extraction_result.get("extracted_facts", [])
                
            elif category == "provider_landscape":
                facts = []
                vendors = extraction_result.get("extracted_vendors", [])
                if vendors:
                    facts.extend([
                        {"type": "vendor", "data": vendor} for vendor in vendors
                    ])
                
                relationships = extraction_result.get("vendor_relationships", [])
                if relationships:
                    facts.extend([
                        {"type": "relationship", "data": rel} for rel in relationships
                    ])
                
            elif category == "technical_requirements":
                facts = []
                requirements = extraction_result.get("extracted_requirements", [])
                if requirements:
                    facts.extend([
                        {"type": "requirement", "data": req} for req in requirements
                    ])
                
                standards = extraction_result.get("standards", [])
                if standards:
                    facts.extend([
                        {"type": "standard", "data": std} for std in standards
                    ])
                
            elif category == "regulatory_landscape":
                facts = []
                regulations = extraction_result.get("extracted_regulations", [])
                if regulations:
                    facts.extend([
                        {"type": "regulation", "data": reg} for reg in regulations
                    ])
                
                compliance = extraction_result.get("compliance_requirements", [])
                if compliance:
                    facts.extend([
                        {"type": "compliance", "data": req} for req in compliance
                    ])
                
            elif category == "cost_considerations":
                facts = []
                costs = extraction_result.get("extracted_costs", [])
                if costs:
                    facts.extend([
                        {"type": "cost", "data": cost} for cost in costs
                    ])
                
                models = extraction_result.get("pricing_models", [])
                if models:
                    facts.extend([
                        {"type": "pricing_model", "data": model} for model in models
                    ])
                
            elif category == "best_practices":
                facts = []
                practices = extraction_result.get("extracted_practices", [])
                if practices:
                    facts.extend([
                        {"type": "practice", "data": practice} for practice in practices
                    ])
                
                methods = extraction_result.get("methodologies", [])
                if methods:
                    facts.extend([
                        {"type": "methodology", "data": method} for method in methods
                    ])
                
            elif category == "implementation_factors":
                facts = []
                factors = extraction_result.get("extracted_factors", [])
                if factors:
                    facts.extend([
                        {"type": "factor", "data": factor} for factor in factors
                    ])
                
                challenges = extraction_result.get("challenges", [])
                if challenges:
                    facts.extend([
                        {"type": "challenge", "data": challenge} for challenge in challenges
                    ])
            else:
                # Default for unknown categories
                facts = extraction_result.get("extracted_facts", [])
            
            # Add source information to each fact
            for fact in facts:
                fact["source_url"] = url
                fact["source_title"] = result.get("title", "")
                
            # Only add source and facts if we extracted something
            if facts:
                extracted_facts.extend(facts)
                
                # Add source metadata
                source = {
                    "url": url,
                    "title": result.get("title", ""),
                    "published_date": result.get("published_date"),
                    "fact_count": len(facts),
                    "relevance_score": relevance_score,
                    "quality_score": result.get("quality_score", 0.5)
                }
                sources.append(source)
                
                info_highlight(f"Extracted {len(facts)} facts from {url}")
            else:
                info_highlight(f"No relevant facts found in {url}")
                
        except Exception as e:
            # Log more details about the exception
            warning_highlight(f"Error extracting from {url}: {str(e)}\nException type: {type(e)}")
            # Log a stack trace for debugging
            import traceback
            error_highlight(traceback.format_exc())
            # Use default empty structure
            extraction_result = get_default_extraction_result(category)
            continue
    
    # Update the category state
    category_state["extracted_facts"] = extracted_facts
    category_state["sources"] = sources
    
    # Determine if extraction was successful
    thresholds = SEARCH_QUALITY_THRESHOLDS.get(category, {})
    min_facts = thresholds.get("min_facts", 3)
    min_sources = thresholds.get("min_sources", 2)
    
    if len(extracted_facts) >= min_facts and len(sources) >= min_sources:
        category_state["status"] = "extracted"
        category_state["complete"] = True
        
        # Calculate quality score for this category
        quality_score = calculate_category_quality_score(
            category=category,
            extracted_facts=extracted_facts,
            sources=sources,
            thresholds=thresholds
        )
        category_state["quality_score"] = quality_score
        
        info_highlight(f"Successfully extracted information for {category} (quality: {quality_score:.2f})")
    else:
        category_state["status"] = "extraction_incomplete"
        info_highlight(f"Incomplete extraction for {category}: {len(extracted_facts)} facts from {len(sources)} sources")
        
        # If we've retried too many times, mark as complete anyway
        if category_state["retry_count"] >= 3:
            category_state["complete"] = True
            warning_highlight(f"Maximum retries reached for {category}, accepting partial results")
    
    return {"categories": categories}

# Helper function to calculate quality score for a category
def calculate_category_quality_score(
    category: str,
    extracted_facts: List[Dict[str, Any]],
    sources: List[Dict[str, Any]],
    thresholds: Dict[str, Any]
) -> float:
    """Calculate quality score for a category based on extracted data."""
    # Base score starts at 0.3
    score = 0.3
    
    # Add points for number of facts
    min_facts = thresholds.get("min_facts", 3)
    fact_ratio = min(1.0, len(extracted_facts) / (min_facts * 2))
    score += fact_ratio * 0.2
    
    # Add points for number of sources
    min_sources = thresholds.get("min_sources", 2)
    source_ratio = min(1.0, len(sources) / (min_sources * 1.5))
    score += source_ratio * 0.2
    
    # Add points for authoritative sources
    auth_ratio = thresholds.get("authoritative_source_ratio", 0.5)
    authoritative_sources = [
        s for s in sources 
        if s.get("quality_score", 0.0) > 0.7 or
        any(domain in s.get("url", "") for domain in ['.edu', '.gov', '.org'])
    ]
    auth_source_ratio = len(authoritative_sources) / len(sources) if sources else 0
    if auth_source_ratio >= auth_ratio:
        score += 0.2
    else:
        score += (auth_source_ratio / auth_ratio) * 0.1
    
    # Add points for recency
    recency_threshold = thresholds.get("recency_threshold_days", 365)
    recent_sources = 0
    for source in sources:
        date_str = source.get("published_date")
        if not date_str:
            continue
            
        try:
            from dateutil import parser
            from datetime import datetime, timezone
            date = parser.parse(date_str)
            now = datetime.now(timezone.utc)
            days_old = (now - date).days
            if days_old <= recency_threshold:
                recent_sources += 1
        except Exception:
            pass
    
    if sources:
        recency_ratio = recent_sources / len(sources)
        score += recency_ratio * 0.1
    
    return min(1.0, score)

async def execute_research_for_categories(
    state: ResearchState,
    config: Optional[RunnableConfig] = None
) -> Dict[str, Any]:
    """Execute research for all categories in parallel."""
    log_step("Executing research for all categories", 5, 10)
    
    categories = state["categories"]
    research_tasks = []
    
    for category, category_state in categories.items():
        if category_state["complete"]:
            info_highlight(f"Category {category} already complete, skipping")
            continue
            
        # Execute search followed by extraction
        info_highlight(f"Adding research task for {category}")
        
        # Create async task for this category
        async def process_category(cat: str) -> None:
            search_result = await execute_category_search(state, cat, config)
            # Only extract if search was successful
            if cat in search_result.get("categories", {}) and search_result["categories"][cat]["status"] == "searched":
                await extract_category_information(state, cat, config)
        
        task = asyncio.create_task(process_category(category))
        research_tasks.append(task)
    
    # Wait for all research tasks to complete
    if research_tasks:
        await asyncio.gather(*research_tasks)
    
    # Check if all categories are complete
    all_complete = all(
        category_state["complete"] for category_state in categories.values()
    )
    
    if all_complete:
        info_highlight("All categories research complete")
        return {
            "status": "researched",
            "categories": categories
        }
    else:
        # Some categories still incomplete
        incomplete = [
            category for category, category_state in categories.items()
            if not category_state["complete"]
        ]
        info_highlight(f"Categories still incomplete: {', '.join(incomplete)}")
        return {
            "status": "research_incomplete",
            "categories": categories
        }

# --------------------------------------------------------------------
# 4. Synthesis and validation nodes
# --------------------------------------------------------------------

async def synthesize_research(
    state: ResearchState,
    config: Optional[RunnableConfig] = None
) -> Dict[str, Any]:
    """Synthesize all research data into a comprehensive result."""
    log_step("Synthesizing research results", 7, 10)
    
    categories = state["categories"]
    original_query = state["original_query"]
    
    # Prepare research data for synthesis
    research_data = {}
    for category, category_state in categories.items():
        research_data[category] = {
            "facts": category_state["extracted_facts"],
            "sources": category_state["sources"],
            "quality_score": category_state["quality_score"]
        }
    
    # Generate prompt
    synthesis_prompt = SYNTHESIS_PROMPT.format(
        query=original_query,
        research_json=json.dumps(research_data, indent=2)
    )
    
    try:
        synthesis_result = await call_model_json(
            messages=[{"role": "human", "content": synthesis_prompt}],
            config=ensure_config(config)
        )
        
        log_dict(
            {
                "synthesis_sections": list(synthesis_result.get("synthesis", {}).keys()),
                "confidence_score": synthesis_result.get("confidence_assessment", {}).get("overall_score")
            },
            title="Synthesis Overview"
        )
        
        overall_score = synthesis_result.get("confidence_assessment", {}).get("overall_score", 0.0)
        info_highlight(f"Research synthesis complete with confidence score: {overall_score:.2f}")
        
        return {
            "synthesis": synthesis_result,
            "status": "synthesized"
        }
    except Exception as e:
        error_highlight(f"Error in research synthesis: {str(e)}")
        return {"error": {"message": f"Error in research synthesis: {str(e)}", "phase": "synthesis"}}

async def validate_synthesis(
    state: ResearchState,
    config: Optional[RunnableConfig] = None
) -> Dict[str, Any]:
    """Validate the synthesized research results."""
    log_step("Validating research synthesis", 8, 10)
    
    synthesis = state.get("synthesis")
    if not synthesis:
        warning_highlight("No synthesis to validate")
        return {"error": {"message": "No synthesis to validate", "phase": "validation"}}
    
    # Generate validation prompt
    validation_prompt = VALIDATION_PROMPT.format(
        synthesis_json=json.dumps(synthesis, indent=2)
    )
    
    try:
        validation_result = await call_model_json(
            messages=[{"role": "human", "content": validation_prompt}],
            config=ensure_config(config)
        )
        
        # Get validation status
        validation_results = validation_result.get("validation_results", {})
        is_valid = validation_results.get("is_valid", False)
        validation_score = validation_results.get("validation_score", 0.0)
        
        # Log validation results
        log_dict(
            {
                "is_valid": is_valid,
                "validation_score": validation_score,
                "critical_issues": validation_results.get("critical_issues", [])
            },
            title="Validation Results"
        )
        
        if is_valid:
            info_highlight(f"Validation passed with score: {validation_score:.2f}")
            return {
                "validation_result": validation_result,
                "status": "validated",
                "complete": True
            }
        else:
            warning_highlight(f"Validation failed with score: {validation_score:.2f}")
            return {
                "validation_result": validation_result,
                "status": "validation_failed"
            }
    except Exception as e:
        error_highlight(f"Error in synthesis validation: {str(e)}")
        return {"error": {"message": f"Error in synthesis validation: {str(e)}", "phase": "validation"}}

async def prepare_final_response(
    state: ResearchState,
    config: Optional[RunnableConfig] = None
) -> Dict[str, Any]:
    """Prepare the final response with the research results."""
    log_step("Preparing final response", 9, 10)
    
    synthesis = state.get("synthesis", {})
    validation = state.get("validation_result", {})
    original_query = state["original_query"]
    
    # Create a summary message for the user
    synthesis_content = synthesis.get("synthesis", {}) if synthesis else {}
    confidence = synthesis.get("confidence_assessment", {}) if synthesis else {}
    
    # Build an executive summary
    executive_summary = "# Research Results: " + original_query + "\n\n"
    
    # Add confidence information
    confidence_score = confidence.get("overall_score", 0.0)
    executive_summary += f"**Confidence Score:** {confidence_score:.2f}/1.0\n\n"
    
    # Add key findings from most complete sections
    executive_summary += "## Key Findings\n\n"
    
    # Get the most complete sections
    section_scores = confidence.get("section_scores", {})
    sorted_sections = sorted(
        section_scores.items(),
        key=lambda x: x[1],
        reverse=True
    )
    
    # Add content from top 3 sections
    for section_name, score in sorted_sections[:3]:
        if section_name in synthesis_content and synthesis_content[section_name]["content"]:
            section_content = synthesis_content[section_name]["content"]
            executive_summary += f"### {section_name.replace('_', ' ').title()}\n\n"
            executive_summary += f"{section_content}\n\n"
    
    # Add limitations
    knowledge_gaps = confidence.get("knowledge_gaps", [])
    if knowledge_gaps:
        executive_summary += "## Limitations\n\n"
        for gap in knowledge_gaps:
            executive_summary += f"- {gap}\n"
    
    # Create the response message
    response_message = AIMessage(content=executive_summary)
    
    return {
        "messages": [response_message],
        "status": "complete",
        "complete": True
    }

# --------------------------------------------------------------------
# 5. Conditional routing functions
# --------------------------------------------------------------------

def should_request_clarification(state: ResearchState) -> Hashable:
    """Determine if clarification is needed."""
    needs_clarification = state.get("needs_clarification", False)
    has_feedback = bool(state.get("human_feedback"))
    
    if needs_clarification and not has_feedback:
        return "request_clarification"
    else:
        return "execute_research_for_categories"

def check_retry_or_continue(state: ResearchState) -> Hashable:
    """Determine if we should retry incomplete categories or continue."""
    categories = state["categories"]

    # Check if any categories need retry
    categories_to_retry = []
    categories_to_retry.extend(
        category
        for category, category_state in categories.items()
        if not category_state["complete"] and category_state["retry_count"] < 3
    )
    if categories_to_retry:
        # Still have categories to retry
        info_highlight(f"Categories to retry: {categories_to_retry}")
        return "execute_research_for_categories"
    else:
        # All categories either complete or max retries reached
        info_highlight("Research complete or max retries reached for all categories")
        return "synthesize_research"

def validate_or_complete(state: ResearchState) -> Hashable:
    """Determine if we should validate the synthesis or finish."""
    validation_result = state.get("validation_result", {})
    validation_results = validation_result.get("validation_results", {}) if validation_result else {}
    if is_valid := validation_results.get("is_valid", False):
        info_highlight("Validation passed, preparing final response")
    else:
        # Not valid, but we'll still finish
        warning_highlight("Validation failed, but preparing final response anyway")
    return "prepare_final_response"

def handle_error_or_continue(state: ResearchState) -> Hashable:
    """Determine if we should handle an error or continue."""
    error = state.get("error")
    
    if error:
        error_highlight(f"Error detected: {error.get('message')} in phase {error.get('phase')}")
        return "handle_error"
    else:
        return "continue"

# --------------------------------------------------------------------
# 6. Error handling
# --------------------------------------------------------------------

async def handle_error(state: ResearchState) -> Dict[str, Any]:
    """Handle errors gracefully and return a helpful message."""
    error = state.get("error", {})
    phase = error.get("phase", "unknown") if error else "unknown"
    message = error.get("message", "An unknown error occurred") if error else "An unknown error occurred"

    error_highlight(f"Handling error in phase {phase}: {message}")

    # Create a helpful error message
    error_response = f"I encountered an issue while researching your query: {message}"
    error_response += "\n\nHere's what I was able to find before the error occurred:"

    # Include any partial results we have
    categories = state.get("categories", {})
    if complete_categories := [
        category
        for category, category_state in categories.items()
        if category_state.get("complete", False)
    ]:
        error_response += f"\n\nI completed research on: {', '.join(complete_categories)}"

        # Include facts from complete categories
        for category in complete_categories:
            category_state = categories[category]
            facts = category_state.get("extracted_facts", [])
            if facts:
                error_response += f"\n\n## {category.replace('_', ' ').title()}\n"
                for i, fact in enumerate(facts[:3]):  # Show up to 3 facts
                    if isinstance(fact, dict):
                        if "data" in fact and isinstance(fact["data"], dict):
                            # Handle structured facts
                            if "fact" in fact["data"]:
                                error_response += f"\n- {fact['data']['fact']}"
                            elif "requirement" in fact["data"]:
                                error_response += f"\n- {fact['data']['requirement']}"
                            elif "vendor_name" in fact["data"]:
                                error_response += f"\n- {fact['data']['vendor_name']}: {fact['data'].get('description', '')}"
                            else:
                                # Just get the first string value we can find
                                for k, v in fact["data"].items():
                                    if isinstance(v, str) and v:
                                        error_response += f"\n- {v}"
                                        break
                        elif "fact" in fact:
                            error_response += f"\n- {fact['fact']}"
    else:
        error_response += "\n\nUnfortunately, I wasn't able to complete any research categories before the error occurred."

    error_response += "\n\nWould you like me to try again with a more specific query?"

    # Create the error message
    error_message = AIMessage(content=error_response)

    return {
        "messages": [error_message],
        "status": "error",
        "complete": True
    }

# --------------------------------------------------------------------
# 7. Build the graph
# --------------------------------------------------------------------

def create_research_graph() -> CompiledStateGraph:
    """Create the modular research graph."""
    graph = StateGraph(ResearchState)

    # Add the main nodes
    graph.add_node("initialize", initialize_research)
    graph.add_node("analyze_query", analyze_query)
    graph.add_node("request_clarification", request_clarification)
    graph.add_node("process_clarification", process_clarification)
    graph.add_node("execute_research_for_categories", execute_research_for_categories)
    graph.add_node("synthesize_research", synthesize_research)
    graph.add_node("validate_synthesis", validate_synthesis)
    graph.add_node("prepare_final_response", prepare_final_response)
    graph.add_node("handle_error", handle_error)
    graph.add_node("check_retry", lambda state: {"next_step": check_retry_or_continue(state)})
    graph.add_node("validate_or_complete", lambda state: {"next_step": validate_or_complete(state)})

    # Add error handling edges
    graph.add_conditional_edges(
        "initialize",
        handle_error_or_continue,
        {
            "handle_error": "handle_error",
            "continue": "analyze_query"
        }
    )

    # Set start point
    graph.add_edge(START, "initialize")

    # Add conditional branch for clarification from analyze_query
    graph.add_conditional_edges(
        "analyze_query",
        should_request_clarification,
        {
            "request_clarification": "request_clarification",
            "execute_research_for_categories": "execute_research_for_categories"
        }
    )
    
    graph.add_edge("request_clarification", "process_clarification")
    graph.add_edge("process_clarification", "analyze_query")

    # Research flow
    graph.add_conditional_edges(
        "execute_research_for_categories",
        handle_error_or_continue,
        {
            "handle_error": "handle_error",
            "continue": "check_retry"
        }
    )

    graph.add_conditional_edges(
        "check_retry",
        lambda state: state.get("next_step", "synthesize_research"),
        {
            "execute_research_for_categories": "execute_research_for_categories",
            "synthesize_research": "synthesize_research"
        }
    )

    # Synthesis and validation
    graph.add_conditional_edges(
        "synthesize_research",
        handle_error_or_continue,
        {
            "handle_error": "handle_error",
            "continue": "validate_synthesis"
        }
    )

    graph.add_conditional_edges(
        "validate_synthesis",
        handle_error_or_continue,
        {
            "handle_error": "handle_error",
            "continue": "validate_or_complete"
        }
    )

    graph.add_conditional_edges(
        "validate_or_complete",
        lambda state: state.get("next_step", "prepare_final_response"),
        {
            "prepare_final_response": "prepare_final_response"
        }
    )

    # Final steps
    graph.add_edge("prepare_final_response", END)
    graph.add_edge("handle_error", END)

    return graph.compile(interrupt_before=["process_clarification"])

# Create the graph instance
research_graph = create_research_graph()

# def create_category_graph(category: str) -> CompiledStateGraph:
#     """Create a specialized graph for a single research category."""
#     graph = StateGraph(ResearchState)
    
#     # Add nodes for single category research
#     graph.add_node("initialize", initialize_research)
#     graph.add_node("analyze_query", analyze_query)
#     graph.add_node("execute_category_search", lambda state, config: execute_category_search(state, category, config))
#     graph.add_node("extract_category_information", lambda state, config: extract_category_information(state, category, config))
#     graph.add_node("prepare_final_response", prepare_final_response)
#     graph.add_node("handle_error", handle_error)
    
#     # Add edges
#     graph.add_edge(START, "initialize")
#     graph.add_edge("initialize", "analyze_query")
#     graph.add_edge("analyze_query", "execute_category_search")
#     graph.add_edge("execute_category_search", "extract_category_information")
#     graph.add_edge("extract_category_information", "prepare_final_response")
#     graph.add_edge("prepare_final_response", END)
#     graph.add_edge("handle_error", END)
    
#     return graph.compile()
</file>

<file path="src/react_agent/prompts/__init__.py">
"""Prompt exports.

This module provides functionality for prompt exports
in the agent framework.
"""

from typing import Any, Dict, Final, List, Tuple

from react_agent.prompts.analysis import (
    ANALYSIS_PROMPT,
    TOOL_SELECTION_PROMPT,
)
from react_agent.prompts.market import (
    MARKET_DATA_PROMPT,
    MARKET_PROMPT,
)
from react_agent.prompts.reflection import (
    REFLECTION_PROMPT,
)
from react_agent.prompts.research import (
    ADDITIONAL_TOPICS_PROMPT,
    RESEARCH_AGENT_PROMPT,
    RESEARCH_BASE_PROMPT,
    TOPICS_PROMPT,
    QUERY_ANALYSIS_PROMPT,
    CLARIFICATION_PROMPT,
)

# Import all prompts from modules
from react_agent.prompts.templates import (
    ANALOGICAL_REASONING_PROMPT,
    COUNTERFACTUAL_PROMPT,
    CRITIQUE_PROMPT_TEMPLATE,
    EVALUATION_PROMPT_TEMPLATE,
    # Reflection prompts
    FEEDBACK_PROMPT_TEMPLATE,
    MAIN_PROMPT,
    METACOGNITION_PROMPT,
    NEWS_SEARCH_DESC,
    SCRAPE_DESC,
    STRUCTURED_OUTPUT_VALIDATION,
    SUMMARIZER_DESC,
    TOOL_INSTRUCTIONS,
    VALIDATION_REQUIREMENTS,
    WEB_SEARCH_DESC,
)
from react_agent.prompts.validation import (
    VALIDATION_AGENT_PROMPT,
    VALIDATION_BASE_PROMPT,
)

# Re-export everything for backward compatibility
__all__ = [
    # Templates
    "STRUCTURED_OUTPUT_VALIDATION",
    "VALIDATION_REQUIREMENTS",
    "MAIN_PROMPT",
    "WEB_SEARCH_DESC",
    "SCRAPE_DESC",
    "SUMMARIZER_DESC",
    "NEWS_SEARCH_DESC",
    "TOOL_INSTRUCTIONS",
    # Research
    "RESEARCH_BASE_PROMPT",
    "RESEARCH_AGENT_PROMPT",
    "MARKET_PROMPT",
    "TOPICS_PROMPT",
    "ADDITIONAL_TOPICS_PROMPT",
    "QUERY_ANALYSIS_PROMPT",
    "CLARIFICATION_PROMPT",
    # Validation
    "VALIDATION_BASE_PROMPT",
    "VALIDATION_AGENT_PROMPT",
    # Analysis
    "ANALYSIS_PROMPT",
    "TOOL_SELECTION_PROMPT",
    # Reflection
    "REFLECTION_PROMPT",
    # Reflection Templates
    "FEEDBACK_PROMPT_TEMPLATE",
    "EVALUATION_PROMPT_TEMPLATE",
    "CRITIQUE_PROMPT_TEMPLATE",
    "ANALOGICAL_REASONING_PROMPT",
    "COUNTERFACTUAL_PROMPT",
    "METACOGNITION_PROMPT",
    # Functions
    "get_report_template",
    "get_analysis_template",
]


# Common utility functions
def get_report_template() -> Dict[str, Any]:
    """Get the template for the final report."""
    return {
        "summary": "",
        "research_findings": {},
        "market_analysis": {},
        "generated_at": "",
    }


def get_analysis_template() -> Dict[str, Any]:
    """Get the template for research analysis."""
    return {
        "citations": [],
        "porters_five_forces": {},
        "swot_analysis": {},
        "pestel_analysis": {},
        "gap_analysis": {},
        "cost_benefit_analysis": {},
        "risk_assessment": {},
        "tco_analysis": {},
        "vendor_analysis": {},
        "benchmarking": {},
        "stakeholder_analysis": {},
        "compliance_analysis": {},
        "business_impact_analysis": {},
    }


# Required analysis topics
REQUIRED_ANALYSIS_TOPICS: List[Tuple[str, str]] = [
    ("Porter's Five Forces", "Analysis of competitive forces in the industry"),
    ("SWOT Analysis", "Strengths, weaknesses, opportunities, and threats"),
    (
        "PESTEL Analysis",
        "Political, economic, social, technological, environmental, and legal factors",
    ),
    ("GAP Analysis", "Current state vs desired state analysis"),
    ("Cost-Benefit Analysis", "Analysis of costs and benefits"),
    ("Risk Assessment", "Identification and analysis of potential risks"),
    ("Total Cost of Ownership", "Complete cost analysis including indirect costs"),
    ("Vendor Analysis", "Analysis of potential vendors and suppliers"),
    ("Benchmarking", "Comparison with industry standards and best practices"),
    ("Stakeholder Analysis", "Analysis of key stakeholders and their needs"),
    ("Compliance Analysis", "Analysis of regulatory and compliance requirements"),
    ("Business Impact Analysis", "Analysis of business impact and strategic alignment"),
]

# System prompts
SYSTEM_PROMPT_ANALYST: Final[str] = "You are an expert market research analyst."

# Finalization prompts
FINALIZATION_BASE_PROMPT: Final[
    str
] = """You are a Finalization Agent for RFP market analysis.
Your goal is to generate comprehensive reports and outputs from the validated research.

{STRUCTURED_OUTPUT_VALIDATION}

FINALIZATION REQUIREMENTS:
1. Research Report
   - Expand each analysis element into well-written sections
   - Maintain professional and clear writing style
   - Include supporting evidence and citations
   - Organize content logically and cohesively
   - Ensure all insights are actionable

2. Analysis Sections
   - Porter's 5 Forces analysis
   - SWOT analysis
   - PESTEL analysis
   - GAP analysis
   - Cost-benefit analysis
   - Risk assessment
   - Total cost of ownership
   - Vendor analysis
   - Benchmarking results
   - Stakeholder analysis
   - Compliance requirements
   - Business impact assessment

3. Market Basket Output
   - Generate CSV format
   - Include all line items
   - Maintain data accuracy
   - Format for easy review
   - Include citations and sources

4. Quality Requirements
   - Professional writing style
   - Clear section headings
   - Consistent formatting
   - Proper citation formatting
   - Executive summary
   - Recommendations section

RESPONSE_FORMAT:
{
    "outputs": {
        "research_report": {
            "format": "markdown",
            "content": "",
            "sections": []
        },
        "market_basket": {
            "format": "csv",
            "headers": [],
            "rows": []
        },
        "executive_summary": "",
        "recommendations": [],
        "confidence_scores": {},
        "key_findings": []
    },
    "metadata": {
        "generated_at": "",
        "version": "1.0",
        "validation_status": {
            "is_valid": false,
            "errors": [],
            "warnings": []
        }
    }
}

Current state: {state}
"""

FINALIZATION_AGENT_PROMPT: Final[str] = FINALIZATION_BASE_PROMPT.replace(
    "Your goal is to generate comprehensive reports and outputs from the validated research.\n",
    "Your goal is to generate comprehensive reports and outputs from the validated research.\n\n{STRUCTURED_OUTPUT_VALIDATION}\n",
)

ENRICHMENT_AGENT_PROMPT: Final[
    str
] = """You are an Enrichment Agent for RFP market analysis.
Enhance the following validated data while maintaining the JSON structure:
Validated Data:
{validated_data}
Required Schema:
{
    "rfp_analysis": {
        "analysis": {
            "porters_5_forces": {
                "competitive_rivalry": "",
                "threat_of_new_entrants": "",
                "threat_of_substitutes": "",
                "bargaining_power_buyers": "",
                "bargaining_power_suppliers": ""
            },
            "swot": {
                "strengths": [],
                "weaknesses": [],
                "opportunities": [],
                "threats": []
            },
            "recent_breakthroughs_and_disruptors": "",
            "cost_trends_and_projections": "",
            "typical_contract_clauses_and_pricing_nuances": "",
            "competitive_landscape": "",
            "citations": {
                "porters_5_forces": [],
                "swot": [],
                "recent_breakthroughs_and_disruptors": [],
                "cost_trends_and_projections": [],
                "typical_contract_clauses_and_pricing_nuances": [],
                "competitive_landscape": []
            }
        },
        "market_basket": [
            {
                "manufacturer_or_distributor": "",
                "item_number": "",
                "item_description": "",
                "uom": "",
                "estimated_qty_per_uom": 0.0,
                "unit_cost": 0.0,
                "citation": ""
            }
        ]
    },
    "confidence_score": 0.0
}
Enrichment Focus Areas:
1. Market Intelligence
   - Add emerging technology trends with citations
   - Include regulatory impact analysis with sources
   - Highlight market consolidation trends with references
   - Ensure at least 2 citations per section

2. Supplier Intelligence
   - Add supplier financial health indicators with sources
   - Include supplier innovation capabilities with citations
   - Note supplier market share trends with references
   - Validate supplier information from multiple sources

3. Pricing Intelligence
   - Add volume discount structures with citations
   - Include regional pricing variations with sources
   - Note seasonal pricing factors with references
   - Verify pricing data from reliable sources

4. Risk Analysis
   - Add supply chain risk factors with citations
   - Include mitigation strategies with sources
   - Note alternative sourcing options with references
   - Cross-reference risk data from multiple sources

5. Citation Requirements
   - Each analysis section must have at least 2 citations
   - Market basket items must each have a valid citation
   - Citations must be from reliable industry sources
   - Avoid using the same citation across multiple sections

CONFIDENCE_SCORING:
- Start with a base score of 0.5
- Add 0.1 for each section with 2+ unique citations
- Add 0.1 for each market basket item with verified pricing
- Subtract 0.1 for any section with fewer than 2 citations
- Maximum score is 0.95 until all data is fully verified

RESPONSE_REQUIREMENTS:
1. Output must be valid JSON only
2. All fields must be populated with enriched data
3. No explanatory text or comments
4. Include enrichment notes in "enrichment_details" if needed
5. Ensure complete, untruncated JSON output
6. Every section must have multiple citations
7. Market basket items must have verified sources

Current enrichment state: {current_state}
Conversation history:
{chat_history}
"""

# Export finalization prompts
__all__.extend(
    [
        "FINALIZATION_BASE_PROMPT",
        "FINALIZATION_AGENT_PROMPT",
        "ENRICHMENT_AGENT_PROMPT",
        "REQUIRED_ANALYSIS_TOPICS",
        "SYSTEM_PROMPT_ANALYST",
    ]
)
</file>

<file path="src/react_agent/prompts/analysis.py">
"""Analysis-specific prompts.

This module provides functionality for analysis-specific prompts
in the agent framework.
"""

from typing import Final

# Prompt for tool selection
TOOL_SELECTION_PROMPT: Final[str] = (
    """What information do we need to research about {current_topic}?"""
)

# Prompt for analysis of tool results
ANALYSIS_PROMPT: Final[str] = """
Based on the following research about {current_topic}, provide a comprehensive analysis:

{formatted_results}

Your analysis should include:
1. Key insights from the research
2. Patterns or trends identified
3. Implications for the business
4. Recommendations based on the findings
"""

# Prompt for analysis plan formulation
ANALYSIS_PLAN_PROMPT: Final[str] = """
Analysis Task: {task}
Available Data:
{data_summary}

Create a comprehensive plan for analyzing this data that will address the task.
Your plan should include:
1. Data preparation steps needed (e.g., cleaning, transformation)
2. Analysis methods to apply (e.g., descriptive statistics, correlation, regression)
3. Visualizations to create (e.g., histograms, scatter plots, bar charts)
4. Hypotheses to test (if applicable)
5. Statistical methods to use (e.g., t-tests, ANOVA, chi-squared)
6. Expected insights (what do you expect to learn from the analysis?)

Format your response as a JSON object with these sections.
"""

# Prompt for results interpretation
INTERPRET_RESULTS_PROMPT: Final[str] = """
Analysis Task: {task}
Analysis Results:
{analysis_results}
Analysis Plan:
{analysis_plan}

Interpret these results in the context of the original task.
Your interpretation should include:
1. Key findings and insights
2. Patterns and trends identified
3. Anomalies or unexpected results
4. Limitations of the analysis
5. Answers to specific questions in the task (if any)
6. Business implications (if applicable)

Format your response as a JSON object with these sections.
"""

# Prompt for report compilation
COMPILE_REPORT_PROMPT: Final[str] = """
Analysis Task: {task}
Analysis Results:
{analysis_results}
Interpretations:
{interpretations}
Visualizations:
{visualization_metadata}

Compile a comprehensive analysis report addressing the original task.
The report should:
1. Start with an executive summary of key findings.
2. Include an introduction explaining the context and objectives.
3. Describe the methodology and data sources.
4. Present the detailed findings with references to visualizations.
5. Discuss implications and recommendations.
6. Note limitations and potential future analysis.

Format the report as markdown with proper headings, lists, and sections.
"""
</file>

<file path="src/react_agent/prompts/market.py">
"""Market-specific prompts.

This module provides functionality for market data processing prompts
in the agent framework.
"""

from typing import Final

# Market data processing prompt
MARKET_DATA_PROMPT: Final[str] = """You are a Market Data Processor specialized in extracting pricing and sourcing information.

Your task is to analyze the following item and identify potential market sources, pricing, and manufacturer information.

INSTRUCTIONS:
1. Analyze the provided item description
2. Identify potential manufacturers or distributors
3. Find item numbers, descriptions, and pricing information
4. Format the response as a structured JSON object

RESPONSE FORMAT:
{
    "market_items": [
        {
            "manufacturer": "Name of manufacturer or distributor",
            "item_number": "Product/catalog number",
            "item_description": "Detailed description of the item",
            "unit_of_measure": "Each, Box, Case, etc.",
            "unit_cost": 0.00,
            "source": "Where this information was found"
        }
    ],
    "confidence_score": 0.0,
    "notes": "Any additional information or context"
}

IMPORTANT:
- Include multiple sources if available
- Provide accurate pricing information
- Include detailed item descriptions
- Assign a confidence score (0.0-1.0) based on data reliability
- Only include items that match the original description

Item to process: {state}
""" 

# Market research prompt
MARKET_PROMPT: Final[str] = """You are a Market Research Agent focused on building comprehensive market baskets.

Your task is to analyze the market for the following items and provide detailed market research information.

INSTRUCTIONS:
1. Analyze the market for each item
2. Identify market trends and dynamics
3. Research pricing and availability
4. Find potential suppliers and manufacturers
5. Analyze market competition
6. Identify regulatory requirements
7. Provide market forecasts and insights

RESPONSE FORMAT:
{
    "market_analysis": {
        "market_size": "Total market size with units",
        "growth_rate": "Annual growth rate",
        "trends": ["Key market trends"],
        "competition": ["Major competitors"],
        "regulations": ["Relevant regulations"]
    },
    "items": [
        {
            "item_name": "Name of item",
            "market_price": "Price range",
            "suppliers": ["List of suppliers"],
            "availability": "Supply status",
            "quality_metrics": ["Quality indicators"]
        }
    ],
    "confidence_score": 0.0,
    "notes": "Additional market insights"
}

IMPORTANT:
- Provide accurate market data with sources
- Include recent market trends and forecasts
- Consider both local and global market factors
- Note any market risks or uncertainties
- Assign confidence scores based on data reliability
"""
</file>

<file path="src/react_agent/prompts/reflection.py">
"""Reflection and critique prompts.

This module provides functionality for reflection and critique prompts
in the agent framework.
"""

from typing import Final

# Reflection prompt
# Parameters:
#   current_state: The current state of the agent
#   validation_targets: List of targets to validate
REFLECTION_PROMPT: Final[
    str
] = """You are a Reflection Agent responsible for validating research findings and preventing hallucinations.
Your tasks include:

1. Citation Validation
- Check all URLs for validity (no 404s)
- Verify source credibility
- Ensure citation dates are recent

2. Confidence Scoring
- Evaluate research findings confidence (threshold: 98%)
- Score market data reliability
- Assess source quality

3. Structured Output Validation
- Verify all required fields are populated
- Check data format consistency
- Validate numerical values

4. Quality Control
- Flag potential hallucinations
- Identify data gaps
- Request additional research if needed

Current state: {current_state}
Validation targets: {validation_targets}
"""
</file>

<file path="src/react_agent/prompts/research.py">
"""Enhanced research-specific prompts.

This module provides specialized prompts for different research categories
to improve extraction quality and relevance.
"""

from typing import Final, Dict, List, Any

# Base templates for common validation requirements
STRUCTURED_OUTPUT_VALIDATION: Final[str] = """CRITICAL: All responses MUST:
1. Be valid JSON only - no additional text or comments
2. Follow the exact schema provided
3. Never return empty or null values - use empty strings or arrays instead
4. Include all required fields
5. Use proper data types (strings, numbers, arrays)
6. Maintain proper JSON syntax
7. Include citations for all data points
8. Pass JSON schema validation

Any response that fails these requirements will be rejected."""

# Enhanced query analysis prompt with improved categorization and structure
QUERY_ANALYSIS_PROMPT: Final[str] = """Analyze the following research query to generate targeted search terms.

Query: {query}

TASK:
Break down this query into precise search components following these rules:
1. Use the UNSPSC taxonomy to identify relevant procurement categories
2. Extract no more than 3-5 focused keywords per category
3. Prioritize specificity over quantity
4. Identify the specific industry verticals, markets, and sectors
5. Determine geographical scope if relevant

FORMAT YOUR RESPONSE AS JSON:
{{
    "unspsc_categories": [
        {{"code": "code", "name": "category name", "relevance": 0.0-1.0}}
    ],
    "search_components": {{
        "primary_topic": "", 
        "industry": "",
        "product_type": "",
        "geographical_focus": ""
    }},
    "search_terms": {{
        "market_dynamics": [],
        "provider_landscape": [],
        "technical_requirements": [],
        "regulatory_landscape": [],
        "cost_considerations": [],
        "best_practices": [],
        "implementation_factors": []
    }},
    "boolean_query": "",
    "missing_context": []
}}

IMPORTANT: 
- Keep each category to a MAXIMUM of 5 focused search terms
- Only include truly essential items in "missing_context" - make reasonable assumptions
- For "boolean_query" create a precise search string using AND/OR operators
- Assign relevance scores (0.0-1.0) to each UNSPSC category
- Your response must be valid JSON with all fields present
- Do not include any comments or additional text in the JSON response
"""

# Specialized extraction prompts for different research categories
EXTRACTION_PROMPTS: Dict[str, str] = {
    "market_dynamics": """Extract factual information about MARKET DYNAMICS from this content about {query}.

URL: {url}

INSTRUCTIONS:
1. ONLY extract VERIFIED facts about market size, growth rates, trends, forecasts, and competitive dynamics
2. Format each fact with:
   - The fact statement
   - Direct quote from the content supporting the fact
   - Confidence rating (high/medium/low)
3. If the document doesn't contain relevant market data, indicate this

CONTENT:
{content}

FORMAT YOUR RESPONSE AS JSON:
{{
  "extracted_facts": [
    {{
      "fact": "Clear factual statement about market dynamics",
      "source_text": "Direct quote from content",
      "confidence": "high/medium/low",
      "data_type": "market_size/growth_rate/trend/forecast/competitive"
    }}
  ],
  "market_metrics": {{
    "market_size": null,  // Include if available with units
    "growth_rate": null,  // Include if available with time period
    "forecast_period": null  // Include if available
  }},
  "relevance_score": 0.0-1.0
}}
""",

    "provider_landscape": """Extract factual information about PROVIDERS/VENDORS from this content about {query}.

URL: {url}

INSTRUCTIONS:
1. ONLY extract VERIFIED facts about vendors, suppliers, service providers, and market players
2. Format each fact with:
   - The vendor name and specific details
   - Direct quote from the content supporting the fact
   - Confidence rating (high/medium/low)
3. If no vendor information is found, indicate this

CONTENT:
{content}

FORMAT YOUR RESPONSE AS JSON:
{{
  "extracted_vendors": [
    {{
      "vendor_name": "Name of vendor",
      "description": "What they provide",
      "market_position": "leader/challenger/niche",
      "source_text": "Direct quote from content",
      "confidence": "high/medium/low"
    }}
  ],
  "vendor_relationships": [
    {{
      "relationship_type": "partnership/competition/acquisition",
      "entities": ["vendor1", "vendor2"],
      "source_text": "Direct quote from content",
      "confidence": "high/medium/low"
    }}
  ],
  "relevance_score": 0.0-1.0
}}
""",

    "technical_requirements": """Extract factual information about TECHNICAL REQUIREMENTS from this content about {query}.

URL: {url}

INSTRUCTIONS:
1. ONLY extract VERIFIED facts about specifications, standards, technologies, and requirements
2. Format each fact with:
   - The technical requirement or specification
   - Direct quote from the content supporting the fact
   - Confidence rating (high/medium/low)
3. If no technical information is found, indicate this

CONTENT:
{content}

FORMAT YOUR RESPONSE AS JSON:
{{
  "extracted_requirements": [
    {{
      "requirement": "Specific technical requirement",
      "category": "hardware/software/compliance/integration/performance",
      "source_text": "Direct quote from content",
      "confidence": "high/medium/low"
    }}
  ],
  "standards": [
    {{
      "standard_name": "Name of standard or protocol",
      "description": "Brief description",
      "source_text": "Direct quote from content",
      "confidence": "high/medium/low"
    }}
  ],
  "relevance_score": 0.0-1.0
}}
""",

    "regulatory_landscape": """Extract factual information about REGULATIONS & COMPLIANCE from this content about {query}.

URL: {url}

INSTRUCTIONS:
1. ONLY extract VERIFIED facts about regulations, laws, compliance requirements, and standards
2. Format each regulation with:
   - The regulation name and jurisdiction
   - Direct quote from the content supporting the fact
   - Confidence rating (high/medium/low)
3. If no regulatory information is found, indicate this

CONTENT:
{content}

FORMAT YOUR RESPONSE AS JSON:
{{
  "extracted_regulations": [
    {{
      "regulation": "Name of regulation/law/standard",
      "jurisdiction": "Geographical or industry scope",
      "description": "Brief description of requirement",
      "source_text": "Direct quote from content",
      "confidence": "high/medium/low"
    }}
  ],
  "compliance_requirements": [
    {{
      "requirement": "Specific compliance requirement",
      "description": "What must be done",
      "source_text": "Direct quote from content", 
      "confidence": "high/medium/low"
    }}
  ],
  "relevance_score": 0.0-1.0
}}
""",

    "cost_considerations": """Extract factual information about COSTS & PRICING from this content about {query}.

URL: {url}

INSTRUCTIONS:
1. ONLY extract VERIFIED facts about pricing, costs, budgets, TCO, ROI, and financial considerations
2. Format each fact with:
   - The specific cost information
   - Direct quote from the content supporting the fact
   - Confidence rating (high/medium/low)
3. If no cost information is found, indicate this

CONTENT:
{content}

FORMAT YOUR RESPONSE AS JSON:
{{
  "extracted_costs": [
    {{
      "cost_item": "Specific cost element",
      "amount": null,  // Include if available with currency
      "context": "Description of pricing context",
      "source_text": "Direct quote from content",
      "confidence": "high/medium/low"
    }}
  ],
  "pricing_models": [
    {{
      "model_type": "subscription/one-time/usage-based/etc",
      "description": "How the pricing works",
      "source_text": "Direct quote from content",
      "confidence": "high/medium/low"
    }}
  ],
  "relevance_score": 0.0-1.0
}}
""",

    "best_practices": """Extract factual information about BEST PRACTICES from this content about {query}.

URL: {url}

CRITICAL: Your response must be a valid JSON object starting with '{{' and ending with '}}'. Do not include any additional text, explanations, or markdown formatting.

INSTRUCTIONS:
1. ONLY extract VERIFIED best practices, methodologies, and success factors
2. Format each practice with:
   - The specific practice or methodology
   - Direct quote from the content supporting the fact
   - Confidence rating (high/medium/low)
3. If no best practices are found, indicate this

CONTENT:
{content}

FORMAT YOUR RESPONSE AS JSON:
{{
  "extracted_practices": [
    {{
      "practice": "Specific best practice or methodology",
      "description": "Detailed description",
      "source_text": "Direct quote from content",
      "confidence": "high/medium/low"
    }}
  ],
  "methodologies": [
    {{
      "methodology": "Name of methodology",
      "description": "How it works",
      "source_text": "Direct quote from content",
      "confidence": "high/medium/low"
    }}
  ],
  "relevance_score": 0.0-1.0
}}

CRITICAL REQUIREMENTS:
1. Response must be a valid JSON object
2. All fields must be present (even if empty)
3. Use proper data types (strings, numbers, arrays)
4. Never use null values - use empty arrays instead
5. Include source_text for every practice and methodology
6. Assign confidence ratings for every item
7. Calculate relevance_score based on content quality
8. Do not include any text outside the JSON object
9. Do not include comments or trailing commas
10. Use double quotes for all strings
""",

    "implementation_factors": """Extract factual information about IMPLEMENTATION FACTORS from this content about {query}.

URL: {url}

INSTRUCTIONS:
1. ONLY extract VERIFIED facts about implementation challenges, success factors, and considerations
2. Format each factor with:
   - The specific implementation factor
   - Direct quote from the content supporting the fact
   - Confidence rating (high/medium/low)
3. If no implementation information is found, indicate this

CONTENT:
{content}

FORMAT YOUR RESPONSE AS JSON:
{{
  "extracted_factors": [
    {{
      "factor": "Specific implementation factor",
      "description": "Detailed description",
      "source_text": "Direct quote from content",
      "confidence": "high/medium/low"
    }}
  ],
  "challenges": [
    {{
      "challenge": "Specific implementation challenge",
      "description": "What makes it challenging",
      "source_text": "Direct quote from content",
      "confidence": "high/medium/low"
    }}
  ],
  "relevance_score": 0.0-1.0
}}
"""
}

# Enhanced synthesis prompt with better structure
SYNTHESIS_PROMPT: Final[str] = """Create a comprehensive synthesis of research findings for: {query}

REQUIREMENTS:
1. Structure your synthesis with these EXACT sections:
   - Domain Overview: Essential context and background
   - Market Dynamics: Size, growth, trends, competition
   - Provider Landscape: Key vendors and their positioning
   - Technical Requirements: Specifications and standards
   - Regulatory Landscape: Compliance and legal requirements
   - Implementation Factors: Resources, process, challenges
   - Cost Considerations: Pricing, ROI, financial factors
   - Best Practices: Recommended approaches

2. For EACH section:
   - Synthesize insights from multiple sources when available
   - Address inconsistencies and note knowledge gaps
   - Include SPECIFIC facts with proper citations
   - Present balanced perspectives where there are differences
   - Prioritize VERIFIED information from authoritative sources
   - If information is missing for any section, explicitly note this

3. For "Confidence Assessment":
   - Evaluate information completeness for each section
   - Identify potential biases in the sources
   - Note limitations in the research
   - Assign justified confidence scores by section

AVAILABLE RESEARCH:
{research_json}

FORMAT RESPONSE AS JSON:
{{
  "synthesis": {{
    "domain_overview": {{ "content": "", "citations": [] }},
    "market_dynamics": {{ "content": "", "citations": [] }},
    "provider_landscape": {{ "content": "", "citations": [] }},
    "technical_requirements": {{ "content": "", "citations": [] }},
    "regulatory_landscape": {{ "content": "", "citations": [] }},
    "implementation_factors": {{ "content": "", "citations": [] }},
    "cost_considerations": {{ "content": "", "citations": [] }},
    "best_practices": {{ "content": "", "citations": [] }}
  }},
  "confidence_assessment": {{
    "overall_score": 0.0-1.0,
    "section_scores": {{
      "domain_overview": 0.0-1.0,
      "market_dynamics": 0.0-1.0,
      "provider_landscape": 0.0-1.0,
      "technical_requirements": 0.0-1.0,
      "regulatory_landscape": 0.0-1.0,
      "implementation_factors": 0.0-1.0,
      "cost_considerations": 0.0-1.0,
      "best_practices": 0.0-1.0
    }},
    "limitations": [],
    "knowledge_gaps": []
  }}
}}

REMEMBER:
- Prioritize factual accuracy over comprehensiveness
- Only include claims that are supported by the research
- Use clear, concise language focused on business impact
- Highlight conflicting information when present
"""

# Enhanced validation prompt with adaptive thresholds
VALIDATION_PROMPT: Final[str] = """Validate the research synthesis against these criteria:

VALIDATION CRITERIA:
1. Factual Accuracy
   - Does each claim have proper citation?
   - Are the citations from credible sources?
   - Are claims consistent with the source material?

2. Comprehensive Coverage
   - Are all required sections populated?
   - Is the depth appropriate for each section?
   - Are there any significant knowledge gaps?

3. Source Quality
   - Are sources diverse and authoritative?
   - Are recent sources used where appropriate?
   - Is there over-reliance on any single source?

4. Overall Quality
   - Is confidence assessment realistic?
   - Are limitations properly acknowledged?
   - Is the synthesis balanced and objective?

RESEARCH SYNTHESIS TO VALIDATE:
{synthesis_json}

FORMAT RESPONSE AS JSON:
{{
  "validation_results": {{
    "is_valid": true/false,
    "validation_score": 0.0-1.0,
    "section_validations": {{
      "domain_overview": {{ "is_valid": true/false, "issues": [] }},
      "market_dynamics": {{ "is_valid": true/false, "issues": [] }},
      "provider_landscape": {{ "is_valid": true/false, "issues": [] }},
      "technical_requirements": {{ "is_valid": true/false, "issues": [] }},
      "regulatory_landscape": {{ "is_valid": true/false, "issues": [] }},
      "implementation_factors": {{ "is_valid": true/false, "issues": [] }},
      "cost_considerations": {{ "is_valid": true/false, "issues": [] }},
      "best_practices": {{ "is_valid": true/false, "issues": [] }}
    }},
    "critical_issues": [],
    "improvement_suggestions": []
  }},
  "adaptive_threshold": {{
    "minimum_valid_sections": 0-8,
    "required_sections": [],
    "section_weights": {{
      "domain_overview": 0.0-1.0,
      "market_dynamics": 0.0-1.0,
      "provider_landscape": 0.0-1.0,
      "technical_requirements": 0.0-1.0,
      "regulatory_landscape": 0.0-1.0,
      "implementation_factors": 0.0-1.0,
      "cost_considerations": 0.0-1.0,
      "best_practices": 0.0-1.0
    }}
  }}
}}

IMPORTANT:
- Calculate "minimum_valid_sections" based on query complexity and available data
- Identify critical sections as "required_sections" based on query intent
- Assign weights to sections based on importance to the query
- A synthesis can be valid even with some sections incomplete if priority sections are solid
- Flag fabricated or unsupported claims as critical issues
"""

# Enhanced report template with executive summary format
REPORT_TEMPLATE: Final[str] = """
# Research Report: {query}

## Executive Summary
{executive_summary}

## Key Findings
{key_findings}

## Detailed Analysis

### Market Dynamics
{market_dynamics}

### Provider Landscape
{provider_landscape}

### Technical Requirements
{technical_requirements}

### Regulatory Landscape
{regulatory_landscape}

### Implementation Considerations
{implementation_factors}

### Cost Analysis
{cost_considerations}

### Best Practices
{best_practices}

## Recommendations
{recommendations}

## Sources and Citations
{sources}

---
Confidence Score: {confidence_score}
Generated: {generation_date}
"""

# Enhanced clarity request prompt
CLARIFICATION_PROMPT: Final[str] = """I'm analyzing your research request: "{query}"

Based on my initial analysis, I need some additional context to provide you with the most relevant research.

What I understand so far:
- Product/Service Focus: {product_vs_service}
- Industry Context: {industry_context}
- Geographical Scope: {geographical_focus}

To deliver more precise and comprehensive research, I need clarification on:

{missing_sections}

Could you please provide these additional details? This will help me focus the research on your specific needs rather than making assumptions.

Even with partial clarification, I can begin the research process and refine as we go."""

# Category-specific search quality thresholds
SEARCH_QUALITY_THRESHOLDS: Dict[str, Dict[str, float]] = {
    "market_dynamics": {
        "min_sources": 3,
        "min_facts": 5,
        "recency_threshold_days": 180,  # Market data needs to be recent
        "authoritative_source_ratio": 0.5  # At least half from authoritative sources
    },
    "provider_landscape": {
        "min_sources": 3,
        "min_facts": 3,
        "recency_threshold_days": 365,
        "authoritative_source_ratio": 0.3
    },
    "technical_requirements": {
        "min_sources": 2,
        "min_facts": 3,
        "recency_threshold_days": 730,  # Technical specs can be older
        "authoritative_source_ratio": 0.7  # Need highly authoritative sources
    },
    "regulatory_landscape": {
        "min_sources": 2,
        "min_facts": 2,
        "recency_threshold_days": 730,
        "authoritative_source_ratio": 0.8  # Regulatory info needs official sources
    },
    "cost_considerations": {
        "min_sources": 2,
        "min_facts": 3,
        "recency_threshold_days": 365,  # Pricing should be recent
        "authoritative_source_ratio": 0.4
    },
    "best_practices": {
        "min_sources": 2,
        "min_facts": 3,
        "recency_threshold_days": 730,
        "authoritative_source_ratio": 0.5
    },
    "implementation_factors": {
        "min_sources": 2,
        "min_facts": 3,
        "recency_threshold_days": 730,
        "authoritative_source_ratio": 0.4
    }
}

# Helper function for creating category-specific search prompts
def get_extraction_prompt(category: str, query: str, url: str, content: str) -> str:
    """Get the appropriate extraction prompt for a specific category."""
    if category in EXTRACTION_PROMPTS:
        prompt = EXTRACTION_PROMPTS[category]
        return prompt.format(
            query=query,
            url=url,
            content=content
        )
    else:
        # Fallback to general extraction prompt
        prompt = EXTRACTION_PROMPTS["market_dynamics"]
        return prompt.format(
            query=query,
            url=url,
            content=content
        )

# Prompt for identifying additional research topics
ADDITIONAL_TOPICS_PROMPT: Final[str] = """Based on the current research findings, identify additional topics that would enhance the analysis.

Current Research:
{current_research}

Consider:
1. Related market segments or industries
2. Emerging technologies or trends
3. Regulatory or compliance areas
4. Implementation considerations
5. Cost factors
6. Best practices

Format your response as JSON:
{
    "additional_topics": [
        {
            "topic": "Topic name",
            "relevance": 0.0-1.0,
            "rationale": "Why this topic is important"
        }
    ],
    "priority_order": ["topic1", "topic2", ...],
    "estimated_effort": {
        "topic1": "high/medium/low",
        "topic2": "high/medium/low",
        ...
    }
}"""

# Base research prompt
RESEARCH_BASE_PROMPT: Final[str] = """You are a Research Agent focused on gathering comprehensive market intelligence.

Your task is to analyze the following query and provide detailed research findings.

Query: {query}

INSTRUCTIONS:
1. Break down the query into research components
2. Identify key areas for investigation
3. Gather relevant market data
4. Analyze trends and patterns
5. Synthesize findings

RESPONSE FORMAT:
{
    "research_components": ["Component 1", "Component 2"],
    "key_findings": ["Finding 1", "Finding 2"],
    "sources": ["Source 1", "Source 2"],
    "confidence_score": 0.0
}"""

# Research agent prompt
RESEARCH_AGENT_PROMPT: Final[str] = """You are an advanced Research Agent specialized in market analysis.

Your task is to conduct comprehensive research on the following topic.

Topic: {topic}

INSTRUCTIONS:
1. Identify key research areas
2. Gather market intelligence
3. Analyze trends and patterns
4. Evaluate sources and credibility
5. Synthesize findings

RESPONSE FORMAT:
{
    "research_areas": ["Area 1", "Area 2"],
    "findings": ["Finding 1", "Finding 2"],
    "sources": ["Source 1", "Source 2"],
    "confidence_score": 0.0
}"""

# Topics prompt
TOPICS_PROMPT: Final[str] = """Analyze the following query to identify key research topics.

Query: {query}

INSTRUCTIONS:
1. Break down the query into main topics
2. Identify subtopics for each main topic
3. Prioritize topics by relevance
4. Consider industry context
5. Note any specialized areas

RESPONSE FORMAT:
{
    "main_topics": ["Topic 1", "Topic 2"],
    "subtopics": {
        "Topic 1": ["Subtopic 1", "Subtopic 2"],
        "Topic 2": ["Subtopic 1", "Subtopic 2"]
    },
    "priority_order": ["Topic 1", "Topic 2"],
    "specialized_areas": ["Area 1", "Area 2"]
}"""

# Add a function to provide default empty responses
def get_default_extraction_result(category: str) -> Dict[str, Any]:
    """Get a default empty extraction result when parsing fails."""
    defaults = {
        "market_dynamics": {
            "extracted_facts": [],
            "market_metrics": {
                "market_size": None,
                "growth_rate": None,
                "forecast_period": None
            },
            "relevance_score": 0.0
        },
        "provider_landscape": {
            "extracted_vendors": [],
            "vendor_relationships": [],
            "relevance_score": 0.0
        },
        "technical_requirements": {
            "extracted_requirements": [],
            "standards": [],
            "relevance_score": 0.0
        },
        "regulatory_landscape": {
            "extracted_regulations": [],
            "compliance_requirements": [],
            "relevance_score": 0.0
        },
        "cost_considerations": {
            "extracted_costs": [],
            "pricing_models": [],
            "relevance_score": 0.0
        },
        "best_practices": {
            "extracted_practices": [],
            "methodologies": [],
            "relevance_score": 0.0
        },
        "implementation_factors": {
            "extracted_factors": [],
            "challenges": [],
            "relevance_score": 0.0
        }
    }
    
    return defaults.get(category, {"extracted_facts": [], "relevance_score": 0.0})

# Export all prompts and utilities
__all__ = [
    "STRUCTURED_OUTPUT_VALIDATION",
    "QUERY_ANALYSIS_PROMPT",
    "EXTRACTION_PROMPTS",
    "SYNTHESIS_PROMPT",
    "VALIDATION_PROMPT",
    "REPORT_TEMPLATE",
    "CLARIFICATION_PROMPT",
    "SEARCH_QUALITY_THRESHOLDS",
    "get_extraction_prompt",
    "get_default_extraction_result",
    "ADDITIONAL_TOPICS_PROMPT",
    "RESEARCH_BASE_PROMPT",
    "RESEARCH_AGENT_PROMPT",
    "TOPICS_PROMPT"
]
</file>

<file path="src/react_agent/prompts/templates.py">
"""Main prompt templates.

This module provides functionality for main prompt templates
in the agent framework.
"""

from typing import Final

# Common validation template used across multiple prompts
STRUCTURED_OUTPUT_VALIDATION: Final[str] = """CRITICAL: All responses MUST:
1. Be valid JSON only - no additional text or comments
2. Follow the exact schema provided
3. Never return empty or null values
4. Include all required fields
5. Use proper data types (strings, numbers, arrays)
6. Maintain proper JSON syntax
7. Include citations for all data points
8. Pass JSON schema validation

Any response that fails these requirements will be rejected."""

# Validation requirements component - reusable across prompts
VALIDATION_REQUIREMENTS: Final[str] = """VALIDATION REQUIREMENTS:
1. Structural Validation
   - Verify JSON syntax is valid
   - Check all required fields are present
   - Ensure no empty or null values
   - Validate data types match schema
   - Check array elements follow required format

2. Citation Validation
   - Verify each citation URL exists and is accessible
   - Ensure at least 2 citations per analysis section
   - Validate source credibility and relevance
   - Cross-reference data points across sources"""

# Main prompt for the primary agent
MAIN_PROMPT: Final[
    str
] = """You are conducting web research for RFP category analysis and market basket development.
Your goal is to produce a structured JSON response following this exact schema:
{
    "rfp_analysis": {
        "analysis": {
            "porters_5_forces": {
                "competitive_rivalry": "",
                "threat_of_new_entrants": "",
                "threat_of_substitutes": "",
                "bargaining_power_buyers": "",
                "bargaining_power_suppliers": ""
            },
            "swot": {
                "strengths": [],
                "weaknesses": [],
                "opportunities": [],
                "threats": []
            },
            "recent_breakthroughs_and_disruptors": "",
            "cost_trends_and_projections": "",
            "typical_contract_clauses_and_pricing_nuances": "",
            "competitive_landscape": ""
        },
        "market_basket": [
            {
                "manufacturer_or_distributor": "",
                "item_number": "",
                "item_description": "",
                "uom": "",
                "estimated_qty_per_uom": 0.0,
                "unit_cost": 0.0
            }
        ]
    },
    "confidence_score": 0.0
}
Category to analyze: {topic}
IMPORTANT INSTRUCTIONS:
1. Your response must be ONLY valid JSON - no additional text, comments or explanations
2. Every field must be populated - no empty strings or null values
3. If you cannot structure some information, include it under a "raw_findings" key
4. Do not truncate or leave responses incomplete
5. Ensure all JSON syntax is valid (quotes, commas, brackets)
Available tools:
1. Search: Query search engines for industry and market information
2. ScrapeWebsite: Extract structured data from industry sources
3. SummarizeResearch: Generate AI-powered summaries for complex topics
4. SearchNews: Find recent news articles and industry developments
5. Info: Compile and format final findings
"""

# Tool descriptions
WEB_SEARCH_DESC: Final[str] = """Search the web for information about a topic.
Input should be a search query string.
Returns up to 3 search results with titles, URLs, and snippets."""

SCRAPE_DESC: Final[str] = """Scrape content from a website URL.
Input should be a valid URL.
Returns the scraped content and metadata."""

# New tool descriptions for Brave Summarizer and News APIs
SUMMARIZER_DESC: Final[
    str
] = """Generate an AI-powered summary of search results for a topic.
Input should be a search query string.
Returns a comprehensive summary along with key topics and 5 source articles."""

NEWS_SEARCH_DESC: Final[str] = """Search for recent news articles related to a topic.
Input should be a search query string.
Returns 5 news articles with titles, URLs, descriptions, and sources."""

# Tool instructions for reuse across agent nodes
TOOL_INSTRUCTIONS: Final[str] = """
IMPORTANT:
1. Use the search_web tool to find relevant information (returns 3 results per query)
2. Use the search_news tool for recent developments and news (returns 5 results per query)
3. Use the scrape_website tool to extract detailed content from websites
4. Use the summarize_research tool to get AI-powered summaries of complex topics (returns 5 sources per query)
5. Always include proper citations for all information
6. Follow all research requirements in the prompt
"""

# Evaluation prompt template for content evaluation
EVALUATION_PROMPT_TEMPLATE: Final[
    str
] = """You are an evaluation system that assesses the quality of AI responses.
Review the following response and provide scores and feedback.

Task description: {task_description}

Response to evaluate:
{response}

Please evaluate this response on these criteria: {criteria}.
For each criterion, provide a score from 0.0 to 1.0 and brief feedback."""

# Reflection prompt templates
FEEDBACK_PROMPT_TEMPLATE: Final[str] = """You are an AI improvement coach.
Based on the critique and evaluation of a previous response, generate actionable feedback 
to help improve future responses.

Original task: {task}

Previous response: {response}

Critique: {critique}

Evaluation scores: {scores}

Generate specific, actionable feedback with examples of how to improve."""

CRITIQUE_PROMPT_TEMPLATE: Final[str] = """You are an expert evaluator providing critique.
Review the following response and provide detailed feedback.

Task: {task}
Response: {response}
Evaluation criteria: {criteria}

Provide specific critique points and actionable suggestions for improvement."""

ANALOGICAL_REASONING_PROMPT: Final[str] = """You are an expert at improving solutions through analogical reasoning.

Current task: {task}
Current response: {response}
Similar examples:
{examples}

Based on these examples, suggest improvements to the current response."""

COUNTERFACTUAL_PROMPT: Final[str] = """You are an expert at generating counterfactual improvements.
Consider 'what if' scenarios that could lead to better outcomes.

Current response: {response}
Areas for improvement: {areas}

Generate counterfactual scenarios and corresponding improvements."""

METACOGNITION_PROMPT: Final[str] = """You are an expert at analyzing thinking processes and cognitive patterns.
Identify patterns, biases, and potential improvements in the reasoning process.

Conversation history: {history}
Current scores: {scores}
Improvement areas: {areas}

Analyze the thinking process and suggest meta-level improvements."""

# Detailed feedback prompt templates
DETAILED_FEEDBACK_PROMPT: Final[str] = """You are an AI improvement coach providing detailed feedback.
Review the following response and generate specific, actionable feedback.

CONTEXT:
Original task: {task}
Previous response: {response}
Critique points: {critique}
Current scores: {scores}

REQUIREMENTS:
1. Provide specific examples of what could be improved
2. Suggest concrete implementation steps
3. Reference similar successful approaches
4. Highlight both strengths and areas for improvement
5. Maintain constructive and actionable tone

Generate detailed, actionable feedback that addresses:
1. Content quality and accuracy
2. Structure and organization
3. Completeness and depth
4. Implementation and practicality
5. Overall effectiveness"""

REFLECTION_FEEDBACK_PROMPT: Final[str] = """You are an AI reflection coach.
Help improve responses through structured reflection and feedback.

CONTEXT:
Task description: {task}
Current response: {response}
Evaluation scores: {scores}
Areas for improvement: {areas}

REFLECTION POINTS:
1. What worked well in the current approach?
2. What could have been done differently?
3. How can we apply lessons from similar successful cases?
4. What specific steps would lead to better outcomes?

Provide actionable feedback focusing on:
1. Strategic improvements
2. Tactical adjustments
3. Process refinements
4. Quality enhancements"""

STRUCTURED_SYSTEM_PROMPT: Final[str] = """You are a helpful assistant that can answer questions and help with tasks."""

SYSTEM_PROMPT: Final[str] = """You are a helpful assistant that can answer questions and help with tasks."""
</file>

<file path="src/react_agent/prompts/validation.py">
"""Validation-specific prompts.

This module provides functionality for validation-specific prompts
in the agent framework.
"""

from typing import Final

# Validation base prompt
VALIDATION_BASE_PROMPT: Final[
    str
] = """You are a Validation Agent for RFP market analysis.
Your goal is to prevent hallucinations and ensure data quality.

{VALIDATION_REQUIREMENTS}

3. Content Validation
   - Verify all required fields are populated
   - Check for data consistency across sections
   - Validate numerical data and calculations
   - Ensure analysis conclusions are supported by data

4. Market Basket Validation
   - Verify product information accuracy
   - Cross-check pricing against multiple sources
   - Validate manufacturer/distributor details
   - Ensure proper unit of measure conversions

5. Analysis Quality
   - Verify PESTEL factors are comprehensive
   - Check GAP analysis identifies clear needs
   - Validate cost-benefit calculations
   - Review risk assessment completeness
   - Cross-check TCO components
   - Verify vendor analysis objectivity
   - Check benchmarking methodology
   - Validate stakeholder identification
   - Ensure compliance requirements are current
   - Verify business impact assessments

CONFIDENCE SCORING:
- Start with base score of 0.4
- Add 0.1 for each validated section with 2+ citations
- Add 0.1 for each verified market basket item
- Add 0.1 for comprehensive analysis coverage
- Subtract 0.1 for each validation failure
- Reject if final score < 0.98

RESPONSE_FORMAT:
{
    "validation_results": {
        "is_valid": false,
        "errors": [],
        "warnings": [],
        "confidence_score": 0.0,
        "section_scores": {
            "structural": 0.0,
            "citations": 0.0,
            "content": 0.0,
            "market_basket": 0.0
        },
        "failed_validations": [],
        "required_fixes": []
    }
}

Current state: {state}
"""

# Validation agent prompt with structured output validation
VALIDATION_AGENT_PROMPT: Final[str] = VALIDATION_BASE_PROMPT.replace(
    "Your goal is to prevent hallucinations and ensure data quality.\n",
    "Your goal is to prevent hallucinations and ensure data quality.\n\n{STRUCTURED_OUTPUT_VALIDATION}\n",
)

# Prompt for generating validation criteria
VALIDATION_CRITERIA_PROMPT: Final[str] = """
Content Type: {content_type}
Generate appropriate validation criteria for content of this type.
The criteria should be comprehensive and tailored to the specific content type.
For example:
- For research content: factual accuracy, source credibility, logical consistency
- For analysis content: methodological soundness, statistical validity, interpretative accuracy
- For code: functional correctness, efficiency, security, readability

Format your response as a JSON object with these fields:
- primary_criteria: List of primary validation criteria (string[])
- secondary_criteria: List of secondary validation criteria (string[])
- critical_requirements: List of must-have elements (string[])
- disqualifying_factors: List of automatic disqualifiers (string[])
- scoring_weights: Dictionary mapping criteria to weights (0.0 to 1.0)
"""

# Prompt for fact checking
FACT_CHECK_CLAIMS_PROMPT: Final[str] = """
Content Type: {content_type}
Analyze the following content for factual accuracy of claims:
{content}

1. Identify claims that are factual, opinion-based, unclear, or contradictory.
2. Provide source citations for each claim.
3. Evaluate the credibility of sources.
4. Verify the accuracy of each claim.
5. Determine if the content as a whole is factually accurate.
6. Identify any potential biases or conflicts of interest.
7. Note any areas where more research is needed.

Respond in JSON format with these fields:
- factually_accurate_claims: string[] (list of factual claims)
- opinion_based_claims: string[] (list of opinion-based claims)
- unclear_claims: string[] (list of unclear claims)
- source_citations: string[] (list of source URLs for each claim)
- source_credibility: string[] (list of source credibility scores)
- verification_results: string[] (list of verification results)
- overall_accuracy: number from 0-10
- potential_biases: string[] (list of potential biases)
- areas_for_future_research: string[] (list of areas for future research)
- issues: string[] (summarizing all critical issues)
"""

# Prompt for validating individual claims
VALIDATE_CLAIM_PROMPT: Final[str] = """
Fact check the following claim:
CLAIM: {claim}

Respond in JSON format with these fields:
- accuracy: number from 0-10
- confidence: number from 0-10
- issues: string[] (empty if no issues)
- verification_notes: string
"""

# Prompt for logic validation
LOGIC_VALIDATION_PROMPT: Final[str] = """
Content Type: {content_type}
Validate the logical consistency, reasoning quality, and argument structure of the following content:
{content}

Analyze for:
1. Valid argument structure (premises, conclusions)
2. Logical fallacies (e.g., circular reasoning, false cause)
3. Consistency between claims
4. Quality of evidence and reasoning
5. Appropriate conclusions

Respond in JSON format with these fields:
- logical_structure_score: number from 0-10
- fallacies_found: string[] (empty if none)
- consistency_issues: string[] (empty if none)
- reasoning_quality: number from 0-10
- conclusion_validity: number from 0-10
- overall_score: number from 0-10
- issues: string[] (summarizing all critical issues)
"""

# Prompt for consistency checking
CONSISTENCY_CHECK_PROMPT: Final[str] = """
Content Type: {content_type}
Check the internal consistency and coherence of the following content:
{content}

Analyze for:
1. Consistency between different sections
2. Coherence of narrative or explanation
3. Presence of contradictions
4. Logical flow and structure
5. Completeness (no missing pieces in the reasoning)

Respond in JSON format with these fields:
- section_consistency: number from 0-10
- coherence_score: number from 0-10
- contradictions: string[] (empty if none)
- flow_quality: number from 0-10
- completeness: number from 0-10
- overall_score: number from 0-10
- issues: string[] (summarizing all critical issues)
- needs_human_review: boolean (true if human review is recommended)
"""

# Prompt for human feedback request
HUMAN_FEEDBACK_PROMPT: Final[str] = """
Content Type: {content_type}
Based on automated validation, the following issues were identified:
{issues}

Generate 3-5 specific questions for human reviewers to address these issues.
Questions should be clear, focused, and help improve the quality of the content.
Additionally, suggest specific sections or aspects that need human attention.

Format your response as JSON with these fields:
- questions: string[] (list of questions)
- focus_areas: string[] (specific aspects needing review)
- content_summary: string (brief summary of the content)
"""
</file>

<file path="src/react_agent/tools/jina.py">
"""Enhanced Jina AI Search Integration.

This module provides a more robust integration with Jina AI's search API
with improved error handling, result validation, and search strategies.
"""


from typing import Dict, List, Optional, Any, Union, cast
import json
import time
import aiohttp
import asyncio
import contextlib
from urllib.parse import urljoin, quote
import random
from datetime import datetime

from langchain_core.documents import Document
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import InjectedToolArg
from typing_extensions import Annotated, Literal

from react_agent.configuration import Configuration
from react_agent.utils.logging import get_logger, log_dict, info_highlight, warning_highlight, error_highlight
from react_agent.utils.validations import is_valid_url

# Initialize logger
logger = get_logger(__name__)

# Define search types for specialized search strategies
SearchType = Literal["general", "authoritative", "recent", "comprehensive", "technical"]

class RetryConfig:
    """Configuration for retry behavior."""
    def __init__(
        self,
        max_retries: int = 3,
        base_delay: float = 1.0,
        max_delay: float = 30.0,
        jitter: bool = True,
    ):
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.max_delay = max_delay
        self.jitter = jitter

    def get_delay(self, attempt: int) -> float:
        """Calculate delay with exponential backoff and optional jitter."""
        delay = min(self.max_delay, self.base_delay * (2 ** (attempt - 1)))
        if self.jitter:
            delay = delay * (0.5 + random.random())
        return delay

class SearchParams:
    """Parameters for search operations."""
    def __init__(
        self,
        query: str,
        search_type: SearchType = "general",
        max_results: int = 10,
        min_quality_score: float = 0.5,
        recency_days: Optional[int] = None,
        domains: Optional[List[str]] = None,
        exclude_domains: Optional[List[str]] = None,
    ):
        self.query = query
        self.search_type = search_type
        self.max_results = max_results
        self.min_quality_score = min_quality_score
        self.recency_days = recency_days
        self.domains = domains or []
        self.exclude_domains = exclude_domains or []

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for API request."""
        # Clean and encode the query
        cleaned_query = self.query.replace('\n', ' ').replace('\r', ' ').strip()
        # Remove any "Additional context" or similar prefixes
        cleaned_query = cleaned_query.split("Additional context:")[0].strip()
        # Limit query length to avoid issues
        cleaned_query = cleaned_query[:200] if len(cleaned_query) > 200 else cleaned_query
        
        result = {
            "q": quote(cleaned_query),
            "limit": self.max_results
        }

        # Add search type specific parameters
        if self.search_type == "authoritative":
            # Increase authority weight
            result["authority_boost"] = 2.0
            if self.domains:
                result["domains"] = ",".join(self.domains)

        elif self.search_type == "comprehensive":
            # Increase diversity
            result["diversity"] = 2.0

        elif self.search_type == "recent":
            # Add recency filter
            result["recency_days"] = self.recency_days or 30
        elif self.search_type == "technical":
            # Focus on technical content
            result["content_type"] = "technical"

        # Add domain filters if not already added
        if self.domains and "domains" not in result:
            result["domains"] = ",".join(self.domains)

        if self.exclude_domains:
            result["exclude_domains"] = ",".join(self.exclude_domains)

        return result

class JinaSearchClient:
    """Enhanced client for Jina AI search with retry and validation."""
    
    def __init__(
        self,
        api_key: str,
        base_url: Optional[str] = None,
        retry_config: Optional[RetryConfig] = None,
    ):
        """Initialize Jina search client.
        
        Args:
            api_key: Jina AI API key
            base_url: Optional base URL for self-hosted instances
            retry_config: Configuration for retry behavior
        """
        self.api_key = api_key
        self.base_url = base_url.rstrip('/') if base_url else "https://s.jina.ai"
        self.retry_config = retry_config or RetryConfig()
        self.session: Optional[aiohttp.ClientSession] = None
        
    async def __aenter__(self):
        """Create aiohttp session."""
        self.session = aiohttp.ClientSession(
            headers={
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
                "Accept": "application/json"
            }
        )
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Close aiohttp session."""
        if self.session:
            await self.session.close()
            self.session = None

    def _get_endpoint(self, endpoint: str) -> str:
        """Get endpoint URL."""
        base = self.base_url.rstrip('/')
        if not endpoint.startswith('/'):
            endpoint = f'/{endpoint}'
        return f"{base}{endpoint}"

    async def _make_request_with_retry(
        self,
        method: str,
        endpoint: str,
        params: Optional[Dict[str, Any]] = None,
        json_data: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Make HTTP request to Jina API with retry logic."""
        if not self.session:
            raise ValueError("Session not initialized")

        last_exception = None
        for attempt in range(1, self.retry_config.max_retries + 1):
            try:
                url = self._get_endpoint(endpoint)
                info_highlight(f"Making request to: {url} with params: {params}")
                
                async with self.session.request(
                    method=method,
                    url=url,
                    params=params,
                    json=json_data
                ) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        error_highlight(f"Request failed with status {response.status}: {error_text}")
                        raise aiohttp.ClientError(f"Request failed with status {response.status}: {error_text}")
                    
                    return await response.json()
            except Exception as e:
                last_exception = e
                if attempt < self.retry_config.max_retries:
                    delay = self.retry_config.get_delay(attempt)
                    warning_highlight(
                        f"Request failed (attempt {attempt}/{self.retry_config.max_retries}): {str(last_exception)}. Retrying in {delay:.2f}s"
                    )
                    await asyncio.sleep(delay)
                else:
                    error_highlight(
                        f"Request failed after {self.retry_config.max_retries} attempts: {str(last_exception)}"
                    )
                    raise

        # This should never be reached as the last failure should raise
        assert last_exception is not None
        raise last_exception

    async def search(
        self,
        params: SearchParams
    ) -> List[Document]:
        """Search with improved parameters and result validation.
        
        Args:
            params: Search parameters
            
        Returns:
            List of documents from search results
        """
        request_params = params.to_dict()
        info_highlight(f"Executing {params.search_type} search with query: {params.query}")
        
        try:
            # Use the search endpoint
            data = await self._make_request_with_retry(
                method="GET",
                endpoint="/search",  # Use the search endpoint
                params=request_params
            )
            
            results = self._parse_search_results(data)
            info_highlight(f"Retrieved {len(results)} search results")
            
            # Convert results to Documents
            documents = self._convert_to_documents(results)
            
            # Apply quality filtering
            filtered_docs = self._filter_documents(documents, params.min_quality_score)
            info_highlight(f"Filtered to {len(filtered_docs)} high-quality results")
            
            return filtered_docs
        except Exception as e:
            error_highlight(f"Search failed: {str(e)}")
            return []

    def _parse_search_results(self, raw_results: Union[str, List[Dict], Dict]) -> List[Dict]:
        """Parse raw results with improved error handling."""
        try:
            if isinstance(raw_results, str):
                try:
                    # Try to parse as JSON first
                    parsed = json.loads(raw_results)
                except json.JSONDecodeError:
                    # If not valid JSON, try to clean and parse again
                    cleaned = raw_results.strip()
                    if cleaned.startswith('```json'):
                        cleaned = cleaned[7:]
                    if cleaned.endswith('```'):
                        cleaned = cleaned[:-3]
                    try:
                        parsed = json.loads(cleaned)
                    except json.JSONDecodeError as e:
                        error_highlight(f"Failed to parse JSON results: {str(e)}")
                        return []
                return self._extract_results_list(parsed)
            elif isinstance(raw_results, (list, dict)):
                return self._extract_results_list(raw_results)
            else:
                warning_highlight(f"Unexpected result type: {type(raw_results)}")
                return []
        except Exception as e:
            error_highlight(f"Error parsing search results: {str(e)}")
            return []

    def _extract_results_list(self, data: Union[List[Dict], Dict]) -> List[Dict]:
        """Extract results list from various response formats."""
        try:
            if isinstance(data, list):
                return data
            elif isinstance(data, dict):
                # Try common response formats
                for key in ['results', 'data', 'items', 'hits', 'matches', 'documents', 'response']:
                    if key in data:
                        if isinstance(data[key], list):
                            return data[key]
                        elif isinstance(data[key], dict):
                            # Try to extract from nested structure
                            for nested_key in ['results', 'data', 'items', 'hits', 'matches']:
                                if nested_key in data[key] and isinstance(data[key][nested_key], list):
                                    return data[key][nested_key]
                
                # If no list found, try to extract single result
                if 'result' in data:
                    return [data['result']]
                
                # If still no results, try to extract from nested structure
                for value in data.values():
                    if isinstance(value, list):
                        return value
                    elif isinstance(value, dict):
                        # Recursively try to extract from nested dictionaries
                        nested_results = self._extract_results_list(value)
                        if nested_results:
                            return nested_results
                
                # If still no results, return empty list
                return []
            return []
        except Exception as e:
            error_highlight(f"Error extracting results list: {str(e)}")
            return []

    def _convert_to_documents(self, results: List[Dict]) -> List[Document]:
        """Convert search results to Document objects with improved metadata."""
        documents = []
        
        for idx, result in enumerate(results):
            try:
                if not isinstance(result, dict):
                    continue
                    
                # Extract content with fallbacks
                content = None
                for field in ['snippet', 'content', 'text', 'description', 'summary', 'body', 'raw']:
                    if field in result and result[field]:
                        content = result[field]
                        if content:
                            info_highlight(f"Found content in field '{field}' for result {idx + 1}")
                            break
                
                if not content:
                    warning_highlight(f"No content found for result {idx + 1}")
                    continue
                    
                # Build metadata with comprehensive information
                metadata = {}
                
                # Process field types with logging
                field_mapping = {
                    'url': ['url', 'link', 'href', 'source_url', 'web_url'],
                    'title': ['title', 'name', 'heading', 'subject', 'headline'],
                    'source': ['source', 'domain', 'site', 'provider', 'publisher'],
                    'published_date': ['published_date', 'date', 'timestamp', 'published', 'created_at', 'publication_date']
                }
                
                for field_type, fields in field_mapping.items():
                    for field in fields:
                        if field in result and result[field]:
                            metadata[field_type] = result[field]
                            info_highlight(f"Found {field_type} in field '{field}' for result {idx + 1}")
                            break
                
                # Add content quality estimate
                metadata['quality_score'] = self._calculate_quality_score(result, content)
                
                # Extract domain from URL for filtering
                if 'url' in metadata and metadata['url']:
                    from urllib.parse import urlparse
                    try:
                        parsed_url = urlparse(metadata['url'])
                        metadata['domain'] = parsed_url.netloc
                    except Exception:
                        metadata['domain'] = ""
                    
                # Add original result for debugging
                metadata['original_result'] = result
                
                # Add extraction metadata
                metadata['extraction_status'] = 'success'
                metadata['extraction_timestamp'] = datetime.now().isoformat()
                
                # Clean content if needed
                if isinstance(content, str):
                    content = content.strip()
                    if content.startswith('```json'):
                        content = content[7:]
                    if content.endswith('```'):
                        content = content[:-3]
                
                doc = Document(
                    page_content=content,
                    metadata=metadata
                )
                documents.append(doc)
                info_highlight(f"Successfully converted result {idx + 1} to Document")
            except Exception as e:
                warning_highlight(f"Error converting result {idx + 1} to Document: {str(e)}")
                continue

        return documents

    def _calculate_quality_score(self, result: Dict[str, Any], content: str) -> float:
        """Calculate quality score for a search result."""
        score = 0.5  # Base score

        # Add points for authoritative domains
        authoritative_domains = [
            '.gov', '.edu', '.org', 'wikipedia.org', 
            'research', 'journal', 'university', 'association'
        ]
        url = result.get('url', '')
        if any(domain in url.lower() for domain in authoritative_domains):
            score += 0.2

        # Add points for content length (substantive content)
        if len(content) > 500:
            score += 0.1

        # Add points for having title/publication date
        if result.get('title'):
            score += 0.05
        if result.get('published_date') or result.get('date'):
            score += 0.05

        if date_field := result.get('published_date', result.get('date', '')):
            with contextlib.suppress(Exception):
                # Try to parse date
                from dateutil import parser
                from datetime import datetime, timezone
                published_date = parser.parse(date_field)
                current_date = datetime.now(timezone.utc)
                days_old = (current_date - published_date).days

                # Fresher content gets higher score
                if days_old < 30:  # Last month
                    score += 0.1
                elif days_old < 180:  # Last 6 months
                    score += 0.05
        return min(1.0, score)  # Cap at 1.0

    def _filter_documents(self, documents: List[Document], min_score: float) -> List[Document]:
        """Filter documents based on quality score."""
        return [
            doc for doc in documents 
            if doc.metadata.get('quality_score', 0) >= min_score
        ]

async def search(
    query: str,
    search_type: Optional[SearchType] = None,
    domains: Optional[List[str]] = None,
    recency_days: Optional[int] = None,
    min_quality: Optional[float] = None,
    max_results: Optional[int] = None,
    *,
    config: Annotated[RunnableConfig, InjectedToolArg]
) -> Optional[List[Document]]:
    """Enhanced search with multiple strategies and quality filters.
    
    Args:
        query: The search query string
        search_type: Type of search to perform (general, authoritative, recent, etc.)
        domains: List of domains to include in search
        recency_days: Only include results from the last N days
        min_quality: Minimum quality score for results (0.0-1.0)
        max_results: Maximum number of results to return
        config: Configuration containing API key and settings
        
    Returns:
        Optional[List[Document]]: List of search results as Documents, or None if search fails
    """
    configuration = Configuration.from_runnable_config(config)
    if not configuration.jina_api_key:
        error_highlight("Jina API key is required")
        return None

    # Set environment variables for Jina (used by some libraries)
    import os
    os.environ["JINA_API_KEY"] = configuration.jina_api_key
    if configuration.jina_url:
        os.environ["JINA_URL"] = configuration.jina_url

    # Use provided params or defaults
    params = SearchParams(
        query=query,
        search_type=search_type or "general",
        max_results=max_results or configuration.max_search_results,
        min_quality_score=min_quality or 0.5,
        recency_days=recency_days,
        domains=domains
    )

    # Add default domains for educational/authoritative content if not provided
    if not domains and search_type in ["authoritative", None]:
        params.domains = ['.edu', '.gov', '.org']

    try:
        retry_config = RetryConfig(max_retries=3, base_delay=1.0, max_delay=10.0)
        async with JinaSearchClient(
                    api_key=configuration.jina_api_key,
                    base_url=configuration.jina_url,
                    retry_config=retry_config
                ) as client:
            return await client.search(params)
    except Exception as e:
        error_highlight(f"Search failed: {str(e)}")
        return None

# Helper function to create optimized queries
def optimize_query(original_query: str, category: str, is_higher_ed: bool = True) -> str:
    """Create optimized queries for specific research categories."""
    # Clean the original query
    original_query = original_query.split("Additional context:")[0].strip()
    
    # Define shorter, more focused query templates
    query_templates = {
        "market_dynamics": "{query} market trends analysis",
        "provider_landscape": "{query} vendors suppliers",
        "technical_requirements": "{query} technical specifications",
        "cost_considerations": "{query} pricing cost budget",
        "best_practices": "{query} best practices case studies",
        "regulatory_landscape": "{query} regulations compliance",
        "implementation_factors": "{query} implementation factors"
    }
    
    if category in query_templates:
        template = query_templates[category]
        return template.format(query=original_query)
    else:
        return original_query

# Export available tools
TOOLS = [search]
</file>

<file path="src/react_agent/utils/__init__.py">
from react_agent.utils.validations import is_valid_url
from react_agent.utils.logging import (
    get_logger,
    log_dict,
    info_highlight,
    warning_highlight,
    error_highlight,
    log_step
)

__all__ = [
    "is_valid_url",
    "get_logger",
    "log_dict",
    "info_highlight",
    "warning_highlight",
    "error_highlight",
    "log_step"
]
</file>

<file path="src/react_agent/utils/llm.py">
"""Utility & helper functions."""

import json
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Sequence, cast

from langchain.chat_models import init_chat_model
from langchain_core.language_models import BaseChatModel
from langchain_core.messages import AIMessage, BaseMessage
from langchain_core.prompt_values import PromptValue
from langchain_core.runnables import RunnableConfig
from langchain_core.runnables.base import Runnable

from react_agent.configuration import Configuration
from react_agent.state import State
from react_agent.tools.tavily import TOOLS
from react_agent.utils import (
    get_logger,
    log_dict,
    info_highlight,
    warning_highlight,
    error_highlight,
    log_step
)


def get_message_text(msg: BaseMessage) -> str:
    """Get the text content of a message."""
    content = msg.content
    if isinstance(content, str):
        return content
    elif isinstance(content, dict):
        return content.get("text", "")
    else:
        txts = [c if isinstance(c, str) else (c.get("text") or "") for c in content]
        return "".join(txts).strip()


def load_chat_model(fully_specified_name: str) -> BaseChatModel:
    """Load a chat model from a fully specified name.

    Args:
        fully_specified_name (str): String in the format 'provider/model'.
    """
    provider: str = fully_specified_name.split("/", maxsplit=1)[0]
    model: str = fully_specified_name.split("/", maxsplit=1)[1]
    return init_chat_model(model, model_provider=provider)


async def call_model(
    state: State, config: RunnableConfig
) -> Dict[str, List[AIMessage]]:
    """Call the LLM powering our "agent".

    This function prepares the prompt, initializes the model, and processes the response.

    Args:
        state (State): The current state of the conversation.
        config (RunnableConfig): Configuration for the model run.

    Returns:
        dict: A dictionary containing the model's response message.
    """
    configuration: Configuration = Configuration.from_runnable_config(config)

    # Initialize the model with tool binding. Change the model or add more tools here.
    model: Runnable[PromptValue | str | Sequence[BaseMessage | list[str] | tuple[str, str] | str | dict[str, Any]], BaseMessage] = load_chat_model(configuration.model).bind_tools(TOOLS)

    # Format the system prompt. Customize this to change the agent's behavior.
    system_message = configuration.system_prompt.format(
        system_time=datetime.now(tz=timezone.utc).isoformat()
    )

    # Get the model's response
    response: AIMessage = cast(
        AIMessage,
        await model.ainvoke(
            input=[{"role": "system", "content": system_message}, *state.messages],
            config=config,
        ),
    )

    return {"messages": [response]}


async def call_model_json(
    messages: List[Dict[str, str]],
    config: Optional[RunnableConfig] = None
) -> Dict[str, Any]:
    """Call the LLM and get a JSON response."""
    base_config: RunnableConfig = config or {}
    configuration: Configuration = Configuration.from_runnable_config(base_config)
    model: BaseChatModel = load_chat_model(configuration.model)
    
    # Create a new config dictionary with response format
    model_config = dict(base_config)
    model_config["response_format"] = {"type": "json_object"}
    
    # Add system message to enforce JSON response
    system_message = {
        "role": "system",
        "content": """You are a helpful assistant that always responds with a single, valid JSON object. 
        CRITICAL REQUIREMENTS:
        1. Response must be a valid JSON object starting with '{' and ending with '}'
        2. Do not include any explanations, markdown formatting, or text outside the JSON object
        3. Use proper data types (strings, numbers, arrays, objects)
        4. Never return null values - use empty strings or arrays instead
        5. Include all required fields from the schema
        6. Maintain proper JSON syntax
        7. Do not include comments or trailing commas"""
    }

    # Check content length and truncate if necessary
    MAX_CONTENT_LENGTH = 1000000  # Leave some buffer below the 1MB limit
    for msg in messages:
        if msg["role"] == "human" and len(msg["content"]) > MAX_CONTENT_LENGTH:
            warning_highlight(f"Content too long ({len(msg['content'])} chars), truncating to {MAX_CONTENT_LENGTH} chars")
            # Try to truncate at a sentence boundary
            truncated = msg["content"][:MAX_CONTENT_LENGTH]
            last_period = truncated.rfind('.')
            if last_period > MAX_CONTENT_LENGTH * 0.8:  # Only use period if it's not too far from the end
                truncated = truncated[:last_period + 1]
            msg["content"] = truncated + "\n[Content truncated due to length]"
    
    all_messages = [system_message] + messages
    
    response = await model.ainvoke(
        all_messages,
        config=cast(RunnableConfig, model_config)
    )
    
    content = get_message_text(response)
    
    try:
        # First try direct JSON parsing
        return json.loads(content)
    except json.JSONDecodeError:
        # If that fails, try to extract and clean the JSON
        import re
        
        # Remove any markdown code block syntax
        content = re.sub(r'```(?:json)?\s*|\s*```', '', content)
        
        # Ensure content starts with opening brace
        content = content.lstrip()
        if not content.startswith('{'):
            # If it doesn't start with a brace, but has one later, remove everything before it
            start = content.find('{')
            if start != -1:
                content = content[start:]
            else:
                # If no opening brace, try to add one
                content = '{' + content
        
        # Ensure content ends with closing brace
        if not content.rstrip().endswith('}'):
            # If it doesn't end with a brace, but has one earlier, remove everything after it
            end = content.rfind('}')
            if end != -1:
                content = content[:end+1]
            else:
                # If no closing brace, try to add one
                content = content + '}'
        
        # Clean up the content
        content = re.sub(r'\s+', ' ', content)  # Normalize whitespace
        content = re.sub(r'[^\x20-\x7E]', '', content)  # Remove non-printable chars
        content = re.sub(r',\s*}', '}', content)  # Remove trailing commas
        content = re.sub(r',\s*]', ']', content)  # Remove trailing commas in arrays
        
        try:
            return json.loads(content)
        except json.JSONDecodeError as e:
            # If still failing, try to fix common JSON issues
            content = re.sub(r'([{,]\s*)(\w+)(\s*:)', r'\1"\2"\3', content)  # Quote unquoted keys
            content = re.sub(r':\s*\'([^\']*)\'', r':"\1"', content)  # Replace single quotes with double
            content = re.sub(r'\\', '\\\\', content)  # Escape backslashes
            content = re.sub(r'([^\\])"', r'\1\\"', content)  # Escape unescaped quotes
            
            try:
                return json.loads(content)
            except json.JSONDecodeError as e:
                # If all else fails, return a default empty structure
                warning_highlight(f"Failed to parse JSON response: {str(e)}")
                return {"error": "Failed to parse JSON response", "raw_content": content[:100]}
</file>

<file path="src/react_agent/utils/logging.py">
"""Logging utilities.

This module provides enhanced logging utilities and convenience methods
for the agent framework. It builds upon the basic logging configuration
defined in log_config.py.
"""

import logging
from typing import Any, Mapping


"""Module: log_config.py. This module provides logging configuration for the enrichment agent.

-------------------------
It includes functions for setting up and configuring loggers with rich formatting.
"""

# Standard library imports
import logging
import threading
from typing import Optional  # noqa: F401

# Third-party imports
from rich.console import Console
from rich.logging import RichHandler

# Create console for rich output - use stderr for logs
console = Console(stderr=True)

# Logging configuration
LOG_FORMAT = "%(message)s"  # Added back for backward compatibility with tests
DATE_FORMAT = "[%X]"

# Logger lock for thread safety
_logger_lock = threading.Lock()


def setup_logger(
    name: str = "enrichment_agent", level: int = logging.INFO
) -> logging.Logger:
    """Set up a logger with rich formatting for beautiful console output.

    Args:
        name: Name of the logger. Defaults to "enrichment_agent".
        level: Logging level. Defaults to logging.INFO.

    Returns:
        Configured logger instance with rich formatting.
    """
    with _logger_lock:
        logger = logging.getLogger(name)

        # Only configure the logger if it hasn't been configured yet
        if not logger.handlers:
            logger.setLevel(level)

            # Create rich handler with proper parameter passing
            handler = RichHandler(
                console=console,
                rich_tracebacks=True,
                tracebacks_show_locals=True,
                show_time=True,
                show_path=True,
                markup=True,
                log_time_format=DATE_FORMAT,
                omit_repeated_times=False,
                level=level,
            )

            # Add handler and disable propagation to prevent duplicate logs
            logger.addHandler(handler)
            logger.propagate = False

        return logger


# Create a default logger instance
logger = setup_logger()

def set_level(level: int) -> None:
    """Set the logging level for the default logger and root logger.
    
    Args:
        level: The logging level to set (e.g., logging.DEBUG, logging.INFO)
    """
    with _logger_lock:
        # Set level for the default logger
        logger.setLevel(level)
        
        # Update handler level
        for handler in logger.handlers:
            handler.setLevel(level)
        
        # Also set for root logger to affect other loggers in hierarchy
        root_logger = logging.getLogger()
        root_logger.setLevel(level)


def get_logger(name: str) -> logging.Logger:
    """Get a logger instance with the specified name.

    This function returns a logger configured with rich formatting and proper
    log levels. It uses the setup_logger function from log_config to ensure
    consistent logging configuration across the application.

    Args:
        name (str): The name for the logger, typically __name__ from the calling module

    Returns:
        logging.Logger: A configured logger instance with rich formatting
    """
    return setup_logger(name)


# Convenience methods for formatted logging with Rich markup
def info_success(message: str, exc_info: bool | BaseException | None = None) -> None:
    """Log a success message with green formatting.

    Args:
        message (str): The message to log
        exc_info (bool | BaseException | None): Exception information to include in the log
    """
    logger.info("[bold green]✓ %s[/bold green]", message, exc_info=exc_info)


def info_highlight(message: str, exc_info: bool | BaseException | None = None) -> None:
    """Log a highlighted informational message.

    Args:
        message (str): The message to log
        exc_info (bool | BaseException | None): Exception information to include in the log
    """
    logger.info("[bold blue]ℹ %s[/bold blue]", message, exc_info=exc_info)


def warning_highlight(
    message: str, exc_info: bool | BaseException | None = None
) -> None:
    """Log a highlighted warning message.

    Args:
        message (str): The message to log
        exc_info (bool | BaseException | None): Exception information to include in the log
    """
    logger.warning("[bold yellow]⚠ %s[/bold yellow]", message, exc_info=exc_info)


def error_highlight(message: str, exc_info: bool | BaseException | None = None) -> None:
    """Log a highlighted error message.

    Args:
        message (str): The message to log
        exc_info (bool | BaseException | None): Exception information to include in the log
    """
    logger.error("[bold red]✗ %s[/bold red]", message, exc_info=exc_info)


def log_dict(
    data: Mapping[str, Any], level: int = logging.INFO, title: str | None = None
) -> None:
    """Log a dictionary with pretty formatting.

    Args:
        data (Mapping[str, Any]): The dictionary to log
        level (int): The logging level to use. Defaults to logging.INFO
        title (str | None): Optional title to display before the dictionary

    Raises:
        ValueError: If level is not a valid logging level
    """
    # Validate logging level
    if level not in (
        logging.DEBUG,
        logging.INFO,
        logging.WARNING,
        logging.ERROR,
        logging.CRITICAL,
    ):
        raise ValueError(f"Invalid logging level: {level}")

    if title:
        logger.log(level, "[bold]%s[/bold]", title)

    # Use rich's pretty printing through the logger
    for key, value in data.items():
        logger.log(level, "  [cyan]%s[/cyan]: %s", key, value)


def log_step(
    step_name: str, step_number: int | None = None, total_steps: int | None = None
) -> None:
    """Log a processing step with optional step counter.

    Args:
        step_name (str): The name of the step
        step_number (int | None): Current step number if part of a sequence
        total_steps (int | None): Total number of steps in the sequence

    Raises:
        ValueError: If step_number is provided without total_steps or vice versa
        ValueError: If step_number is greater than total_steps
    """
    # Validate step numbers
    if (step_number is None) != (total_steps is None):
        raise ValueError("Both step_number and total_steps must be provided together")

    if step_number is None or total_steps is None:
        logger.info("[bold magenta]Step:[/bold magenta] %s", step_name)

    elif not 1 <= step_number <= total_steps:
        raise ValueError(f"Invalid step numbers: {step_number}/{total_steps}")
    else:
        logger.info(
            "[bold magenta]Step %s/%s:[/bold magenta] %s",
            step_number,
            total_steps,
            step_name,
        )
</file>

<file path="src/react_agent/utils/validations.py">
import re
from urllib.parse import urlparse

def is_valid_url(url: str) -> bool:
    """
    Validate if a URL is properly formatted and not a fabricated example URL.
    """
    if not url:
        return False

    # Check for example/fake URLs
    fake_url_patterns = [
        r'example\.com',
        r'sample\.org',
        r'test\.net',
        r'domain\.com',
        r'yourcompany\.com',
        r'acme\.com',
        r'widget\.com',
        r'placeholder\.net',
        r'company\.org'
    ]

    for pattern in fake_url_patterns:
        if re.search(pattern, url, re.IGNORECASE):
            return False

    # Basic URL validation
    try:
        result = urlparse(url)
        return all([result.scheme in ('http', 'https'), result.netloc])
    except Exception:
        return False
</file>

<file path="src/react_agent/__init__.py">
"""React Agent.

This module defines a custom reasoning and action agent graph.
It invokes tools in a simple loop.
"""

from react_agent.graphs.graph import graph

__all__ = ["graph"]
</file>

<file path="src/react_agent/configuration.py">
"""Define the configurable parameters for the agent."""

from __future__ import annotations

import os
from dataclasses import dataclass, field, fields
from typing import Annotated, Optional

from langchain_core.runnables import RunnableConfig, ensure_config

from react_agent.prompts import templates


@dataclass(kw_only=True)
class Configuration:
    """The configuration for the agent."""

    system_prompt: str = field(
        default=templates.SYSTEM_PROMPT,
        metadata={
            "description": "The system prompt to use for the agent's interactions. "
            "This prompt sets the context and behavior for the agent."
        },
    )

    model: Annotated[str, {"__template_metadata__": {"kind": "llm"}}] = field(
        default="openai/gpt-4o",
        metadata={
            "description": "The name of the language model to use for the agent's main interactions. "
            "Should be in the form: provider/model-name."
        },
    )

    max_search_results: int = field(
        default=10,
        metadata={
            "description": "The maximum number of search results to return for each search query."
        },
    )

    firecrawl_api_key: Optional[str] = field(
        default_factory=lambda: os.getenv("FIRECRAWL_API_KEY"),
        metadata={
            "description": "API key for the FireCrawl service. Required for web scraping and crawling."
        },
    )

    firecrawl_url: Optional[str] = field(
        default_factory=lambda: os.getenv("FIRECRAWL_URL"),
        metadata={
            "description": "Base URL for the FireCrawl service. Use this for self-hosted instances."
        },
    )

    jina_api_key: Optional[str] = field(
        default_factory=lambda: os.getenv("JINA_API_KEY"),
        metadata={
            "description": "API key for the Jina AI service. Required for web search and summarization."
        },
    )

    jina_url: Optional[str] = field(
        default_factory=lambda: os.getenv("JINA_URL", "https://s.jina.ai"),
        metadata={
            "description": "Base URL for the Jina AI service. Use this for self-hosted instances."
        },
    )

    @classmethod
    def from_runnable_config(
        cls, config: Optional[RunnableConfig] = None
    ) -> Configuration:
        """Create a Configuration instance from a RunnableConfig object."""
        config = ensure_config(config)
        configurable = config.get("configurable") or {}
        
        # Get environment variables for FireCrawl
        env_config = {
            "firecrawl_api_key": os.getenv("FIRECRAWL_API_KEY"),
            "firecrawl_url": os.getenv("FIRECRAWL_URL"),
        }
        
        # Merge environment variables with configurable, giving priority to configurable
        merged_config = {**env_config, **configurable}
        
        _fields = {f.name for f in fields(cls) if f.init}
        return cls(**{k: v for k, v in merged_config.items() if k in _fields})
</file>

<file path="src/react_agent/state.py">
"""Define the state structures for the agent."""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import Sequence

from langchain_core.messages import AnyMessage
from langgraph.graph import add_messages
from langgraph.managed import IsLastStep
from typing_extensions import Annotated


@dataclass
class InputState:
    """Defines the input state for the agent, representing a narrower interface to the outside world.

    This class is used to define the initial state and structure of incoming data.
    """

    messages: Annotated[Sequence[AnyMessage], add_messages] = field(
        default_factory=list
    )
    """
    Messages tracking the primary execution state of the agent.

    Typically accumulates a pattern of:
    1. HumanMessage - user input
    2. AIMessage with .tool_calls - agent picking tool(s) to use to collect information
    3. ToolMessage(s) - the responses (or errors) from the executed tools
    4. AIMessage without .tool_calls - agent responding in unstructured format to the user
    5. HumanMessage - user responds with the next conversational turn

    Steps 2-5 may repeat as needed.

    The `add_messages` annotation ensures that new messages are merged with existing ones,
    updating by ID to maintain an "append-only" state unless a message with the same ID is provided.
    """


@dataclass
class State(InputState):
    """Represents the complete state of the agent, extending InputState with additional attributes.

    This class can be used to store any information needed throughout the agent's lifecycle.
    """

    is_last_step: IsLastStep = field(default=False)
    """
    Indicates whether the current step is the last one before the graph raises an error.

    This is a 'managed' variable, controlled by the state machine rather than user code.
    It is set to 'True' when the step count reaches recursion_limit - 1.
    """

    # Additional attributes can be added here as needed.
    # Common examples include:
    # retrieved_documents: List[Document] = field(default_factory=list)
    # extracted_entities: Dict[str, Any] = field(default_factory=dict)
    # api_connections: Dict[str, Any] = field(default_factory=dict)
</file>

<file path="tests/cassettes/103fe67e-a040-4e4e-aadb-b20a7057f904.yaml">
interactions:
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:50:53.832822+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA2yRS0vEQAzHv0rIxctUuqurOEdXXRQPooIvpIzb9KFtsjuTUevS7y6tiAqeQh6/
        /PPYYJ2jxTaUWTrZf32Wp9Jf3h2+Fa/z+4/F1dFiskCD2q1oqKIQXElo0EszBFwIdVDHigZbyalB
        i8vGxZySnWSWBGEmTabpdDfdm6ZocCmsxIr2YfPdVOl9wEdj8VrAcXgjD51ED+tIQWthcE8SFbQi
        KCRyTh6kgHPH5bxyNRs43WoaYKIcVCCQ88sKCvEj0UpQiKtEJcmdEtRciG/d0HcbzkmhJcgFtHI6
        Mp3EbezNz4QiTRbDsPd4rMGPWTo5XB/NbiYXz2fkZrfHxye+q9pFiQbZtQP3NcZA8Soq2g2uI/kO
        Lf63A/b9o8Ggsso8uSD8V3lMBFpH4iWh5dg0BuP4Drv5UshUXogD2t2dPYMS9XfsYNr3nwAAAP//
        AwCzkxon7QEAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22ab88f99c4cb1-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:51:31 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:51:29Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:51:31Z'
      request-id:
      - req_019JrRXeYjgQXtSjyp85fdHe
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: null
    headers: {}
    method: POST
    uri: https://api.tavily.com/search
  response:
    body:
      string: '{"query":"founder of LangChain","follow_up_questions":null,"answer":null,"images":[],"results":[{"title":"Speaker
        Harrison Chase - ELC","url":"https://sfelc.com/speaker/harrison-chase","content":"Harrison
        Chase is the CEO and co-founder of LangChain, a company formed around the
        open source Python/Typescript packages that aim to make it easy to develop
        Language Model applications. Prior to starting LangChain, he led the ML team
        at Robust Intelligence (an MLOps company focused on testing and validation
        of machine learning models), led the","score":0.99967754,"raw_content":null},{"title":"Harrison
        Chase - The AI Conference","url":"https://aiconference.com/speakers/harrison-chase/","content":"Harrison
        Chase is the co-founder and CEO of LangChain, a company formed around the
        open-source Python/Typescript packages that aim to make it easy to develop
        Language Model applications. Prior to starting LangChain, he led the ML team
        at Robust Intelligence (an MLOps company focused on testing and validation
        of machine learning models), led the","score":0.9995908,"raw_content":null},{"title":"Harrison
        Chase | TEDAI San Francisco","url":"https://tedai-sanfrancisco.ted.com/speakers-1/harrison-chase-/co-founder-and-ceo,-langchain/","content":"Harrison
        Chase, a Harvard graduate in statistics and computer science, co-founded LangChain
        to streamline the development of Language Model applications with open-source
        Python/Typescript packages. Chase''s experience includes heading the Machine
        Learning team at Robust Intelligence, focusing on the testing and validation
        of machine learning models, and leading the entity linking team at Kensho","score":0.9994746,"raw_content":null},{"title":"Harrison
        Chase, Author at TechCrunch","url":"https://techcrunch.com/author/harrison-chase/","content":"Harrison
        Chase is the CEO and co-founder of LangChain, a company formed around the
        open source Python/Typescript packages that aim to make it easy to develop
        Language Model applications","score":0.9994185,"raw_content":null},{"title":"LangChain''s
        Harrison Chase on Building the Orchestration Layer for AI ...","url":"https://www.sequoiacap.com/podcast/training-data-harrison-chase/","content":"Sonya
        Huang: Hi, and welcome to training data. We have with us today Harrison Chase,
        founder and CEO of LangChain. Harrison is a legend in the agent ecosystem,
        as the product visionary who first connected LLMs with tools and actions.
        And LangChain is the most popular agent building framework in the AI space.","score":0.99876,"raw_content":null},{"title":"Harrison
        Chase, LangChain CEO - Interview - YouTube","url":"https://www.youtube.com/watch?v=7D8bw_4hTdo","content":"Join
        us for an insightful interview with Harrison Chase, the CEO and co-founder
        of Langchain, as he provides a comprehensive overview of Langchain''s innovati","score":0.99854493,"raw_content":null},{"title":"Harrison
        Chase - Forbes","url":"https://www.forbes.com/profile/harrison-chase/","content":"Harrison
        Chase only cofounded LangChain in late 2022, but the company caught instant
        attention for enabling anyone to build apps powered by large language models
        like GPT-4 in as little as two","score":0.9977743,"raw_content":null},{"title":"LangChain
        - Wikipedia","url":"https://en.wikipedia.org/wiki/LangChain","content":"In
        October 2023 LangChain introduced LangServe, a deployment tool designed to
        facilitate the transition from LCEL (LangChain Expression Language) prototypes
        to production-ready applications.[5]\nIntegrations[edit]\nAs of March 2023,
        LangChain included integrations with systems including Amazon, Google, and
        Microsoft Azure cloud storage; API wrappers for news, movie information, and
        weather; Bash for summarization, syntax and semantics checking, and execution
        of shell scripts; multiple web scraping subsystems and templates; few-shot
        learning prompt generation support; finding and summarizing \"todo\" tasks
        in code; Google Drive documents, spreadsheets, and presentations summarization,
        extraction, and creation; Google Search and Microsoft Bing web search; OpenAI,
        Anthropic, and Hugging Face language models; iFixit repair guides and wikis
        search and summarization; MapReduce for question answering, combining documents,
        and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and
        pymupdf for PDF file text extraction and manipulation; Python and JavaScript
        code generation, analysis, and debugging; Milvus vector database[6] to store
        and retrieve vector embeddings; Weaviate vector database[7] to cache embedding
        and data objects; Redis cache database storage; Python RequestsWrapper and
        other methods for API requests; SQL and NoSQL databases including JSON support;
        Streamlit, including for logging; text mapping for k-nearest neighbors search;
        time zone conversion and calendar operations; tracing and recording stack
        symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha
        website and SDK.[8] As a language model integration framework, LangChain''s
        use-cases largely overlap with those of language models in general, including
        document analysis and summarization, chatbots, and code analysis.[2]\nHistory[edit]\nLangChain
        was launched in October 2022 as an open source project by Harrison Chase,
        while working at machine learning startup Robust Intelligence. In April 2023,
        LangChain had incorporated and the new startup raised over $20 million in
        funding at a valuation of at least $200 million from venture firm Sequoia
        Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\n
        The project quickly garnered popularity, with improvements from hundreds of
        contributors on GitHub, trending discussions on Twitter, lively activity on
        the project''s Discord server, many YouTube tutorials, and meetups in San
        Francisco and London. As of April 2023, it can read from more than 50 document
        types and data sources.[9]\nReferences[edit]\nExternal links[edit]","score":0.99694854,"raw_content":null},{"title":"Harrison
        Chase - CEO of LangChain - Analytics India Magazine","url":"https://analyticsindiamag.com/people/harrison-chase/","content":"By
        AIM The dynamic co-founder and CEO of LangChain, Harrison Chase is simplifying
        the creation of applications powered by LLMs. With a background in statistics
        and computer science from Harvard University, Chase has carved a niche in
        the AI landscape. AIM Brand Solutions, a marketing division within AIM, specializes
        in creating diverse content such as documentaries, public artworks, podcasts,
        videos, articles, and more to effectively tell compelling stories. AIM Research
        produces a series of annual reports on AI & Data Science covering every aspect
        of the industry. Discover how Cypher 2024 expands to the USA, bridging AI
        innovation gaps and tackling the challenges of enterprise AI adoption AIM
        India AIM Research AIM Leaders Council 50 Best Data Science Firms","score":0.99491996,"raw_content":null},{"title":"Key
        Insights from Harrison Chase''s Talk on Building Next-Level AI Agents","url":"https://www.turingpost.com/p/harrison-chase-langchain-ai-agents","content":"Harrison
        Chase, founder of LangChain, shared insights on the evolution of AI agents
        and their applications during Sequoia Capital''s AI Ascent. ... Saves you
        a lot of research time, plus gives a flashback to ML history and insights
        into the future. Stay ahead alongside over 73,000 professionals from top AI
        labs, ML startups, and enterprises","score":0.9941801,"raw_content":null}],"response_time":2.54}'
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '7474'
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:51:34 GMT
      Server:
      - nginx
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}, {"role": "assistant", "content": [{"text": "To answer
      your question about the founder of LangChain, I''ll need to search for the most
      up-to-date information. Let me do that for you.", "type": "text"}, {"type":
      "tool_use", "name": "search", "input": {"query": "founder of LangChain"}, "id":
      "toolu_01BqD5W1PjJea5XEEFryhmGg"}]}, {"role": "user", "content": [{"type": "tool_result",
      "content": "[{\"url\": \"https://sfelc.com/speaker/harrison-chase\", \"content\":
      \"Harrison Chase is the CEO and co-founder of LangChain, a company formed around
      the open source Python/Typescript packages that aim to make it easy to develop
      Language Model applications. Prior to starting LangChain, he led the ML team
      at Robust Intelligence (an MLOps company focused on testing and validation of
      machine learning models), led the\"}, {\"url\": \"https://aiconference.com/speakers/harrison-chase/\",
      \"content\": \"Harrison Chase is the co-founder and CEO of LangChain, a company
      formed around the open-source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://tedai-sanfrancisco.ted.com/speakers-1/harrison-chase-/co-founder-and-ceo,-langchain/\",
      \"content\": \"Harrison Chase, a Harvard graduate in statistics and computer
      science, co-founded LangChain to streamline the development of Language Model
      applications with open-source Python/Typescript packages. Chase''s experience
      includes heading the Machine Learning team at Robust Intelligence, focusing
      on the testing and validation of machine learning models, and leading the entity
      linking team at Kensho\"}, {\"url\": \"https://techcrunch.com/author/harrison-chase/\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications\"}, {\"url\": \"https://www.sequoiacap.com/podcast/training-data-harrison-chase/\",
      \"content\": \"Sonya Huang: Hi, and welcome to training data. We have with us
      today Harrison Chase, founder and CEO of LangChain. Harrison is a legend in
      the agent ecosystem, as the product visionary who first connected LLMs with
      tools and actions. And LangChain is the most popular agent building framework
      in the AI space.\"}, {\"url\": \"https://www.youtube.com/watch?v=7D8bw_4hTdo\",
      \"content\": \"Join us for an insightful interview with Harrison Chase, the
      CEO and co-founder of Langchain, as he provides a comprehensive overview of
      Langchain''s innovati\"}, {\"url\": \"https://www.forbes.com/profile/harrison-chase/\",
      \"content\": \"Harrison Chase only cofounded LangChain in late 2022, but the
      company caught instant attention for enabling anyone to build apps powered by
      large language models like GPT-4 in as little as two\"}, {\"url\": \"https://en.wikipedia.org/wiki/LangChain\",
      \"content\": \"In October 2023 LangChain introduced LangServe, a deployment
      tool designed to facilitate the transition from LCEL (LangChain Expression Language)
      prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of
      March 2023, LangChain included integrations with systems including Amazon, Google,
      and Microsoft Azure cloud storage; API wrappers for news, movie information,
      and weather; Bash for summarization, syntax and semantics checking, and execution
      of shell scripts; multiple web scraping subsystems and templates; few-shot learning
      prompt generation support; finding and summarizing \\\"todo\\\" tasks in code;
      Google Drive documents, spreadsheets, and presentations summarization, extraction,
      and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic,
      and Hugging Face language models; iFixit repair guides and wikis search and
      summarization; MapReduce for question answering, combining documents, and question
      generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF
      file text extraction and manipulation; Python and JavaScript code generation,
      analysis, and debugging; Milvus vector database[6] to store and retrieve vector
      embeddings; Weaviate vector database[7] to cache embedding and data objects;
      Redis cache database storage; Python RequestsWrapper and other methods for API
      requests; SQL and NoSQL databases including JSON support; Streamlit, including
      for logging; text mapping for k-nearest neighbors search; time zone conversion
      and calendar operations; tracing and recording stack symbols in threaded and
      asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a
      language model integration framework, LangChain''s use-cases largely overlap
      with those of language models in general, including document analysis and summarization,
      chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in
      October 2022 as an open source project by Harrison Chase, while working at machine
      learning startup Robust Intelligence. In April 2023, LangChain had incorporated
      and the new startup raised over $20 million in funding at a valuation of at
      least $200 million from venture firm Sequoia Capital, a week after announcing
      a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered
      popularity, with improvements from hundreds of contributors on GitHub, trending
      discussions on Twitter, lively activity on the project''s Discord server, many
      YouTube tutorials, and meetups in San Francisco and London. As of April 2023,
      it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal
      links[edit]\"}, {\"url\": \"https://analyticsindiamag.com/people/harrison-chase/\",
      \"content\": \"By AIM The dynamic co-founder and CEO of LangChain, Harrison
      Chase is simplifying the creation of applications powered by LLMs. With a background
      in statistics and computer science from Harvard University, Chase has carved
      a niche in the AI landscape. AIM Brand Solutions, a marketing division within
      AIM, specializes in creating diverse content such as documentaries, public artworks,
      podcasts, videos, articles, and more to effectively tell compelling stories.
      AIM Research produces a series of annual reports on AI & Data Science covering
      every aspect of the industry. Discover how Cypher 2024 expands to the USA, bridging
      AI innovation gaps and tackling the challenges of enterprise AI adoption AIM
      India AIM Research AIM Leaders Council 50 Best Data Science Firms\"}, {\"url\":
      \"https://www.turingpost.com/p/harrison-chase-langchain-ai-agents\", \"content\":
      \"Harrison Chase, founder of LangChain, shared insights on the evolution of
      AI agents and their applications during Sequoia Capital''s AI Ascent. ... Saves
      you a lot of research time, plus gives a flashback to ML history and insights
      into the future. Stay ahead alongside over 73,000 professionals from top AI
      labs, ML startups, and enterprises\"}]", "tool_use_id": "toolu_01BqD5W1PjJea5XEEFryhmGg",
      "is_error": false}]}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:50:59.620569+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3RUXW/cRgz8K8QiQF90wln+SHtvjlvERh2kqG2gaFMYvBUlbW7FlXe55wiG/3vB
        9Z0/EvRJgEQOZ4ZDPRjXmpUZU3+7PLg8/P1Kmq83H9PPza9Xf/2d+vPh5hdTGZkn0ipKCXsylYnB
        6wtMySVBFlOZMbTkzcpYj7mlxeHieJECM8miWTZHy5NmaSpjAwuxmNU/D3tQoW/aXh4rcz0gb2AO
        GboQ9RnhLlMSF7iGC7DIwOEephi2rqVSeO9kAMddiCNqHeA6ZAEZCLqQuaUIoYNL5P5sQMf1F/7C
        1//zEVyCc4zRpcBwNmCiGj6FSJAmsq5zFr2fV4pwUH9XqK0604bFHhm5hbPfPv84vqnhfE+gfT2d
        waMQNMumqeG6oI0T8gz3mCB0nbNOGYDHzHagVjs+WwlriqUJMAEyhIl4kUKOltSqr2SlzD2sd1wH
        rYM12k0flYXiJEFxSZxNhbhOzkIRknXElqCLYVTNW4wt3LDbUkxO5gJ8VMMH6opRglEc9y+qKhgI
        PLXFnU9oB8cEl4SRtUwIR0CBP8M6J4ELFvLe9TqxAnzW3wWbE7UQGETjwH0huUXv2qethw7GHbjf
        g5dMpsLwuH7l8112duNn6NExtTCFKXuMTmb1QWmeXujkMbOTuSqT1jOcTtF5tfmw2m36iduALUR0
        Si+5nktMWKDL3Druyx5nSGRzVAFbivCuWcLovFfejveVagOqpPysCEXFJNGOl5ayiSu6y8EhnOHk
        BH0FaQhR/AzYSckeh8y2wMK7g5fmRCU2W0oyktJUsA/EdhgxbopXJzXclACXsPyUlENLMQ1uql65
        qCFakw0jAe49hC7iSPchbsoBt7QlH6bCYpq8s0VZginck7qx1ijHnsAj9xl72q0MvNsQfPzjenFU
        GP14ajZwcm0Bwbe2uz5HerXINKFmadJcWuXon9e8o1d8CB1ICP4p/M8q9KZRYMQNgRMgTI4iSIAi
        sfx6vqdejieS3vHpxRvZtXn8tzJJwnQbCVNgszLE7a3kyGb3IdFd1vCbFWfvK5PLH3f1YBxPWW4l
        bIiTWTXL98eVCVnevHx/8vj4HwAAAP//AwBvXpD30gUAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22abad2aef4caf-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:51:40 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:51:35Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:51:40Z'
      request-id:
      - req_012BB17DG6rpcEU1xAbh9Zao
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:51:11.433533+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1SRTWvcQAyG/4rQpZdxcHY3XuJLCYX0a3tJCz2EYiYeeT2tLXktTRuz+L8Xe1vS
        noQ+3lcP0hljwBJ7PVb59ef44Xtzc/+UBp8Oxce3t9vdcf+ADm0aaJkiVX8kdDhKtxS8alTzbOiw
        l0Adllh3PgXKttlNpsJMlm3yzS4vNjk6rIWN2LB8PP81NXpe5Gso8YuAZ/1FI1gbFU6J1KIw+LpO
        ozfqJgfvX3UdMFEAE1DyY91CI4uCoBc1SENmkgVvBJEbGXt/8XiSZHDwfHzT+sjgOUA0hUYSBxqv
        4EAGPUEQsNbb6jlJusLZvdCKdFXS5Qbr4ZY8Vfn13VTc3/XF/vT88PPdp9ooNBoEHbLvF90Fc1Hx
        kAzLM54SjROW+LUViLrC/wEBaV4oX+M8f3OoJkM1klfh/ynWhtIpEdeEJaeuc5jWN5Xny7bK5Aex
        YrnbFg4l2b+12/08/wYAAP//AwBjKTr0BQIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22abf709c34cb4-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:51:49 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:51:47Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:51:49Z'
      request-id:
      - req_01QtVfENAkfspCf9KVLM7Emk
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}, {"role": "assistant", "content": [{"text": "To answer
      this question accurately, I''ll need to search for the most up-to-date information
      about LangChain and its founder. Let me do that for you.", "type": "text"},
      {"type": "tool_use", "name": "search", "input": {"query": "Who is the founder
      of LangChain?"}, "id": "toolu_01Ay6FAm67qxRvHMctedfsdo"}]}, {"role": "user",
      "content": [{"type": "tool_result", "content": "[{\"url\": \"https://sfelc.com/speaker/harrison-chase\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://aiconference.com/speakers/harrison-chase/\",
      \"content\": \"Harrison Chase is the co-founder and CEO of LangChain, a company
      formed around the open-source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://tedai-sanfrancisco.ted.com/speakers-1/harrison-chase-/co-founder-and-ceo,-langchain/\",
      \"content\": \"Harrison Chase, a Harvard graduate in statistics and computer
      science, co-founded LangChain to streamline the development of Language Model
      applications with open-source Python/Typescript packages. Chase''s experience
      includes heading the Machine Learning team at Robust Intelligence, focusing
      on the testing and validation of machine learning models, and leading the entity
      linking team at Kensho\"}, {\"url\": \"https://techcrunch.com/author/harrison-chase/\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications\"}, {\"url\": \"https://www.sequoiacap.com/podcast/training-data-harrison-chase/\",
      \"content\": \"Sonya Huang: Hi, and welcome to training data. We have with us
      today Harrison Chase, founder and CEO of LangChain. Harrison is a legend in
      the agent ecosystem, as the product visionary who first connected LLMs with
      tools and actions. And LangChain is the most popular agent building framework
      in the AI space.\"}, {\"url\": \"https://www.youtube.com/watch?v=7D8bw_4hTdo\",
      \"content\": \"Join us for an insightful interview with Harrison Chase, the
      CEO and co-founder of Langchain, as he provides a comprehensive overview of
      Langchain''s innovati\"}, {\"url\": \"https://www.forbes.com/profile/harrison-chase/\",
      \"content\": \"Harrison Chase only cofounded LangChain in late 2022, but the
      company caught instant attention for enabling anyone to build apps powered by
      large language models like GPT-4 in as little as two\"}, {\"url\": \"https://en.wikipedia.org/wiki/LangChain\",
      \"content\": \"In October 2023 LangChain introduced LangServe, a deployment
      tool designed to facilitate the transition from LCEL (LangChain Expression Language)
      prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of
      March 2023, LangChain included integrations with systems including Amazon, Google,
      and Microsoft Azure cloud storage; API wrappers for news, movie information,
      and weather; Bash for summarization, syntax and semantics checking, and execution
      of shell scripts; multiple web scraping subsystems and templates; few-shot learning
      prompt generation support; finding and summarizing \\\"todo\\\" tasks in code;
      Google Drive documents, spreadsheets, and presentations summarization, extraction,
      and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic,
      and Hugging Face language models; iFixit repair guides and wikis search and
      summarization; MapReduce for question answering, combining documents, and question
      generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF
      file text extraction and manipulation; Python and JavaScript code generation,
      analysis, and debugging; Milvus vector database[6] to store and retrieve vector
      embeddings; Weaviate vector database[7] to cache embedding and data objects;
      Redis cache database storage; Python RequestsWrapper and other methods for API
      requests; SQL and NoSQL databases including JSON support; Streamlit, including
      for logging; text mapping for k-nearest neighbors search; time zone conversion
      and calendar operations; tracing and recording stack symbols in threaded and
      asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a
      language model integration framework, LangChain''s use-cases largely overlap
      with those of language models in general, including document analysis and summarization,
      chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in
      October 2022 as an open source project by Harrison Chase, while working at machine
      learning startup Robust Intelligence. In April 2023, LangChain had incorporated
      and the new startup raised over $20 million in funding at a valuation of at
      least $200 million from venture firm Sequoia Capital, a week after announcing
      a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered
      popularity, with improvements from hundreds of contributors on GitHub, trending
      discussions on Twitter, lively activity on the project''s Discord server, many
      YouTube tutorials, and meetups in San Francisco and London. As of April 2023,
      it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal
      links[edit]\"}, {\"url\": \"https://analyticsindiamag.com/people/harrison-chase/\",
      \"content\": \"By AIM The dynamic co-founder and CEO of LangChain, Harrison
      Chase is simplifying the creation of applications powered by LLMs. With a background
      in statistics and computer science from Harvard University, Chase has carved
      a niche in the AI landscape. AIM Brand Solutions, a marketing division within
      AIM, specializes in creating diverse content such as documentaries, public artworks,
      podcasts, videos, articles, and more to effectively tell compelling stories.
      AIM Research produces a series of annual reports on AI & Data Science covering
      every aspect of the industry. Discover how Cypher 2024 expands to the USA, bridging
      AI innovation gaps and tackling the challenges of enterprise AI adoption AIM
      India AIM Research AIM Leaders Council 50 Best Data Science Firms\"}, {\"url\":
      \"https://www.turingpost.com/p/harrison-chase-langchain-ai-agents\", \"content\":
      \"Harrison Chase, founder of LangChain, shared insights on the evolution of
      AI agents and their applications during Sequoia Capital''s AI Ascent. ... Saves
      you a lot of research time, plus gives a flashback to ML history and insights
      into the future. Stay ahead alongside over 73,000 professionals from top AI
      labs, ML startups, and enterprises\"}]", "tool_use_id": "toolu_01Ay6FAm67qxRvHMctedfsdo",
      "is_error": false}]}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:51:14.324904+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3RVbW/bNhD+KwdiQDZA9lynaQd9a4IWyZBi6dq9AMsQnKmzxJoiFd7RrhD0vw9H
        2Z6XoZ8MUHfH5+3oJ+MaU5ue24fFi9uP169//u2PO/rzarndvXt9+/nt9t3GVEbGgbSKmLElU5kU
        vR4gs2PBIKYyfWzIm9pYj7mh2fnsYsYxBJLZcrF8uXi1XJjK2BiEgpj6r6fDUKEv2l5+anOJTA3E
        ANIRMGGyHSTi7IUruAGLAWwMa9dQED8CBt5RgjHmBI+ZWFwMgKuYpQxYxxwaShDXcIuhverQhfl9
        uA/XmJLjGOCqQyZw/O1y+BRhRdDHRDAkso6pgu7YY+Ps0Iahgau3vzxrv6ZEgImAY0+woRGG6ILw
        HuYzJDrj2Fwr1BdzeKcXoHKrn9cfrz9pAxfAoxAsF8vlHD4VlP2AYYQdMqxj6qkBTNoHcaAw45iT
        JbgbpYvhx0/jQB9tcoPAgHaDLTGgKz0CPW5caMEJELKjBBKhoS35OBQEGVuC95oFwGHwzhbcXFRf
        zuES7aYtN9f/ao/KaoupgTZhkxX6zkkHCKtjuZJiQXEsznLRSUlloQRsHQVL5Y7zOdwl2rqYGejL
        QKl8quGS1uogCyZRAke1ipmemuLme7SdCwS3hClomRD2SvvXuMoscBOEvHetzqwAj7quo82H4GoK
        Q1sQbtG7yTgNRb8f7g/Dy8pM0rycw4fs7AbaFHfS1SduPuq5H6FFF6iBIQ7ZY3IyqiQK+s2N4uhz
        cDLO4XKEN0NyXt0/r+Czwu5jkI4B16qWEwaPOdiu2id44tBhAwmd0mDXBrd2FoPAOofmwEfjs0Wf
        pyjELSX4brlYQO+8d3FarYs53PQDWvlfVh1DQ2yTW2m/2n5vPLU0matQsKUgQDbyyEL9vdGwQucY
        9MHRKqtPit07mFp6ljmG729v3/MPU34kRj9FBe2UwhNZO2RYkdWljIHUH0XQR5aDxBOc2So7XxRY
        J+xpF9OGT5TnAffJezWH3x2XJS18zxjaiH6CcrKcrCvDkgh7r3HQQfsN6pX+/vn4xiJVJxuI1hKz
        W3kqOiHsnL5DCUNbCO2nUppEWGV2gZipILCJdNHe3MyGuKOkljzf1yPoM4aEg2sgOaYT8i40mSWN
        wF3cWdTJ//X8jGFbNCkAtEvzXeD3Q0yCwU7SF6ekmx4YAlVZq4p2vhjtD5pMWzM9yCcK6AW0Xjt9
        C2Ruvv5dGZY4PCRCjsHUhkLzIDkFs//A9Jh1j00dsveVyeW/rX4yLgxZHiRuKLCpl4ufFpWJWU4P
        zy8WX7/+AwAA//8DAHBCV3w8BwAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22ac0918734cb2-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:51:56 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:51:49Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:51:56Z'
      request-id:
      - req_01BLNX4GjFRn5bwxxBo3hd3r
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:51:55.561440+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1RRS2vbQBD+K8NcclkFxY6dZG+NIaTgXNxgU0oRa2lkCa9mJO1sY2P034vklrSn
        YR7fg28uWBdosQmHLL3b0fHwbb85Plb1utsudt8X2+enFRrUc0vjFYXgDoQGe/HjwIVQB3WsaLCR
        gjxazL2LBSXzZJEEYSZNZunsPl3OUjSYCyuxov1x+UuqdBrhU7H4LuA4fFAPWtUBukhBa2FweR57
        p+TPBr7eeA9MVIAKBHJ9XkEpI4KgkaAQ20QlKZwS1FxK37grx16iwtrxYVW5msFxAbUGKCVyQf0t
        rEmhISgEtHI6cZ4l3uJgPt2K+CyGMYMpuLGPWXr3Rt1m177+enj5svp4OZVv283+tESD7JoRd7U5
        oriNivaCXaT+jBb/qIOUn9ZwGH4aDCpt1pMLwv8rT4tAXSTOCS1H7w3G6TX2clXIVI7EAe39fGlQ
        ov47e5oPw28AAAD//wMAEu0ZMPkBAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22ad0acd1032b3-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:52:33 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:52:31Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:52:33Z'
      request-id:
      - req_01GSwnbYyFo11udBwAygsuuc
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}, {"role": "assistant", "content": [{"text": "To answer
      this question accurately, I''ll need to search for the most up-to-date information
      about LangChain and its founder. Let me do that for you.", "type": "text"},
      {"type": "tool_use", "name": "search", "input": {"query": "founder of LangChain"},
      "id": "toolu_01MeqRWpHv7FACwFxfMVRbx6"}]}, {"role": "user", "content": [{"type":
      "tool_result", "content": "[{\"url\": \"https://sfelc.com/speaker/harrison-chase\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://aiconference.com/speakers/harrison-chase/\",
      \"content\": \"Harrison Chase is the co-founder and CEO of LangChain, a company
      formed around the open-source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://tedai-sanfrancisco.ted.com/speakers-1/harrison-chase-/co-founder-and-ceo,-langchain/\",
      \"content\": \"Harrison Chase, a Harvard graduate in statistics and computer
      science, co-founded LangChain to streamline the development of Language Model
      applications with open-source Python/Typescript packages. Chase''s experience
      includes heading the Machine Learning team at Robust Intelligence, focusing
      on the testing and validation of machine learning models, and leading the entity
      linking team at Kensho\"}, {\"url\": \"https://techcrunch.com/author/harrison-chase/\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications\"}, {\"url\": \"https://www.sequoiacap.com/podcast/training-data-harrison-chase/\",
      \"content\": \"Sonya Huang: Hi, and welcome to training data. We have with us
      today Harrison Chase, founder and CEO of LangChain. Harrison is a legend in
      the agent ecosystem, as the product visionary who first connected LLMs with
      tools and actions. And LangChain is the most popular agent building framework
      in the AI space.\"}, {\"url\": \"https://www.youtube.com/watch?v=7D8bw_4hTdo\",
      \"content\": \"Join us for an insightful interview with Harrison Chase, the
      CEO and co-founder of Langchain, as he provides a comprehensive overview of
      Langchain''s innovati\"}, {\"url\": \"https://www.forbes.com/profile/harrison-chase/\",
      \"content\": \"Harrison Chase only cofounded LangChain in late 2022, but the
      company caught instant attention for enabling anyone to build apps powered by
      large language models like GPT-4 in as little as two\"}, {\"url\": \"https://en.wikipedia.org/wiki/LangChain\",
      \"content\": \"In October 2023 LangChain introduced LangServe, a deployment
      tool designed to facilitate the transition from LCEL (LangChain Expression Language)
      prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of
      March 2023, LangChain included integrations with systems including Amazon, Google,
      and Microsoft Azure cloud storage; API wrappers for news, movie information,
      and weather; Bash for summarization, syntax and semantics checking, and execution
      of shell scripts; multiple web scraping subsystems and templates; few-shot learning
      prompt generation support; finding and summarizing \\\"todo\\\" tasks in code;
      Google Drive documents, spreadsheets, and presentations summarization, extraction,
      and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic,
      and Hugging Face language models; iFixit repair guides and wikis search and
      summarization; MapReduce for question answering, combining documents, and question
      generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF
      file text extraction and manipulation; Python and JavaScript code generation,
      analysis, and debugging; Milvus vector database[6] to store and retrieve vector
      embeddings; Weaviate vector database[7] to cache embedding and data objects;
      Redis cache database storage; Python RequestsWrapper and other methods for API
      requests; SQL and NoSQL databases including JSON support; Streamlit, including
      for logging; text mapping for k-nearest neighbors search; time zone conversion
      and calendar operations; tracing and recording stack symbols in threaded and
      asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a
      language model integration framework, LangChain''s use-cases largely overlap
      with those of language models in general, including document analysis and summarization,
      chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in
      October 2022 as an open source project by Harrison Chase, while working at machine
      learning startup Robust Intelligence. In April 2023, LangChain had incorporated
      and the new startup raised over $20 million in funding at a valuation of at
      least $200 million from venture firm Sequoia Capital, a week after announcing
      a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered
      popularity, with improvements from hundreds of contributors on GitHub, trending
      discussions on Twitter, lively activity on the project''s Discord server, many
      YouTube tutorials, and meetups in San Francisco and London. As of April 2023,
      it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal
      links[edit]\"}, {\"url\": \"https://analyticsindiamag.com/people/harrison-chase/\",
      \"content\": \"By AIM The dynamic co-founder and CEO of LangChain, Harrison
      Chase is simplifying the creation of applications powered by LLMs. With a background
      in statistics and computer science from Harvard University, Chase has carved
      a niche in the AI landscape. AIM Brand Solutions, a marketing division within
      AIM, specializes in creating diverse content such as documentaries, public artworks,
      podcasts, videos, articles, and more to effectively tell compelling stories.
      AIM Research produces a series of annual reports on AI & Data Science covering
      every aspect of the industry. Discover how Cypher 2024 expands to the USA, bridging
      AI innovation gaps and tackling the challenges of enterprise AI adoption AIM
      India AIM Research AIM Leaders Council 50 Best Data Science Firms\"}, {\"url\":
      \"https://www.turingpost.com/p/harrison-chase-langchain-ai-agents\", \"content\":
      \"Harrison Chase, founder of LangChain, shared insights on the evolution of
      AI agents and their applications during Sequoia Capital''s AI Ascent. ... Saves
      you a lot of research time, plus gives a flashback to ML history and insights
      into the future. Stay ahead alongside over 73,000 professionals from top AI
      labs, ML startups, and enterprises\"}]", "tool_use_id": "toolu_01MeqRWpHv7FACwFxfMVRbx6",
      "is_error": false}]}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:51:58.213993+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3RU0W7cNhD8lQWfWkCnXs6Jg96bY7SIURtxE/epVxh71EraHLWUyeW5guF/L1Z3
        bmynfRJEcmdmZ4d8cNy4tRtyd7t8c/3b5erns7yKfHp18iXSr1+73zO7yuk0kp2inLEjV7kUgy1g
        zpwVRV3lhthQcGvnA5aGFieLd4scRUgXq+Xq7fJ0tXSV81GURN36z4cnUKW/rXz+rN0HzNRAFNCe
        IBMm30OiXILmCi7Ao8CY4p4bgikWuGftAb0vCZWApY1pQOUogNtYdEZpY5GGEsQWLlG68x5Z1hvZ
        yM3/bAJn+IgpcY4C5z1mquEqJoI8kueWPYYwzQhv6lcHrdQ4fVw8IaM0cP7LpxcM9UZWNXx8om+e
        cwsE62W1XK2qufiAN4woE9wV9rswQYcs1ACquWnttjEBawYWiXtU3hPgOKaIvgeNcHYBDe0pxHEg
        0XojJ/Uzznu0Qla2xiBgEd8begYUiCPJIseSPJn1X8mrifzkNW4pzTrhvudAr60w1PuYdiwdoALC
        gL5nIQiESWw1KyYtI5ih1MDnuC1Z4UKUQuCOxFO9kbf1Ea83PbBFv+uS2WYqsqJyVvZ5tspsKkoJ
        smcrhzbFwXTtMTXwh/CeUmad6o28q+E6cUzmzqzDBP1rSQW96TyYf3XUffmkWwkHa+k/BFfmhe+h
        jb48JZnyDG4C9xi4OQQ0tt8bMt+hXFu0vk0HecimcsAdASsQ5sn+jwOdRRfsCK6s2sYe2M8clsUU
        S9e/GOL1pH2Un26mkbJPPCqM6HfYUa7h5lnWzO9jzjJ3MgdfFDShnxvgwyU9u7CKoQjrNPdodYk8
        8d4qy3Z+IBgDtEUa63Ieyp5ESyLwOLLaJqchQ+AdwRe6K5ERzo9bBvqBxPcDpt1szveXzkfJ3FCy
        2IJExW0gaLkzim9Cycc8ZaWhgtFG7kvAFKb59vR8iKsd9/Zw+WMkUkevPM7ww+XlVf7x8PxojOEQ
        v4MxubJRvYgTIIxxNDJoEw408xjptnCYPTm7AOxINNfu8a/KZY3jbSLMUdzakTS3WpK440amu2Jh
        c2spIVSuzK/y+sGxjEVvNe5Isluvlu9PKxeLvlh8f/L4+A8AAAD//wMAo1MaSPYFAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22ad1b7c4d4cb1-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:52:39 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:52:33Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:52:39Z'
      request-id:
      - req_01E8yQY8oXhidTwTxeWKdjiW
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:52:42.318107+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1SRXWvbUAyG/4rQzW6Oi5O2SeObQgspgzBW2tLBGObUVuJDbSk50mkSgv/7sLPR
        7Uro4331IJ0w1Fhgp5syn9w8r252+7iY3YfV9+nbkibd+8ccHdpxS8MUqfoNocMo7VDwqkHNs6HD
        TmpqscCq9amm7DK7zlSYybJpPr3KZ9McHVbCRmxY/Dz9NTU6DPIxFPgs4Fn3FMGaoLBLpBaEwVdV
        it6oPTr4+qVtgYlqMAElH6sG1jIoCDpRg7TNTLLaG0HgtcTOnz3eJBmsPG/uGx8YPNcQTGEtiWuK
        F7Aig46gFrDG2+h5lHSBvfukFWnLpMMNxsMNeSrzyeQ1/rh7OsQFx2931/v54+HhZblEh+y7QXfG
        HFS8TYbFCXeJ4hELfG0Ego7wf0BA1p+Ut9j3vxyqybaM5FX4f4qxobRLxBVhwaltHabxTcXpvK00
        eSdWLK4uZw4l2b+1xbzvfwMAAP//AwB9NM36BQIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22ae2f5dec4cb6-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:53:20 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:53:18Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:53:20Z'
      request-id:
      - req_01DsVqmPigsQsHqctV3yYFQ5
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}, {"role": "assistant", "content": [{"text": "To answer
      this question accurately, I''ll need to search for the most up-to-date information
      about LangChain and its founder. Let me do that for you.", "type": "text"},
      {"type": "tool_use", "name": "search", "input": {"query": "Who is the founder
      of LangChain?"}, "id": "toolu_011WrXBSxr9nrNB5w7QxGUFF"}]}, {"role": "user",
      "content": [{"type": "tool_result", "content": "[{\"url\": \"https://sfelc.com/speaker/harrison-chase\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://aiconference.com/speakers/harrison-chase/\",
      \"content\": \"Harrison Chase is the co-founder and CEO of LangChain, a company
      formed around the open-source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://tedai-sanfrancisco.ted.com/speakers-1/harrison-chase-/co-founder-and-ceo,-langchain/\",
      \"content\": \"Harrison Chase, a Harvard graduate in statistics and computer
      science, co-founded LangChain to streamline the development of Language Model
      applications with open-source Python/Typescript packages. Chase''s experience
      includes heading the Machine Learning team at Robust Intelligence, focusing
      on the testing and validation of machine learning models, and leading the entity
      linking team at Kensho\"}, {\"url\": \"https://techcrunch.com/author/harrison-chase/\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications\"}, {\"url\": \"https://www.sequoiacap.com/podcast/training-data-harrison-chase/\",
      \"content\": \"Sonya Huang: Hi, and welcome to training data. We have with us
      today Harrison Chase, founder and CEO of LangChain. Harrison is a legend in
      the agent ecosystem, as the product visionary who first connected LLMs with
      tools and actions. And LangChain is the most popular agent building framework
      in the AI space.\"}, {\"url\": \"https://www.youtube.com/watch?v=7D8bw_4hTdo\",
      \"content\": \"Join us for an insightful interview with Harrison Chase, the
      CEO and co-founder of Langchain, as he provides a comprehensive overview of
      Langchain''s innovati\"}, {\"url\": \"https://www.forbes.com/profile/harrison-chase/\",
      \"content\": \"Harrison Chase only cofounded LangChain in late 2022, but the
      company caught instant attention for enabling anyone to build apps powered by
      large language models like GPT-4 in as little as two\"}, {\"url\": \"https://en.wikipedia.org/wiki/LangChain\",
      \"content\": \"In October 2023 LangChain introduced LangServe, a deployment
      tool designed to facilitate the transition from LCEL (LangChain Expression Language)
      prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of
      March 2023, LangChain included integrations with systems including Amazon, Google,
      and Microsoft Azure cloud storage; API wrappers for news, movie information,
      and weather; Bash for summarization, syntax and semantics checking, and execution
      of shell scripts; multiple web scraping subsystems and templates; few-shot learning
      prompt generation support; finding and summarizing \\\"todo\\\" tasks in code;
      Google Drive documents, spreadsheets, and presentations summarization, extraction,
      and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic,
      and Hugging Face language models; iFixit repair guides and wikis search and
      summarization; MapReduce for question answering, combining documents, and question
      generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF
      file text extraction and manipulation; Python and JavaScript code generation,
      analysis, and debugging; Milvus vector database[6] to store and retrieve vector
      embeddings; Weaviate vector database[7] to cache embedding and data objects;
      Redis cache database storage; Python RequestsWrapper and other methods for API
      requests; SQL and NoSQL databases including JSON support; Streamlit, including
      for logging; text mapping for k-nearest neighbors search; time zone conversion
      and calendar operations; tracing and recording stack symbols in threaded and
      asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a
      language model integration framework, LangChain''s use-cases largely overlap
      with those of language models in general, including document analysis and summarization,
      chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in
      October 2022 as an open source project by Harrison Chase, while working at machine
      learning startup Robust Intelligence. In April 2023, LangChain had incorporated
      and the new startup raised over $20 million in funding at a valuation of at
      least $200 million from venture firm Sequoia Capital, a week after announcing
      a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered
      popularity, with improvements from hundreds of contributors on GitHub, trending
      discussions on Twitter, lively activity on the project''s Discord server, many
      YouTube tutorials, and meetups in San Francisco and London. As of April 2023,
      it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal
      links[edit]\"}, {\"url\": \"https://analyticsindiamag.com/people/harrison-chase/\",
      \"content\": \"By AIM The dynamic co-founder and CEO of LangChain, Harrison
      Chase is simplifying the creation of applications powered by LLMs. With a background
      in statistics and computer science from Harvard University, Chase has carved
      a niche in the AI landscape. AIM Brand Solutions, a marketing division within
      AIM, specializes in creating diverse content such as documentaries, public artworks,
      podcasts, videos, articles, and more to effectively tell compelling stories.
      AIM Research produces a series of annual reports on AI & Data Science covering
      every aspect of the industry. Discover how Cypher 2024 expands to the USA, bridging
      AI innovation gaps and tackling the challenges of enterprise AI adoption AIM
      India AIM Research AIM Leaders Council 50 Best Data Science Firms\"}, {\"url\":
      \"https://www.turingpost.com/p/harrison-chase-langchain-ai-agents\", \"content\":
      \"Harrison Chase, founder of LangChain, shared insights on the evolution of
      AI agents and their applications during Sequoia Capital''s AI Ascent. ... Saves
      you a lot of research time, plus gives a flashback to ML history and insights
      into the future. Stay ahead alongside over 73,000 professionals from top AI
      labs, ML startups, and enterprises\"}]", "tool_use_id": "toolu_011WrXBSxr9nrNB5w7QxGUFF",
      "is_error": false}]}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:52:45.186170+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA2RV0W4bRwz8FWIRoC1wUhXZSdp7i402NuCgbpunNoVB7VF3jPZ210uuHNXIvxc8
        SbGcPgnYI4fDIYd6dNy51o3S3y1e3sa/7h/ecL6X128+XXU3//rxLJ27xukuk0WRCPbkGldSsAcU
        YVGM6ho3po6Ca50PWDuanc1ezSTFSDpbLpbni9fLhWucT1Epqmv/fjyCKn229OmndRco1EGKoAOB
        EBY/QCGpQaWBa/AYIZe05Y5glyo8sA6A3teCSsBxncqIyikCrlLVCWWdauyoQFrDDcb+ckCO7cf4
        MV5hKSwpwuWAQsDyLBxjB5e//PYsbQ5XVAiwEEgaCTa0g5w4qhzqfQNpGM9rvpzDZZodarTfxvvj
        p5M04AjBulsulsu5YSzncIF+0xcLbZ/Yo8FtsXTQF+yq5ez1gdXXcEMTRWVR9jIR9GnMVamAeKbo
        aapxZjzHjHEH6+SrtKeErJQ/fF1VDgq4B0+Z4kxSLZ7gdqdDij9+2GUSXzgrZPQb7MlkRgXkETTB
        iBsCViAUpmIvHW0ppDwVrNgTvLfNAsw5sJ+GKxPF8zncFtpyqgL0OVOZ2LdwQetkA1IsyrF/It48
        yR2om4b9Hv3AkeCGsEQLVsIRUOGPtKqicB2VQuDekJuTridNDotKMpUxKbcYuNvvX1rDeAAPR/DJ
        Invyr+bwe2W/gb6kBx1O5b2397CDHjlSBznlGrCw7mx2RvrttfEYa2TdNfsRm68Kr+qkDqxLGmGo
        sSvUiTE5SEpFjPE71qu6mgijV94SdCy+ikzJKcIWy6RqDqjmqD3l13P4tcaOY9/CdYS3uXCwpTxr
        4JNpNaaogwCubZdYBQLW6IfmpLWCPKm2pQIvlgsYOQQTiyOs99CmPZqO9auMqKagqGU8pUw9bilq
        LQRrLiP8Sfc1McIlZlYMc/gwsIDHkUCGVDTsDtwQXrx8AhIic8WWREeKuge+oOiHEctm6vzNHK7H
        jF7/Z1grkKJwR4U6QBDuI6/ZowFxb9yehoa94ZNPshOlsYFsG+ptusFWqoARttNqSd6Opz9scOnp
        Gz8IfH9z815+2M9fUwrydaJHh5xs/v6mPWf/nZiwHRUZODcwoMCKvN21FMmUN95jEj3u4L6DmVl+
        mtW64EgPqWzkpEvJaF6hiKtgQSe7pwl8IbtLp2aGnB4m+VY7CFOn4djp3jAQeEPw7vbD7BxGs7bd
        Cptm7I5mmbsv/zRONOW7QigputZR7O60lugOH4Tuq/nYtbGG0Lg6/Ze1j45jrnqnaUNRXLtc/LRo
        XKp6+nh2/vOXL/8BAAD//wMABqZyviwHAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22ae419e4532cc-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:53:26 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:53:20Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:53:26Z'
      request-id:
      - req_01B7UWY6NpA4GBZ9DRu9YWdS
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:53:11.070630+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1SRXWvbUAyG/4rQzW6Oi5ukKfPN2AalLWWMURhlDHPso8RebSk+0qHxgv/7sNPR
        7Uro4331IJ2wDVhgr/syv/x6fwxfwup5qId6M1zfbNpqPX5DhzYeaJ4iVb8ndBilmwtetVXzbOiw
        l0AdFlh3PgXK1tlVpsJMlq3y1SbfrnJ0WAsbsWHx4/TX1Og4y5dQ4KOAZ32hCNa0CkMitVYYfF2n
        6I260cHdu64DJgpgAko+1g3sZFYQ9KIG6ZCZZMEbQcs7ib0/e1SSDB487z83vmXwHKA1hZ0kDhQv
        4IEMeoIgYI23xXOUdIGTe6MV6cqk8w2Ww815KvPLq5tfcnza7l+q6uNtHKqnT4/H3yM6ZN/PujPm
        rOJDMixOOCSKIxb4vRFodYF/BQHZvVF+wGn66VBNDmUkr8L/UywNpSER14QFp65zmJY3FafzttLk
        mVix2Ky3DiXZv7X319P0BwAA//8DAHnV818FAgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22aee2bec36992-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:53:48 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:53:46Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:53:48Z'
      request-id:
      - req_01Jk8NvFFDybK94i9Qz4cRk5
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}, {"role": "assistant", "content": [{"text": "To answer
      this question accurately, I''ll need to search for the most up-to-date information
      about LangChain and its founder. Let me do that for you.", "type": "text"},
      {"type": "tool_use", "name": "search", "input": {"query": "Who is the founder
      of LangChain?"}, "id": "toolu_015FjoxY6gwbbAHrqbYBTxzy"}]}, {"role": "user",
      "content": [{"type": "tool_result", "content": "[{\"url\": \"https://sfelc.com/speaker/harrison-chase\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://aiconference.com/speakers/harrison-chase/\",
      \"content\": \"Harrison Chase is the co-founder and CEO of LangChain, a company
      formed around the open-source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://tedai-sanfrancisco.ted.com/speakers-1/harrison-chase-/co-founder-and-ceo,-langchain/\",
      \"content\": \"Harrison Chase, a Harvard graduate in statistics and computer
      science, co-founded LangChain to streamline the development of Language Model
      applications with open-source Python/Typescript packages. Chase''s experience
      includes heading the Machine Learning team at Robust Intelligence, focusing
      on the testing and validation of machine learning models, and leading the entity
      linking team at Kensho\"}, {\"url\": \"https://techcrunch.com/author/harrison-chase/\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications\"}, {\"url\": \"https://www.sequoiacap.com/podcast/training-data-harrison-chase/\",
      \"content\": \"Sonya Huang: Hi, and welcome to training data. We have with us
      today Harrison Chase, founder and CEO of LangChain. Harrison is a legend in
      the agent ecosystem, as the product visionary who first connected LLMs with
      tools and actions. And LangChain is the most popular agent building framework
      in the AI space.\"}, {\"url\": \"https://www.youtube.com/watch?v=7D8bw_4hTdo\",
      \"content\": \"Join us for an insightful interview with Harrison Chase, the
      CEO and co-founder of Langchain, as he provides a comprehensive overview of
      Langchain''s innovati\"}, {\"url\": \"https://www.forbes.com/profile/harrison-chase/\",
      \"content\": \"Harrison Chase only cofounded LangChain in late 2022, but the
      company caught instant attention for enabling anyone to build apps powered by
      large language models like GPT-4 in as little as two\"}, {\"url\": \"https://en.wikipedia.org/wiki/LangChain\",
      \"content\": \"In October 2023 LangChain introduced LangServe, a deployment
      tool designed to facilitate the transition from LCEL (LangChain Expression Language)
      prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of
      March 2023, LangChain included integrations with systems including Amazon, Google,
      and Microsoft Azure cloud storage; API wrappers for news, movie information,
      and weather; Bash for summarization, syntax and semantics checking, and execution
      of shell scripts; multiple web scraping subsystems and templates; few-shot learning
      prompt generation support; finding and summarizing \\\"todo\\\" tasks in code;
      Google Drive documents, spreadsheets, and presentations summarization, extraction,
      and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic,
      and Hugging Face language models; iFixit repair guides and wikis search and
      summarization; MapReduce for question answering, combining documents, and question
      generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF
      file text extraction and manipulation; Python and JavaScript code generation,
      analysis, and debugging; Milvus vector database[6] to store and retrieve vector
      embeddings; Weaviate vector database[7] to cache embedding and data objects;
      Redis cache database storage; Python RequestsWrapper and other methods for API
      requests; SQL and NoSQL databases including JSON support; Streamlit, including
      for logging; text mapping for k-nearest neighbors search; time zone conversion
      and calendar operations; tracing and recording stack symbols in threaded and
      asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a
      language model integration framework, LangChain''s use-cases largely overlap
      with those of language models in general, including document analysis and summarization,
      chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in
      October 2022 as an open source project by Harrison Chase, while working at machine
      learning startup Robust Intelligence. In April 2023, LangChain had incorporated
      and the new startup raised over $20 million in funding at a valuation of at
      least $200 million from venture firm Sequoia Capital, a week after announcing
      a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered
      popularity, with improvements from hundreds of contributors on GitHub, trending
      discussions on Twitter, lively activity on the project''s Discord server, many
      YouTube tutorials, and meetups in San Francisco and London. As of April 2023,
      it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal
      links[edit]\"}, {\"url\": \"https://analyticsindiamag.com/people/harrison-chase/\",
      \"content\": \"By AIM The dynamic co-founder and CEO of LangChain, Harrison
      Chase is simplifying the creation of applications powered by LLMs. With a background
      in statistics and computer science from Harvard University, Chase has carved
      a niche in the AI landscape. AIM Brand Solutions, a marketing division within
      AIM, specializes in creating diverse content such as documentaries, public artworks,
      podcasts, videos, articles, and more to effectively tell compelling stories.
      AIM Research produces a series of annual reports on AI & Data Science covering
      every aspect of the industry. Discover how Cypher 2024 expands to the USA, bridging
      AI innovation gaps and tackling the challenges of enterprise AI adoption AIM
      India AIM Research AIM Leaders Council 50 Best Data Science Firms\"}, {\"url\":
      \"https://www.turingpost.com/p/harrison-chase-langchain-ai-agents\", \"content\":
      \"Harrison Chase, founder of LangChain, shared insights on the evolution of
      AI agents and their applications during Sequoia Capital''s AI Ascent. ... Saves
      you a lot of research time, plus gives a flashback to ML history and insights
      into the future. Stay ahead alongside over 73,000 professionals from top AI
      labs, ML startups, and enterprises\"}]", "tool_use_id": "toolu_015FjoxY6gwbbAHrqbYBTxzy",
      "is_error": false}]}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:53:13.741829+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3RUYW8bNwz9K4RQYBtw9mynKTp/a4NhyZagxZYOGNYhoHW8O8068ipKzg5B/vtA
        xUHdDvtkQ0e+9/j4pAcXWrd1o/Z3q/X58JrO1r+vf54vflnvfvpjg+v1+aVrXJ4nsipSxZ5c45JE
        O0DVoBk5u8aN0lJ0W+cjlpYWZ4vzhQoz5cVmtXm5erVZucZ54Uyc3fbPh2fQTP9Ye/3Zureo1IIw
        5IFACZMfIJGWmLWBK/DIMCU5hJZglgL3IQ+1NHAnacQchAF3UnI97aRwSwmkg2vk/mLAwNuP/JFv
        /+cjBIVLTCmoMFwMqLSEG0kEOpEPXfAY41wR1suvCq3VOL0snpGRW7j48d0XDEtr3izh8llAe8rO
        EDETbFabzRJuK9o4Ic9wjwrSdcEHUwARC/uBWkAFZJCJeKFSkiez52/y2bDe+Sw7Sk9wxnu2hPcp
        SIIsoBlTDtx/pm++nuhe0t44MiCM6IfABJEwsbXV/jKBWUIt/Cq7ohmuOFOMoSf21MD9QIlgsK62
        mnNzDZlwrGJeLo80gw0BO/T7PpklJl0z5qA5eK0umg0lUwL1waChSzKa3AOmFj5wOFDSkOcKfL48
        sfRTCX4fZ+gxMLUwyVQippBnYzFJb64MfSwc8txUst0Mb6YUovl21hyX+rSGAVtIGCyjGnquieAM
        XeE2cF9XNoOSL8lSfKAELzYrGEOMFszAz5VPnh4wlqfISmcnkVCzdXxuqXP+Rp+KBIQLnELG2EAn
        Mcp9xYEX68/VSmTuHUjzSKbLut8S+2HEtK/mvFrChxrO6v03aqQtJR3C1JzYZjvZkZeRQJhMn9kw
        iuZnCwF74rzYlRDrRF3CkSwxeuKsTmg56MQXtSJhGHFv/0IGQp0tiS0dKMpU2Qv2BDf2lABOUwy+
        +qNwbD/J+fs5D8Lf384TqU9hyjCh32NPWuf87+X0whpass3gl9sLfUl0opq86KyZxgYmuyTe5o0z
        dJJgCFrvhZV7e9/88RKlnr6aQOHb6+sb/e74SonEpzCjrzPZ9Qh+OFpNFo8uFuIcMD6LOVpTlymd
        aauuH3FODFq6x78ap1mmu0Sowm7riNu7XBK74welT8Uuj9tyibFxpT7m2wcXeCr5LsueWN12s3q9
        apyU/MXhD68fH/8FAAD//wMA0hFTIS0GAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22aef3a88e32c6-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:53:54 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:53:49Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:53:54Z'
      request-id:
      - req_01HxWKuEjZTokR87xSj3FNGK
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:54:04.768568+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1RRW0/bUAz+K5Zf9nKCQluYdt42hLisSIUxBJpQdEjcNuPEbmMfrVGV/46SbmI8
        Wb58F33eY12hx0ZXRX789fP5nV3Wi+ty3j38/P14Kbtvtzt0aN2GhitSDStCh63EYRBUa7XAhg4b
        qSiixzKGVFE2zU4yFWaybJJPZvnpJEeHpbARG/pf+3+kRrsBPhaP9wKB9Q+1YOtaYZtIrRaGUJap
        DUaxc3D1KUZgogpMQCm05RqWMiAIGlGDtMlMsioYQc1LaZtw4HiRZDAPvDpbh5ohcAW1KSwlcUXt
        EczJoCGoBGwdbOTsJB1h797disQi6ZDBGNzQpyI/nun317Pbxd3DzeLx4ub6/iKdPP1o0CGHZsAd
        bA4o3iRDv8dtorZDj3/VQZbv1rDvnx2qyaZoKajwR+VxobRNxCWh5xSjwzS+xu8PCoXJK7Gin01P
        HUqy/2dfpn3/BgAA//8DABCOjgv5AQAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22b0325b034cb6-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:54:42 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:54:40Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:54:42Z'
      request-id:
      - req_01SsSvCQgy3vQfuMCiJiaZLM
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}, {"role": "assistant", "content": [{"text": "To answer
      this question accurately, I''ll need to search for the most up-to-date information
      about LangChain and its founder. Let me do that for you.", "type": "text"},
      {"type": "tool_use", "name": "search", "input": {"query": "founder of LangChain"},
      "id": "toolu_014sKkCQPRVMPXGMJTGu5YSm"}]}, {"role": "user", "content": [{"type":
      "tool_result", "content": "[{\"url\": \"https://sfelc.com/speaker/harrison-chase\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://aiconference.com/speakers/harrison-chase/\",
      \"content\": \"Harrison Chase is the co-founder and CEO of LangChain, a company
      formed around the open-source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://tedai-sanfrancisco.ted.com/speakers-1/harrison-chase-/co-founder-and-ceo,-langchain/\",
      \"content\": \"Harrison Chase, a Harvard graduate in statistics and computer
      science, co-founded LangChain to streamline the development of Language Model
      applications with open-source Python/Typescript packages. Chase''s experience
      includes heading the Machine Learning team at Robust Intelligence, focusing
      on the testing and validation of machine learning models, and leading the entity
      linking team at Kensho\"}, {\"url\": \"https://techcrunch.com/author/harrison-chase/\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications\"}, {\"url\": \"https://www.sequoiacap.com/podcast/training-data-harrison-chase/\",
      \"content\": \"Sonya Huang: Hi, and welcome to training data. We have with us
      today Harrison Chase, founder and CEO of LangChain. Harrison is a legend in
      the agent ecosystem, as the product visionary who first connected LLMs with
      tools and actions. And LangChain is the most popular agent building framework
      in the AI space.\"}, {\"url\": \"https://www.youtube.com/watch?v=7D8bw_4hTdo\",
      \"content\": \"Join us for an insightful interview with Harrison Chase, the
      CEO and co-founder of Langchain, as he provides a comprehensive overview of
      Langchain''s innovati\"}, {\"url\": \"https://www.forbes.com/profile/harrison-chase/\",
      \"content\": \"Harrison Chase only cofounded LangChain in late 2022, but the
      company caught instant attention for enabling anyone to build apps powered by
      large language models like GPT-4 in as little as two\"}, {\"url\": \"https://en.wikipedia.org/wiki/LangChain\",
      \"content\": \"In October 2023 LangChain introduced LangServe, a deployment
      tool designed to facilitate the transition from LCEL (LangChain Expression Language)
      prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of
      March 2023, LangChain included integrations with systems including Amazon, Google,
      and Microsoft Azure cloud storage; API wrappers for news, movie information,
      and weather; Bash for summarization, syntax and semantics checking, and execution
      of shell scripts; multiple web scraping subsystems and templates; few-shot learning
      prompt generation support; finding and summarizing \\\"todo\\\" tasks in code;
      Google Drive documents, spreadsheets, and presentations summarization, extraction,
      and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic,
      and Hugging Face language models; iFixit repair guides and wikis search and
      summarization; MapReduce for question answering, combining documents, and question
      generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF
      file text extraction and manipulation; Python and JavaScript code generation,
      analysis, and debugging; Milvus vector database[6] to store and retrieve vector
      embeddings; Weaviate vector database[7] to cache embedding and data objects;
      Redis cache database storage; Python RequestsWrapper and other methods for API
      requests; SQL and NoSQL databases including JSON support; Streamlit, including
      for logging; text mapping for k-nearest neighbors search; time zone conversion
      and calendar operations; tracing and recording stack symbols in threaded and
      asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a
      language model integration framework, LangChain''s use-cases largely overlap
      with those of language models in general, including document analysis and summarization,
      chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in
      October 2022 as an open source project by Harrison Chase, while working at machine
      learning startup Robust Intelligence. In April 2023, LangChain had incorporated
      and the new startup raised over $20 million in funding at a valuation of at
      least $200 million from venture firm Sequoia Capital, a week after announcing
      a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered
      popularity, with improvements from hundreds of contributors on GitHub, trending
      discussions on Twitter, lively activity on the project''s Discord server, many
      YouTube tutorials, and meetups in San Francisco and London. As of April 2023,
      it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal
      links[edit]\"}, {\"url\": \"https://analyticsindiamag.com/people/harrison-chase/\",
      \"content\": \"By AIM The dynamic co-founder and CEO of LangChain, Harrison
      Chase is simplifying the creation of applications powered by LLMs. With a background
      in statistics and computer science from Harvard University, Chase has carved
      a niche in the AI landscape. AIM Brand Solutions, a marketing division within
      AIM, specializes in creating diverse content such as documentaries, public artworks,
      podcasts, videos, articles, and more to effectively tell compelling stories.
      AIM Research produces a series of annual reports on AI & Data Science covering
      every aspect of the industry. Discover how Cypher 2024 expands to the USA, bridging
      AI innovation gaps and tackling the challenges of enterprise AI adoption AIM
      India AIM Research AIM Leaders Council 50 Best Data Science Firms\"}, {\"url\":
      \"https://www.turingpost.com/p/harrison-chase-langchain-ai-agents\", \"content\":
      \"Harrison Chase, founder of LangChain, shared insights on the evolution of
      AI agents and their applications during Sequoia Capital''s AI Ascent. ... Saves
      you a lot of research time, plus gives a flashback to ML history and insights
      into the future. Stay ahead alongside over 73,000 professionals from top AI
      labs, ML startups, and enterprises\"}]", "tool_use_id": "toolu_014sKkCQPRVMPXGMJTGu5YSm",
      "is_error": false}]}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:54:07.180606+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3SUW28bNxCF/8qAKNAWWKmyfEmjt8QIHAN2YjTOS5rCGHFnVxNxhzQvUreG/3sx
        lFTbafskLXdn5juHh3ww3JqFGVJ/Nzt6ffplLvdXR/2Hi7f9xYf1uy/fxr8G05g8BtKvKCXsyTQm
        eqcLmBKnjJJNYwbfkjMLYx2WlibHk9NJ8iKUJ/PZ/GR2Np+ZxlgvmSSbxe8Ph6aZ/tTy+rMwbzFR
        C14grwgSYbQriJSKy6mBS7AoEKLfcEsw+gJbzitg6XwcMLMXwKUvuRZ3vkhLEXwHVyj9+QpZFl/l
        q9z+z0vgBO8xRk5e4HyFiaZw7SNBCmS5Y4vOjbXD0fS7D7VUZ1o/OXRGaeH83ccXE6ZaPJ/C+wNA
        +3y6gMNMMJ/N54AJUMAHkknyJVpS1d/IZtiu2BFsfVyz9IAZEAa0KxYCRxhFV1PGmEsAJaYWfvPL
        kjJcSibnuCexVEmOp3v6lY6DJdp1H5VLWVLGzCmzTVWK9UMomSIky9oAuugHdWGDsYXPwhuKifNY
        G59M4Sayj5D9jkWh/lHawEpZ2+rY9Z796sCeCQeV9R/QjYq3K+i8LYeUUKrNFXGDjttdCnz3b1Nq
        PlPlO50+8/2+sF27EXpkoRaCD8Vh5DyqC4r45lLVD0U4j02dxAJvQmSne3Xc7Hd+CCgjRGRFS9xL
        jYxk6Iq0LH0DLNYV/Qt+QxF+mM9gYOcUuLr5ie6LZ4RzDJzRVdSz6cuArsVvBTofgXN6EZCbMa+8
        /HI7Bko2csgQ0K6xJ42m5oQH3Y8B1wScgTCN+tzShpwPdUrBnuBafQIMwbGtbu48ezV9irr1kril
        SC2gBnNgIRXKfYn0zDbsdZmsT2PKNDQQNAtW/XVjFWH1hrD7fMSevsNI8NPV1XX6eXfOs/dul0a0
        T2AvT+KPCTac1NJa8uSdZnxJJDWTPATH3Vg5Q/SWUtLM2Ei4i9Mz9RD8tkpdjuAqozsw7iIFjtcE
        Fze3k5NG7dUGnAGttuWlIx2JsFXHIKL0pLP2vlPcKYq0u+z0+cnAjsm1U/P4R2NS9uEuEiYvZmFI
        2rtcopj9i0T3RY+IWUhxrjGl3tOLB8MSSr7Lfk2SzGI+e3XWGF/yi8VfXz8+/g0AAP//AwD0aedG
        CAYAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22b04158a84cb1-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:54:48 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:54:42Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:54:48Z'
      request-id:
      - req_01Ty6RLDuDeMCfmVfunAmMKp
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:54:32.018816+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1SRTW8TQQyG/4rlC5fZapO0KZ0LEqAWlB4Q4UMBodWw42QXdu1k7KGNov3vaDeg
        wsnyx/v6kX3CNqLHXndVObtpZ6vHu+cPH3/Zdbh7t9ysbjerNTq0457GKVINO0KHSbqxEFRbtcCG
        DnuJ1KHHugs5UrEorgoVZrJiXs4vy+W8RIe1sBEb+q+nv6ZGj6N8Ch4/CATWB0pgTatwyKTWCkOo
        65yCUXd08PZZ1wETRTABpZDqBrYyKgh6UYO8L0yKGIyg5a2kPpw9vks2uA+8e9WEliFwhNYUtpI5
        UrqAezLoCaKANcEmz6PkCxzcE61IV2UdbzAdbsxzVc7WdBVvfzRfXu7im0+vZ+v3i2aeNuiQQz/q
        zpijivfZ0J/wkCkd0ePnRqDVCf4PCMj2ifIFDsM3h2qyrxIFFf6fYmooHTJxTeg5d53DPL3Jn87b
        KpOfxIr+crF0KNn+rd1cD8NvAAAA//8DAPfUzMAFAgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22b0dcbd844caf-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:55:09 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:55:07Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:55:09Z'
      request-id:
      - req_018TP5XzbuQ82VrDc4fbETo3
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}, {"role": "assistant", "content": [{"text": "To answer
      this question accurately, I''ll need to search for the most up-to-date information
      about LangChain and its founder. Let me do that for you.", "type": "text"},
      {"type": "tool_use", "name": "search", "input": {"query": "Who is the founder
      of LangChain?"}, "id": "toolu_01Se5dFjhZBgdHVD1SR3h2rY"}]}, {"role": "user",
      "content": [{"type": "tool_result", "content": "[{\"url\": \"https://sfelc.com/speaker/harrison-chase\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://aiconference.com/speakers/harrison-chase/\",
      \"content\": \"Harrison Chase is the co-founder and CEO of LangChain, a company
      formed around the open-source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://tedai-sanfrancisco.ted.com/speakers-1/harrison-chase-/co-founder-and-ceo,-langchain/\",
      \"content\": \"Harrison Chase, a Harvard graduate in statistics and computer
      science, co-founded LangChain to streamline the development of Language Model
      applications with open-source Python/Typescript packages. Chase''s experience
      includes heading the Machine Learning team at Robust Intelligence, focusing
      on the testing and validation of machine learning models, and leading the entity
      linking team at Kensho\"}, {\"url\": \"https://techcrunch.com/author/harrison-chase/\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications\"}, {\"url\": \"https://www.sequoiacap.com/podcast/training-data-harrison-chase/\",
      \"content\": \"Sonya Huang: Hi, and welcome to training data. We have with us
      today Harrison Chase, founder and CEO of LangChain. Harrison is a legend in
      the agent ecosystem, as the product visionary who first connected LLMs with
      tools and actions. And LangChain is the most popular agent building framework
      in the AI space.\"}, {\"url\": \"https://www.youtube.com/watch?v=7D8bw_4hTdo\",
      \"content\": \"Join us for an insightful interview with Harrison Chase, the
      CEO and co-founder of Langchain, as he provides a comprehensive overview of
      Langchain''s innovati\"}, {\"url\": \"https://www.forbes.com/profile/harrison-chase/\",
      \"content\": \"Harrison Chase only cofounded LangChain in late 2022, but the
      company caught instant attention for enabling anyone to build apps powered by
      large language models like GPT-4 in as little as two\"}, {\"url\": \"https://en.wikipedia.org/wiki/LangChain\",
      \"content\": \"In October 2023 LangChain introduced LangServe, a deployment
      tool designed to facilitate the transition from LCEL (LangChain Expression Language)
      prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of
      March 2023, LangChain included integrations with systems including Amazon, Google,
      and Microsoft Azure cloud storage; API wrappers for news, movie information,
      and weather; Bash for summarization, syntax and semantics checking, and execution
      of shell scripts; multiple web scraping subsystems and templates; few-shot learning
      prompt generation support; finding and summarizing \\\"todo\\\" tasks in code;
      Google Drive documents, spreadsheets, and presentations summarization, extraction,
      and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic,
      and Hugging Face language models; iFixit repair guides and wikis search and
      summarization; MapReduce for question answering, combining documents, and question
      generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF
      file text extraction and manipulation; Python and JavaScript code generation,
      analysis, and debugging; Milvus vector database[6] to store and retrieve vector
      embeddings; Weaviate vector database[7] to cache embedding and data objects;
      Redis cache database storage; Python RequestsWrapper and other methods for API
      requests; SQL and NoSQL databases including JSON support; Streamlit, including
      for logging; text mapping for k-nearest neighbors search; time zone conversion
      and calendar operations; tracing and recording stack symbols in threaded and
      asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a
      language model integration framework, LangChain''s use-cases largely overlap
      with those of language models in general, including document analysis and summarization,
      chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in
      October 2022 as an open source project by Harrison Chase, while working at machine
      learning startup Robust Intelligence. In April 2023, LangChain had incorporated
      and the new startup raised over $20 million in funding at a valuation of at
      least $200 million from venture firm Sequoia Capital, a week after announcing
      a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered
      popularity, with improvements from hundreds of contributors on GitHub, trending
      discussions on Twitter, lively activity on the project''s Discord server, many
      YouTube tutorials, and meetups in San Francisco and London. As of April 2023,
      it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal
      links[edit]\"}, {\"url\": \"https://analyticsindiamag.com/people/harrison-chase/\",
      \"content\": \"By AIM The dynamic co-founder and CEO of LangChain, Harrison
      Chase is simplifying the creation of applications powered by LLMs. With a background
      in statistics and computer science from Harvard University, Chase has carved
      a niche in the AI landscape. AIM Brand Solutions, a marketing division within
      AIM, specializes in creating diverse content such as documentaries, public artworks,
      podcasts, videos, articles, and more to effectively tell compelling stories.
      AIM Research produces a series of annual reports on AI & Data Science covering
      every aspect of the industry. Discover how Cypher 2024 expands to the USA, bridging
      AI innovation gaps and tackling the challenges of enterprise AI adoption AIM
      India AIM Research AIM Leaders Council 50 Best Data Science Firms\"}, {\"url\":
      \"https://www.turingpost.com/p/harrison-chase-langchain-ai-agents\", \"content\":
      \"Harrison Chase, founder of LangChain, shared insights on the evolution of
      AI agents and their applications during Sequoia Capital''s AI Ascent. ... Saves
      you a lot of research time, plus gives a flashback to ML history and insights
      into the future. Stay ahead alongside over 73,000 professionals from top AI
      labs, ML startups, and enterprises\"}]", "tool_use_id": "toolu_01Se5dFjhZBgdHVD1SR3h2rY",
      "is_error": false}]}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:54:34.582739+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA2yUYW8bNwyG/wpxGLANOHuuk3SAv2VGsWZz0CLLgA7rENA6+k61jlQkyq5R9L8P
        lJ0sSffpAB1FPnz5Ul8a3zWLZsz93ezVm9vzv8ryfjVf9mfp5mJz8+HD+NvvTdvoIZJFUc7YU9M2
        SYIdYM4+K7I2bTNKR6FZNC5g6WhyNrmYZGEmncxn8/PZ6/msaRsnrMTaLP7+8pBU6bNdr59Fczsg
        b+EgBTaSICbZ+c5zDyPB3usAOhBIjJK0sNcDqEAmTG6o8fZ3lKxQ4kRl0qESeN5IGlG98BR+wUwd
        CNfI08VEuQTNLVyBQwYnvPEdsYYDIOc9JcNJcF8oW5LFR/7ItwPBRgp3lEA2sELulwN6Bp/hLabk
        szAsB8w0reFyasXwEkGV4bPWVK+mL25YDhaFTyVr5TwVamFdjgdOJg/FkTtYvnn3DKKWnE+fUO0x
        Q8DCbqAOPMM7p7KmBPPZfA6YARkkEk+ylOTIWD+RU1gfXqLtBx8IBqoZ95K2NhtUQBjRDZ4JAmFi
        O82KSUsEhyFQBzeytn6uWCkE3xO7ozRn01PqwThgjW7bJ2vOOLOi+qze5dqokzEWpQTZeUsAmySj
        Ie4wdfAn+x2l7PVQE59P4X3yZgo5shjUoyStNWFcpuf1iX31wK6Eo7X1P9CtaVDt5sqDl8wYpgN3
        sMPgu2o2G8k3otQlyZXv4umA7ot323CAHj1TB1FiCZjM4P7o1csr636spm8BVRO6WnQo3CXqspUz
        WyW/LiopG9ivXt+WdeVak5OxQsLedxQO0PnsSrYWVKJ3Fr/D5KVkiAHVluYI+noKVwyXMflghjlr
        n9qdnaQoCZW6aqQ6I+RDLZrQW/7se/Yb75AVNoVtn1u7GUpdbdlRgu/mMxh9CCZcneofdF/EIywx
        esXQmrKlzqYuwKmImrRZ7frj/Qr98xRu/wv8PsNouHVotl/y3PDvDzoI/3R7iJRd8lEhottiTxl0
        MHv70Ww04pbAKxDm+vJ0tKMgsepRsCe4tvECxhi8qybILUSznrNxhsdpJsIw2sQurwB7Yj36e7W6
        hh9WmHp6kfJHiLKnZBo/yV0b/fbtcMLZd8do2PnshTE9NVKOaD5+Bmav5+CPO22hzp7uo8NWq+t8
        enxFwpHUzFe7G3H7bK9AmKyxx5f4ZGXYJBzJsudaa118qNN/VGDafP2nbbJKvEuEWbhZNMTdnZbE
        zelHpvtiS9gs/lVeaU6OjlIpuDqyqlbKzCsoLYkvyc9OzStWsjIysDDQUcovLUEWNDY2q60FAAAA
        //8DAHryTTDvBgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22b0ec98794caf-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:55:17 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:55:10Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:55:17Z'
      request-id:
      - req_011iT4S1koK6LtTJefPZgpb9
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:54:53.846143+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1RRS2vcQAz+K0KXXsbBu5um6dySQCAQckiXPijFTD3y2slYsmc0JO7i/17sbUl7
        Enp8Dz4dsfNosU+HqtxsPrdPfjNcf2A3Svvl5uGXxKtLNKjTQMsVpeQOhAajhGXgUuqSOlY02Iun
        gBbr4LKnYle8L5IwkxbbcnteXmxLNFgLK7Gi/X78S6r0usDXYnEv4Di9UARtuwRjpqSdMLi6ztEp
        hcnA3bsQgIk8qEAiF+sWGlkQBL0khTwUKoV3StBxI7F3J46fkhXuHR9uWtcxOPbQaYJGMnuKZ3BP
        Cj2BF9DW6co5ST7D2by5FQlVTksGa3BLn6tyczt9uv76bV9f7X39eCnj+Hpo+hc0yK5fcCebC4qH
        rGiPOGaKE1r8ow7SvFnDef5hMKkMVSSXhP9XXheJxkxcE1rOIRjM62vs8aRQqTwTJ7TnuwuDkvXf
        2cfdPP8GAAD//wMAgzLCHfkBAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22b1653bb54cb6-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:55:32 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:55:29Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:55:32Z'
      request-id:
      - req_01RU57s1YVTHykXPQ2qnPNr4
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}, {"role": "assistant", "content": [{"text": "To answer
      this question accurately, I''ll need to search for the most up-to-date information
      about LangChain and its founder. Let me do that for you.", "type": "text"},
      {"type": "tool_use", "name": "search", "input": {"query": "founder of LangChain"},
      "id": "toolu_01FySBXYTcATdcR8oqqxgfmw"}]}, {"role": "user", "content": [{"type":
      "tool_result", "content": "[{\"url\": \"https://sfelc.com/speaker/harrison-chase\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://aiconference.com/speakers/harrison-chase/\",
      \"content\": \"Harrison Chase is the co-founder and CEO of LangChain, a company
      formed around the open-source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://tedai-sanfrancisco.ted.com/speakers-1/harrison-chase-/co-founder-and-ceo,-langchain/\",
      \"content\": \"Harrison Chase, a Harvard graduate in statistics and computer
      science, co-founded LangChain to streamline the development of Language Model
      applications with open-source Python/Typescript packages. Chase''s experience
      includes heading the Machine Learning team at Robust Intelligence, focusing
      on the testing and validation of machine learning models, and leading the entity
      linking team at Kensho\"}, {\"url\": \"https://techcrunch.com/author/harrison-chase/\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications\"}, {\"url\": \"https://www.sequoiacap.com/podcast/training-data-harrison-chase/\",
      \"content\": \"Sonya Huang: Hi, and welcome to training data. We have with us
      today Harrison Chase, founder and CEO of LangChain. Harrison is a legend in
      the agent ecosystem, as the product visionary who first connected LLMs with
      tools and actions. And LangChain is the most popular agent building framework
      in the AI space.\"}, {\"url\": \"https://www.youtube.com/watch?v=7D8bw_4hTdo\",
      \"content\": \"Join us for an insightful interview with Harrison Chase, the
      CEO and co-founder of Langchain, as he provides a comprehensive overview of
      Langchain''s innovati\"}, {\"url\": \"https://www.forbes.com/profile/harrison-chase/\",
      \"content\": \"Harrison Chase only cofounded LangChain in late 2022, but the
      company caught instant attention for enabling anyone to build apps powered by
      large language models like GPT-4 in as little as two\"}, {\"url\": \"https://en.wikipedia.org/wiki/LangChain\",
      \"content\": \"In October 2023 LangChain introduced LangServe, a deployment
      tool designed to facilitate the transition from LCEL (LangChain Expression Language)
      prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of
      March 2023, LangChain included integrations with systems including Amazon, Google,
      and Microsoft Azure cloud storage; API wrappers for news, movie information,
      and weather; Bash for summarization, syntax and semantics checking, and execution
      of shell scripts; multiple web scraping subsystems and templates; few-shot learning
      prompt generation support; finding and summarizing \\\"todo\\\" tasks in code;
      Google Drive documents, spreadsheets, and presentations summarization, extraction,
      and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic,
      and Hugging Face language models; iFixit repair guides and wikis search and
      summarization; MapReduce for question answering, combining documents, and question
      generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF
      file text extraction and manipulation; Python and JavaScript code generation,
      analysis, and debugging; Milvus vector database[6] to store and retrieve vector
      embeddings; Weaviate vector database[7] to cache embedding and data objects;
      Redis cache database storage; Python RequestsWrapper and other methods for API
      requests; SQL and NoSQL databases including JSON support; Streamlit, including
      for logging; text mapping for k-nearest neighbors search; time zone conversion
      and calendar operations; tracing and recording stack symbols in threaded and
      asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a
      language model integration framework, LangChain''s use-cases largely overlap
      with those of language models in general, including document analysis and summarization,
      chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in
      October 2022 as an open source project by Harrison Chase, while working at machine
      learning startup Robust Intelligence. In April 2023, LangChain had incorporated
      and the new startup raised over $20 million in funding at a valuation of at
      least $200 million from venture firm Sequoia Capital, a week after announcing
      a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered
      popularity, with improvements from hundreds of contributors on GitHub, trending
      discussions on Twitter, lively activity on the project''s Discord server, many
      YouTube tutorials, and meetups in San Francisco and London. As of April 2023,
      it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal
      links[edit]\"}, {\"url\": \"https://analyticsindiamag.com/people/harrison-chase/\",
      \"content\": \"By AIM The dynamic co-founder and CEO of LangChain, Harrison
      Chase is simplifying the creation of applications powered by LLMs. With a background
      in statistics and computer science from Harvard University, Chase has carved
      a niche in the AI landscape. AIM Brand Solutions, a marketing division within
      AIM, specializes in creating diverse content such as documentaries, public artworks,
      podcasts, videos, articles, and more to effectively tell compelling stories.
      AIM Research produces a series of annual reports on AI & Data Science covering
      every aspect of the industry. Discover how Cypher 2024 expands to the USA, bridging
      AI innovation gaps and tackling the challenges of enterprise AI adoption AIM
      India AIM Research AIM Leaders Council 50 Best Data Science Firms\"}, {\"url\":
      \"https://www.turingpost.com/p/harrison-chase-langchain-ai-agents\", \"content\":
      \"Harrison Chase, founder of LangChain, shared insights on the evolution of
      AI agents and their applications during Sequoia Capital''s AI Ascent. ... Saves
      you a lot of research time, plus gives a flashback to ML history and insights
      into the future. Stay ahead alongside over 73,000 professionals from top AI
      labs, ML startups, and enterprises\"}]", "tool_use_id": "toolu_01FySBXYTcATdcR8oqqxgfmw",
      "is_error": false}]}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.\n\nSystem time: 2024-11-13T23:54:56.977251+00:00",
      "tools": [{"name": "search", "description": "Search for general web results.
      This function performs a search using the Tavily search engine, which is designed\nto
      provide comprehensive, accurate, and trusted results. It''s particularly useful\nfor
      answering questions about current events.", "input_schema": {"properties": {"query":
      {"type": "string"}}, "required": ["query"], "type": "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3RVbW/bRgz+K4RQYBsge4nTppu/tdnQZEnQbnWHDesQ0CdaYn3iXY48p1rR/z6c
        bDd2h30yJB3Jh8/L+VPFTTWvem3vTk6vf/1w+ePpu9D8IYvww0eJv5xd/35d1ZUNkcopUsWWqrpK
        wZcXqMpqKFbVVR8a8tW8ch5zQ5OzybOJBhGyyexk9vTkfHZS1ZULYiRWzf/6tG9q9LGUjz/z6iUq
        NRAErCNQwuQ6SKTZm9ZwBQ4FYgobbgiGkOGBrQOWVUg9GgcBXIZsY/EqZGkoQVjBDUp70SHL/L28
        l8X/fARWuMSUWIPARYdKU1gEWBL0IRHERI6VauionCwjXJjsG6E0cPHz66OGU7ikRICJQENPsKYB
        YmAx3cE8njb2OIZ6Ov36zJeRzSFwAY9GMDuZzaalbjY9XgvBhT6iDFCYogYwlSYQIslEQ06O4M1g
        XZDvF0Okty5xNIjo1thS2RUNkHuwAD2uCdiAUIfy3NCGfIjjvIwtwW3xAWCMnt2oiY6QzqbwJnFI
        pUYNk7G0jyDrr/acvxcAmMANNSPTtzdghD2gwW9hmdXgSoy855bEUQ0ocHvzOurBni7vnUQ6Div0
        btBzs3VKWEGPrmMh8IRJypHRwwXv0XASYxvAs6zLoT2QaxLtwrjc0+lOng4L2Ut063bLMEvZ1liN
        nY4QCsJslEAdF/CwSqEv628wNfBOeENJ2Yax8bNDIe8zu7UfoEUWaiCGmD2mAo23eXlxVbr3WdiG
        epuNErjEyzwKsR3VZWkSNVoY2KlHSQtTr9gu87IGdMYbgobVZdWxMggsHthsZ/WfWF1ITT0+SO4p
        hazwZ8iLvCSwbCEx+q3y51O4EngRE/vi0LP6yLkupBgSWjFl4W70Ro5j44RcNFRuhVfsUAxWWRqW
        du+P1xtK8GR2Aj17X1Rl2R8pEmERPH/RG61IrVYqHktGUjYklhPBilMPb+k+B0a4wMiGfu+HRccK
        DnuCD8WBCA9Ea8DVlhQJWdw4F56cPnZXouKCDan1VBYo016SuK7HtB4Jev6flLNCIhda4X/2vJTL
        Y8VtwfioNralJbmggxr1NcQSLFds4cesF/2F3C5sqaWvcqrw7c3NrX63NYuF4LcmLQ7YJ/cgpNu7
        7hjsN1pIbShpx7EeE7AkV+473FsUVgl7eghpPWJaZvZbhQ4uCYjhgRI1sBzAj0j9Huk2leB5TfDq
        zWLytAYSXPrS4sDAFsAlKvfgi6vJvhvGqNv7m1DZD+N2uyBNq89/15VaiHeJUINU84qkubOcpNp9
        ULrPJaXVXLL3dZXHP8D5p4olZruzsCbRaj47eX5eVyHb4cuz5+efP/8LAAD//wMAjIY6NGEHAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22b178d9d04cb4-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:55:39 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:55:32Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:55:39Z'
      request-id:
      - req_015HcqrgirHzeLfD6UpmyE4r
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.", "tools": [{"name": "search", "description": "Search
      for general web results. This function performs a search using the Tavily search
      engine, which is designed\nto provide comprehensive, accurate, and trusted results.
      It''s particularly useful\nfor answering questions about current events.", "input_schema":
      {"properties": {"query": {"type": "string"}}, "required": ["query"], "type":
      "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1SR3WrcQAyFX0Xopjfj4HWzKZm7JrTQsimhBAIpxcza8nqoLe2ONLRm8bsXe1vS
        Xgn9nKMP6YyxRY+jHupy8/jxOcfbB9me7qqc08uXd81Ee3Ro05GWKVINB0KHSYalEFSjWmBDh6O0
        NKDHZgi5peJtsS1UmMmKqqyuy5uqRIeNsBEb+m/nv6ZGvxb5Gjw+CQTWn5TA+qhwyqQWhSE0TU7B
        aJgcfHozDMBELZiAUkhND50sCoJR1CAfC5OiDUYQuZM0hovHXrLBLvDhvg+RIXAL0RQ6ydxSuoId
        GYwErYD1wVbPSfIVzu6VVmSosy43WA+35LkuN7v3U5zuuj1/eHmi/ePnr4ftw31ChxzGRXfBXFR8
        zIb+jKdMaUKPz71A1BX+DwhI90qJ8/zdoZoc60RBhf+HWBtKp0zcEHrOw+Awr1/y58uy2uQHsaK/
        3lQOJdu/tdubef4NAAD//wMAEAehhwQCAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22b64a18a54caf-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:58:52 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:58:49Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:58:52Z'
      request-id:
      - req_01JfEnoQAvmWG3PFoZTmVtmb
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
- request:
    body: '{"max_tokens": 1024, "messages": [{"role": "user", "content": "Who is the
      founder of LangChain?"}, {"role": "assistant", "content": [{"text": "To answer
      this question accurately, I''ll need to search for the most up-to-date information
      about LangChain and its founder. Let me do that for you.", "type": "text"},
      {"type": "tool_use", "name": "search", "input": {"query": "Who is the founder
      of LangChain"}, "id": "toolu_01LAyiyBfbnEZTebPJRg5MCr"}]}, {"role": "user",
      "content": [{"type": "tool_result", "content": "[{\"url\": \"https://sfelc.com/speaker/harrison-chase\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://aiconference.com/speakers/harrison-chase/\",
      \"content\": \"Harrison Chase is the co-founder and CEO of LangChain, a company
      formed around the open-source Python/Typescript packages that aim to make it
      easy to develop Language Model applications. Prior to starting LangChain, he
      led the ML team at Robust Intelligence (an MLOps company focused on testing
      and validation of machine learning models), led the\"}, {\"url\": \"https://tedai-sanfrancisco.ted.com/speakers-1/harrison-chase-/co-founder-and-ceo,-langchain/\",
      \"content\": \"Harrison Chase, a Harvard graduate in statistics and computer
      science, co-founded LangChain to streamline the development of Language Model
      applications with open-source Python/Typescript packages. Chase''s experience
      includes heading the Machine Learning team at Robust Intelligence, focusing
      on the testing and validation of machine learning models, and leading the entity
      linking team at Kensho\"}, {\"url\": \"https://techcrunch.com/author/harrison-chase/\",
      \"content\": \"Harrison Chase is the CEO and co-founder of LangChain, a company
      formed around the open source Python/Typescript packages that aim to make it
      easy to develop Language Model applications\"}, {\"url\": \"https://www.sequoiacap.com/podcast/training-data-harrison-chase/\",
      \"content\": \"Sonya Huang: Hi, and welcome to training data. We have with us
      today Harrison Chase, founder and CEO of LangChain. Harrison is a legend in
      the agent ecosystem, as the product visionary who first connected LLMs with
      tools and actions. And LangChain is the most popular agent building framework
      in the AI space.\"}, {\"url\": \"https://www.youtube.com/watch?v=7D8bw_4hTdo\",
      \"content\": \"Join us for an insightful interview with Harrison Chase, the
      CEO and co-founder of Langchain, as he provides a comprehensive overview of
      Langchain''s innovati\"}, {\"url\": \"https://www.forbes.com/profile/harrison-chase/\",
      \"content\": \"Harrison Chase only cofounded LangChain in late 2022, but the
      company caught instant attention for enabling anyone to build apps powered by
      large language models like GPT-4 in as little as two\"}, {\"url\": \"https://en.wikipedia.org/wiki/LangChain\",
      \"content\": \"In October 2023 LangChain introduced LangServe, a deployment
      tool designed to facilitate the transition from LCEL (LangChain Expression Language)
      prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of
      March 2023, LangChain included integrations with systems including Amazon, Google,
      and Microsoft Azure cloud storage; API wrappers for news, movie information,
      and weather; Bash for summarization, syntax and semantics checking, and execution
      of shell scripts; multiple web scraping subsystems and templates; few-shot learning
      prompt generation support; finding and summarizing \\\"todo\\\" tasks in code;
      Google Drive documents, spreadsheets, and presentations summarization, extraction,
      and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic,
      and Hugging Face language models; iFixit repair guides and wikis search and
      summarization; MapReduce for question answering, combining documents, and question
      generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF
      file text extraction and manipulation; Python and JavaScript code generation,
      analysis, and debugging; Milvus vector database[6] to store and retrieve vector
      embeddings; Weaviate vector database[7] to cache embedding and data objects;
      Redis cache database storage; Python RequestsWrapper and other methods for API
      requests; SQL and NoSQL databases including JSON support; Streamlit, including
      for logging; text mapping for k-nearest neighbors search; time zone conversion
      and calendar operations; tracing and recording stack symbols in threaded and
      asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a
      language model integration framework, LangChain''s use-cases largely overlap
      with those of language models in general, including document analysis and summarization,
      chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in
      October 2022 as an open source project by Harrison Chase, while working at machine
      learning startup Robust Intelligence. In April 2023, LangChain had incorporated
      and the new startup raised over $20 million in funding at a valuation of at
      least $200 million from venture firm Sequoia Capital, a week after announcing
      a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered
      popularity, with improvements from hundreds of contributors on GitHub, trending
      discussions on Twitter, lively activity on the project''s Discord server, many
      YouTube tutorials, and meetups in San Francisco and London. As of April 2023,
      it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal
      links[edit]\"}, {\"url\": \"https://analyticsindiamag.com/people/harrison-chase/\",
      \"content\": \"By AIM The dynamic co-founder and CEO of LangChain, Harrison
      Chase is simplifying the creation of applications powered by LLMs. With a background
      in statistics and computer science from Harvard University, Chase has carved
      a niche in the AI landscape. AIM Brand Solutions, a marketing division within
      AIM, specializes in creating diverse content such as documentaries, public artworks,
      podcasts, videos, articles, and more to effectively tell compelling stories.
      AIM Research produces a series of annual reports on AI & Data Science covering
      every aspect of the industry. Discover how Cypher 2024 expands to the USA, bridging
      AI innovation gaps and tackling the challenges of enterprise AI adoption AIM
      India AIM Research AIM Leaders Council 50 Best Data Science Firms\"}, {\"url\":
      \"https://www.turingpost.com/p/harrison-chase-langchain-ai-agents\", \"content\":
      \"Harrison Chase, founder of LangChain, shared insights on the evolution of
      AI agents and their applications during Sequoia Capital''s AI Ascent. ... Saves
      you a lot of research time, plus gives a flashback to ML history and insights
      into the future. Stay ahead alongside over 73,000 professionals from top AI
      labs, ML startups, and enterprises\"}]", "tool_use_id": "toolu_01LAyiyBfbnEZTebPJRg5MCr",
      "is_error": false}]}], "model": "claude-3-5-sonnet-20240620", "system": "You
      are a helpful AI assistant.", "tools": [{"name": "search", "description": "Search
      for general web results. This function performs a search using the Tavily search
      engine, which is designed\nto provide comprehensive, accurate, and trusted results.
      It''s particularly useful\nfor answering questions about current events.", "input_schema":
      {"properties": {"query": {"type": "string"}}, "required": ["query"], "type":
      "object"}}]}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3RU0W4bRwz8FeIQoC1wEmQ5KVC/2UZQu5DQNEmf6iKg9nh3jPa45yVPqhD03wuu
        LEdx26cFdpfkcGbILxU31VU1aPdpcbFu9q8vfnv/y0/j5frx1j7vbldv391UdWWHkfwXqWJHVV3l
        FP0CVVkNxaq6GlJDsbqqQsSpodnl7M1MkwjZbLlYvl78uFxUdRWSGIlVV398OSU1+svDy3FV3aBS
        A0nAegIlzKGHTDpF0xruIaBASNJyQ2LxACi6pwyHNGV4nEiNkwBu0mQlQZsmaShDamGF0t32yDJ/
        kAf5+D+PwAp3mDNrErjtUWkO65QJdKTALQeM8XDlGS7mLz56qNcMaXbKjNLA7dtfX5ZfzuHuVL45
        ry0Q0QiWi+WyBhY29nKACiiQRpKZpikHgjGnzxQM9j1Hgn3KW5YO0ABhwNCzEETCLH6rhtmmERw6
        NfA+bSY1uBejGLkjCTR/kMv5GY49KoRMaNSAJRhwS8AGhMqU/aahHcU0Ao5j5IBOusKY9pSpgc0B
        Vpg7Kgkn7AjW7gyF71ertf5Q6P+QBgJsGvZQjMBilF096aDFYPqk4QuGnc9nmCcVjk+9kwQbDNsu
        O7FOphoaq3HQEhnSME5GGTSwtw1tToOX2GFu4HfhHWVlOxwVepc5lWYLfw7suXINvfPbFLnXT3yv
        Tnwb4eBS/AfRNbQpTOq/3OFPDTu2HUZuCpFuln9pWGZLX+r0OHHYxgN0yEINjGmcIma2gzfv2K7v
        velhErZDDXu23ofHMm+mo2aFgX6SJlOjXvlJWcrqCH9mu5s2BSAG4x1Bwxom1RKcBHaYOU0KY0Rr
        Ux4c4us53Atcj5mjO/my/sbhIeUx5WKtopiLgnIoNTKyD79yJ2XUxKCdpGHp5vCxpwNkCsQ73w87
        yvBquYCBY3TSWE5fj1Owwzg904nmTKp5xNeQ0vsHepwSI9ziyIaxBu1TLoultTLAkiYJJS28uvga
        rERusR2pDeQ4PdkNSegHzNv5g7w5F8rNuaHgpk9CDsnVGZLaSTTAjsRmm4ljaaLNOJDPtZ5pqSO6
        h7aS9gJtyi6mUDiac7XWo8KWUtRnzZJombhvJ+k7hR27iseQl0hJivF5GCO3h1J+zCmQFo+U1eA1
        r+9np6E/3wS1bwx/Z4PBdycGD+VNpLPl4RZzkBufB1IlBYy8pXn19591pZbGT/kfpSYW5+cpWSml
        5qXEl5QW5SlBJYpTC0tB+UnJKq80J0dHqRRcK1lVK2XmFZSWxJfkZ6fmFStZGRmYmuoo5ZeWIAsa
        mxjW1gIAAAD//wMALzV23/YGAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e22b65b6bda4caf-PHL
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 13 Nov 2024 23:58:59 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Robots-Tag:
      - none
      anthropic-ratelimit-requests-limit:
      - '4000'
      anthropic-ratelimit-requests-remaining:
      - '3999'
      anthropic-ratelimit-requests-reset:
      - '2024-11-13T23:58:52Z'
      anthropic-ratelimit-tokens-limit:
      - '400000'
      anthropic-ratelimit-tokens-remaining:
      - '400000'
      anthropic-ratelimit-tokens-reset:
      - '2024-11-13T23:58:59Z'
      request-id:
      - req_013QF9W14BVn6VHs6PZwfFs7
      via:
      - 1.1 google
    status:
      code: 200
      message: OK
version: 1
</file>

<file path="tests/integration_tests/__init__.py">
"""Define any integration tests you want in this directory."""
</file>

<file path="tests/integration_tests/test_graph.py">
import pytest
from langsmith import unit

from react_agent import graph


@pytest.mark.asyncio
@unit
async def test_react_agent_simple_passthrough() -> None:
    res = await graph.ainvoke(
        {"messages": [("user", "Who is the founder of LangChain?")]},
        {"configurable": {"system_prompt": "You are a helpful AI assistant."}},
    )

    assert "harrison" in str(res["messages"][-1].content).lower()
</file>

<file path="tests/unit_tests/__init__.py">
"""Define any unit tests you may want in this directory."""
</file>

<file path="tests/unit_tests/test_configuration.py">
from react_agent.configuration import Configuration


def test_configuration_empty() -> None:
    Configuration.from_runnable_config({})
</file>

<file path=".gitignore">
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class
uv.lock

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST
.langgraph_api/
# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/
.qodo
</file>

<file path=".repomixignore">
# Add patterns to ignore here, one per line
# Example:
# *.log
# tmp/
.venv/
src/react_agent/tools/tavily.py
src/react_agent/tools/firecrawl.py
src/react_agent/graphs/error.py
src/react_agent/graphs/graph.py
src/react_agent/graphs/analysis.py
</file>

<file path="langgraph.json">
{
  "dockerfile_lines": [],
  "graphs": {
    "agent": "src/react_agent/graphs/graph.py:graph",
    "analysis": "src/react_agent/graphs/analysis.py:graph",
    "research": "src/react_agent/graphs/research.py:research_graph"
  },
  "env": ".env",
  "python_version": "3.11",
  "dependencies": [
    "."
  ]
}
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2024 LangChain

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="Makefile">
.PHONY: all format lint test tests test_watch integration_tests docker_tests help extended_tests

# Default target executed when no arguments are given to make.
all: help

# Define a variable for the test file path.
TEST_FILE ?= tests/unit_tests/

test:
	python -m pytest $(TEST_FILE)

test_watch:
	python -m ptw --snapshot-update --now . -- -vv tests/unit_tests

test_profile:
	python -m pytest -vv tests/unit_tests/ --profile-svg

extended_tests:
	python -m pytest --only-extended $(TEST_FILE)


######################
# LINTING AND FORMATTING
######################

# Define a variable for Python and notebook files.
PYTHON_FILES=src/
MYPY_CACHE=.mypy_cache
lint format: PYTHON_FILES=.
lint_diff format_diff: PYTHON_FILES=$(shell git diff --name-only --diff-filter=d main | grep -E '\.py$$|\.ipynb$$')
lint_package: PYTHON_FILES=src
lint_tests: PYTHON_FILES=tests
lint_tests: MYPY_CACHE=.mypy_cache_test

lint lint_diff lint_package lint_tests:
	python -m ruff check .
	[ "$(PYTHON_FILES)" = "" ] || python -m ruff format $(PYTHON_FILES) --diff
	[ "$(PYTHON_FILES)" = "" ] || python -m ruff check --select I $(PYTHON_FILES)
	[ "$(PYTHON_FILES)" = "" ] || python -m mypy --strict $(PYTHON_FILES)
	[ "$(PYTHON_FILES)" = "" ] || mkdir -p $(MYPY_CACHE) && python -m mypy --strict $(PYTHON_FILES) --cache-dir $(MYPY_CACHE)

format format_diff:
	ruff format $(PYTHON_FILES)
	ruff check --select I --fix $(PYTHON_FILES)

spell_check:
	codespell --toml pyproject.toml

spell_fix:
	codespell --toml pyproject.toml -w

######################
# HELP
######################

help:
	@echo '----'
	@echo 'format                       - run code formatters'
	@echo 'lint                         - run linters'
	@echo 'test                         - run unit tests'
	@echo 'tests                        - run unit tests'
	@echo 'test TEST_FILE=<test_file>   - run all tests in file'
	@echo 'test_watch                   - run unit tests in watch mode'
</file>

<file path="pyproject.toml">
[project]
name = "react-agent"
version = "0.0.1"
description = "Starter template for making a custom Reasoning and Action agent (using tool calling) in LangGraph."
authors = [
    { name = "William Fu-Hinthorn", email = "13333726+hinthornw@users.noreply.github.com" },
]
readme = "README.md"
license = { text = "MIT" }
requires-python = ">=3.11,<4.0"
dependencies = [
    "langgraph>=0.2.6",
    "langchain-openai>=0.1.22",
    "langchain-anthropic>=0.1.23",
    "langchain>=0.2.14",
    "langchain-fireworks>=0.1.7",
    "python-dotenv>=1.0.1",
    "langchain-community>=0.2.17",
    "tavily-python>=0.4.0",
    "pandas",
    "firecrawl-py",
    "rich"
]


[project.optional-dependencies]
dev = ["mypy>=1.11.1", "ruff>=0.6.1"]

[build-system]
requires = ["setuptools>=73.0.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
packages = ["langgraph.templates.react_agent", "react_agent"]
[tool.setuptools.package-dir]
"langgraph.templates.react_agent" = "src/react_agent"
"react_agent" = "src/react_agent"


[tool.setuptools.package-data]
"*" = ["py.typed"]

[tool.ruff]
lint.select = [
    "E",    # pycodestyle
    "F",    # pyflakes
    "I",    # isort
    "D",    # pydocstyle
    "D401", # First line should be in imperative mood
    "T201",
    "UP",
]
lint.ignore = [
    "UP006",
    "UP007",
    # We actually do want to import from typing_extensions
    "UP035",
    # Relax the convention by _not_ requiring documentation for every function parameter.
    "D417",
    "E501",
]
[tool.ruff.lint.per-file-ignores]
"tests/*" = ["D", "UP"]
[tool.ruff.lint.pydocstyle]
convention = "google"

[dependency-groups]
dev = [
    "langgraph-cli[inmem]>=0.1.71",
]
</file>

<file path="README.md">
# LangGraph ReAct Agent Template

[![CI](https://github.com/langchain-ai/react-agent/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/langchain-ai/react-agent/actions/workflows/unit-tests.yml)
[![Integration Tests](https://github.com/langchain-ai/react-agent/actions/workflows/integration-tests.yml/badge.svg)](https://github.com/langchain-ai/react-agent/actions/workflows/integration-tests.yml)
[![Open in - LangGraph Studio](https://img.shields.io/badge/Open_in-LangGraph_Studio-00324d.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI4NS4zMzMiIGhlaWdodD0iODUuMzMzIiB2ZXJzaW9uPSIxLjAiIHZpZXdCb3g9IjAgMCA2NCA2NCI+PHBhdGggZD0iTTEzIDcuOGMtNi4zIDMuMS03LjEgNi4zLTYuOCAyNS43LjQgMjQuNi4zIDI0LjUgMjUuOSAyNC41QzU3LjUgNTggNTggNTcuNSA1OCAzMi4zIDU4IDcuMyA1Ni43IDYgMzIgNmMtMTIuOCAwLTE2LjEuMy0xOSAxLjhtMzcuNiAxNi42YzIuOCAyLjggMy40IDQuMiAzLjQgNy42cy0uNiA0LjgtMy40IDcuNkw0Ny4yIDQzSDE2LjhsLTMuNC0zLjRjLTQuOC00LjgtNC44LTEwLjQgMC0xNS4ybDMuNC0zLjRoMzAuNHoiLz48cGF0aCBkPSJNMTguOSAyNS42Yy0xLjEgMS4zLTEgMS43LjQgMi41LjkuNiAxLjcgMS44IDEuNyAyLjcgMCAxIC43IDIuOCAxLjYgNC4xIDEuNCAxLjkgMS40IDIuNS4zIDMuMi0xIC42LS42LjkgMS40LjkgMS41IDAgMi43LS41IDIuNy0xIDAtLjYgMS4xLS44IDIuNi0uNGwyLjYuNy0xLjgtMi45Yy01LjktOS4zLTkuNC0xMi4zLTExLjUtOS44TTM5IDI2YzAgMS4xLS45IDIuNS0yIDMuMi0yLjQgMS41LTIuNiAzLjQtLjUgNC4yLjguMyAyIDEuNyAyLjUgMy4xLjYgMS41IDEuNCAyLjMgMiAyIDEuNS0uOSAxLjItMy41LS40LTMuNS0yLjEgMC0yLjgtMi44LS44LTMuMyAxLjYtLjQgMS42LS41IDAtLjYtMS4xLS4xLTEuNS0uNi0xLjItMS42LjctMS43IDMuMy0yLjEgMy41LS41LjEuNS4yIDEuNi4zIDIuMiAwIC43LjkgMS40IDEuOSAxLjYgMi4xLjQgMi4zLTIuMy4yLTMuMi0uOC0uMy0yLTEuNy0yLjUtMy4xLTEuMS0zLTMtMy4zLTMtLjUiLz48L3N2Zz4=)](https://langgraph-studio.vercel.app/templates/open?githubUrl=https://github.com/langchain-ai/react-agent)

This template showcases a [ReAct agent](https://arxiv.org/abs/2210.03629) implemented using [LangGraph](https://github.com/langchain-ai/langgraph), designed for [LangGraph Studio](https://github.com/langchain-ai/langgraph-studio). ReAct agents are uncomplicated, prototypical agents that can be flexibly extended to many tools.

![Graph view in LangGraph studio UI](./static/studio_ui.png)

The core logic, defined in `src/react_agent/graph.py`, demonstrates a flexible ReAct agent that iteratively reasons about user queries and executes actions, showcasing the power of this approach for complex problem-solving tasks.

## What it does

The ReAct agent:

1. Takes a user **query** as input
2. Reasons about the query and decides on an action
3. Executes the chosen action using available tools
4. Observes the result of the action
5. Repeats steps 2-4 until it can provide a final answer

By default, it's set up with a basic set of tools, but can be easily extended with custom tools to suit various use cases.

## Getting Started

Assuming you have already [installed LangGraph Studio](https://github.com/langchain-ai/langgraph-studio?tab=readme-ov-file#download), to set up:

1. Create a `.env` file.

```bash
cp .env.example .env
```

2. Define required API keys in your `.env` file.

The primary [search tool](./src/react_agent/tools.py) [^1] used is [Tavily](https://tavily.com/). Create an API key [here](https://app.tavily.com/sign-in).

<!--
Setup instruction auto-generated by `langgraph template lock`. DO NOT EDIT MANUALLY.
-->

### Setup Model

The defaults values for `model` are shown below:

```yaml
model: anthropic/claude-3-5-sonnet-20240620
```

Follow the instructions below to get set up, or pick one of the additional options.

#### Anthropic

To use Anthropic's chat models:

1. Sign up for an [Anthropic API key](https://console.anthropic.com/) if you haven't already.
2. Once you have your API key, add it to your `.env` file:

```
ANTHROPIC_API_KEY=your-api-key
```
#### OpenAI

To use OpenAI's chat models:

1. Sign up for an [OpenAI API key](https://platform.openai.com/signup).
2. Once you have your API key, add it to your `.env` file:
```
OPENAI_API_KEY=your-api-key
```





<!--
End setup instructions
-->


3. Customize whatever you'd like in the code.
4. Open the folder LangGraph Studio!

## How to customize

1. **Add new tools**: Extend the agent's capabilities by adding new tools in [tools.py](./src/react_agent/tools.py). These can be any Python functions that perform specific tasks.
2. **Select a different model**: We default to Anthropic's Claude 3 Sonnet. You can select a compatible chat model using `provider/model-name` via configuration. Example: `openai/gpt-4-turbo-preview`.
3. **Customize the prompt**: We provide a default system prompt in [prompts.py](./src/react_agent/prompts.py). You can easily update this via configuration in the studio.

You can also quickly extend this template by:

- Modifying the agent's reasoning process in [graph.py](./src/react_agent/graph.py).
- Adjusting the ReAct loop or adding additional steps to the agent's decision-making process.

## Development

While iterating on your graph, you can edit past state and rerun your app from past states to debug specific nodes. Local changes will be automatically applied via hot reload. Try adding an interrupt before the agent calls tools, updating the default system message in `src/react_agent/configuration.py` to take on a persona, or adding additional nodes and edges!

Follow up requests will be appended to the same thread. You can create an entirely new thread, clearing previous history, using the `+` button in the top right.

You can find the latest (under construction) docs on [LangGraph](https://github.com/langchain-ai/langgraph) here, including examples and other references. Using those guides can help you pick the right patterns to adapt here for your use case.

LangGraph Studio also integrates with [LangSmith](https://smith.langchain.com/) for more in-depth tracing and collaboration with teammates.

[^1]: https://python.langchain.com/docs/concepts/#tools

<!--
Configuration auto-generated by `langgraph template lock`. DO NOT EDIT MANUALLY.
{
  "config_schemas": {
    "agent": {
      "type": "object",
      "properties": {
        "model": {
          "type": "string",
          "default": "anthropic/claude-3-5-sonnet-20240620",
          "description": "The name of the language model to use for the agent's main interactions. Should be in the form: provider/model-name.",
          "environment": [
            {
              "value": "anthropic/claude-1.2",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-2.0",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-2.1",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-3-5-sonnet-20240620",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-3-haiku-20240307",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-3-opus-20240229",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-3-sonnet-20240229",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "anthropic/claude-instant-1.2",
              "variables": "ANTHROPIC_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-0125",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-0301",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-0613",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-1106",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-16k",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-3.5-turbo-16k-0613",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-0125-preview",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-0314",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-0613",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-1106-preview",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-32k",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-32k-0314",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-32k-0613",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-turbo",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-turbo-preview",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4-vision-preview",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4o",
              "variables": "OPENAI_API_KEY"
            },
            {
              "value": "openai/gpt-4o-mini",
              "variables": "OPENAI_API_KEY"
            }
          ]
        }
      },
      "environment": [
        "TAVILY_API_KEY"
      ]
    }
  }
}
-->
</file>

<file path="repomix.config.json">
{
  "output": {
    "filePath": "repomix-output.xml",
    "style": "xml",
    "parsableStyle": false,
    "fileSummary": true,
    "directoryStructure": true,
    "removeComments": false,
    "removeEmptyLines": false,
    "compress": false,
    "topFilesLength": 5,
    "showLineNumbers": false,
    "copyToClipboard": false
  },
  "include": [],
  "ignore": {
    "useGitignore": true,
    "useDefaultPatterns": true,
    "customPatterns": []
  },
  "security": {
    "enableSecurityCheck": true
  },
  "tokenCount": {
    "encoding": "o200k_base"
  }
}
</file>

</files>
