
# Generated by Qodo Gen

# Dependencies:
# pip install pytest-mock
import pytest

class TestCodeUnderTest:

    # API requests to Jina services succeed and return expected responses
    @pytest.mark.asyncio
    async def test_search_api_success(self, mocker):
        # 1. Mock the _make_request_with_retry function to return a successful response
        mock_response = {"results": [{"title": "Test Result", "url": "https://example.com"}]}
        mock_request = mocker.patch("react_agent.tools.jina._make_request_with_retry", return_value=mock_response)
    
        # 2. Mock the _get_jina_api_key function to return a test API key
        mocker.patch("react_agent.tools.jina._get_jina_api_key", return_value="test_api_key")
    
        # 3. Call the search function with test parameters
        result = await search(query="test query", options="Default")
    
        # 4. Verify the function called _make_request_with_retry with correct parameters
        mock_request.assert_called_once()
        call_args = mock_request.call_args[1]
    
        # 5. Check that the method and URL are correct
        assert call_args["method"] == "POST"
        assert call_args["url"] == "https://s.jina.ai/"
    
        # 6. Verify the headers contain the API key
        assert call_args["headers"]["Authorization"] == "Bearer test_api_key"
    
        # 7. Check that the JSON data contains the query
        assert call_args["json_data"]["q"] == "test query"
    
        # 8. Verify the function returns the expected response
        assert result == mock_response

    # Cache mechanism correctly stores and retrieves results using create_checkpoint and load_checkpoint
    @pytest.mark.asyncio
    async def test_cache_mechanism(self, mocker):
        # 1. Mock the load_checkpoint function to return None first (cache miss), then a cached result
        mock_load = mocker.patch("react_agent.tools.jina.load_checkpoint", side_effect=[None, {"cached": "result"}])
    
        # 2. Mock the create_checkpoint function
        mock_create = mocker.patch("react_agent.tools.jina.create_checkpoint")
    
        # 3. Mock the _make_request_with_retry function to return a successful response
        mock_response = {"results": [{"title": "Test Result"}]}
        mocker.patch("react_agent.tools.jina._make_request_with_retry", return_value=mock_response)
    
        # 4. Mock the _get_jina_api_key function
        mocker.patch("react_agent.tools.jina._get_jina_api_key", return_value="test_api_key")
    
        # 5. Create a test state with cache_results=True
        test_state = {"cache_results": True}
    
        # 6. First call should miss cache and make API request
        result1 = await reader(url="https://valid-url.com", state=test_state)
    
        # 7. Verify load_checkpoint was called
        mock_load.assert_called_once()
    
        # 8. Verify create_checkpoint was called with the response
        mock_create.assert_called_once()
    
        # 9. Verify the result is from the API
        assert result1 == mock_response
    
        # 10. Second call should hit cache
        result2 = await reader(url="https://valid-url.com", state=test_state)
    
        # 11. Verify load_checkpoint was called again
        assert mock_load.call_count == 2
    
        # 12. Verify the result is from cache
        assert result2 == {"cached": "result"}

    # Tool functions properly handle valid inputs and return structured responses
    @pytest.mark.asyncio
    async def test_embeddings_valid_input(self, mocker):
        # 1. Mock the _make_request_with_retry function to return a successful response
        mock_response = {
            "data": [
                {"embedding": [0.1, 0.2, 0.3], "index": 0},
                {"embedding": [0.4, 0.5, 0.6], "index": 1}
            ],
            "model": "jina-embeddings-v3",
            "usage": {"prompt_tokens": 10, "total_tokens": 10}
        }
        mock_request = mocker.patch("react_agent.tools.jina._make_request_with_retry", return_value=mock_response)
    
        # 2. Mock the _get_jina_api_key function
        mocker.patch("react_agent.tools.jina._get_jina_api_key", return_value="test_api_key")
    
        # 3. Mock the load_checkpoint function to return None (cache miss)
        mocker.patch("react_agent.tools.jina.load_checkpoint", return_value=None)
    
        # 4. Mock the create_checkpoint function
        mocker.patch("react_agent.tools.jina.create_checkpoint")
    
        # 5. Call the embeddings function with valid inputs
        result = await embeddings(
            model="jina-embeddings-v3",
            input_texts=["Hello world", "Test text"],
            normalized=True
        )
    
        # 6. Verify the function called _make_request_with_retry with correct parameters
        mock_request.assert_called_once()
        call_args = mock_request.call_args[1]
    
        # 7. Check that the method and URL are correct
        assert call_args["method"] == "POST"
        assert call_args["url"] == "https://api.jina.ai/v1/embeddings"
    
        # 8. Verify the JSON data contains the correct model and inputs
        assert call_args["json_data"]["model"] == "jina-embeddings-v3"
        assert call_args["json_data"]["input"] == ["Hello world", "Test text"]
        assert call_args["json_data"]["normalized"] is True
    
        # 9. Verify the function returns the expected structured response
        assert result == mock_response
        assert "data" in result
        assert len(result["data"]) == 2
        assert "embedding" in result["data"][0]

    # HTTP requests fail and trigger retry mechanism with exponential backoff
    @pytest.mark.asyncio
    async def test_retry_mechanism(self, mocker):
        # 1. Mock asyncio.sleep to avoid actual waiting during tests
        mock_sleep = mocker.patch("asyncio.sleep")
    
        # 2. Create a mock ClientError that will be raised during requests
        mock_error = aiohttp.ClientError("Test connection error")
    
        # 3. Create a mock ClientSession that raises an error on first two calls, then succeeds
        mock_session = mocker.AsyncMock()
        mock_response = mocker.AsyncMock()
        mock_response.status = 200
        mock_response.json.return_value = {"success": True}
        mock_response.text.return_value = '{"success": true}'
    
        # 4. Configure the session's request method to fail twice then succeed
        session_instance = mock_session.return_value
        session_instance.__aenter__.return_value = session_instance
        session_instance.request.side_effect = [
            mock_error,  # First attempt fails
            mock_error,  # Second attempt fails
            mock_response  # Third attempt succeeds
        ]
    
        # 5. Mock aiohttp.ClientSession to use our configured mock
        mocker.patch("aiohttp.ClientSession", return_value=mock_session.return_value)
    
        # 6. Create a retry config with 3 retries
        retry_config = RetryConfig(max_retries=3, base_delay=0.1, max_delay=1.0)
    
        # 7. Call _make_request_with_retry directly to test the retry mechanism
        result = await _make_request_with_retry(
            method="GET",
            url="https://test-url.com",
            headers={"Authorization": "Bearer test"},
            retry_config=retry_config
        )
    
        # 8. Verify that request was called 3 times (2 failures + 1 success)
        assert session_instance.request.call_count == 3
    
        # 9. Verify that sleep was called twice (after each failure)
        assert mock_sleep.call_count == 2
    
        # 10. Verify that the delays follow exponential backoff pattern
        first_delay = mock_sleep.call_args_list[0][0][0]
        second_delay = mock_sleep.call_args_list[1][0][0]
        assert second_delay > first_delay  # Second delay should be longer (exponential)
    
        # 11. Verify the successful result was returned
        assert result == {"success": True}

    # API key is missing from all possible sources (config, state, environment)
    @pytest.mark.asyncio
    async def test_missing_api_key(self, mocker):
        # 1. Mock os.environ.get to return None for JINA_API_KEY
        mocker.patch("os.environ.get", return_value=None)
    
        # 2. Create an empty configuration
        mock_config = mocker.Mock()
        mock_config.jina_api_key = None
    
        # 3. Mock Configuration.from_runnable_config to return our empty config
        mocker.patch("react_agent.configuration.Configuration.from_runnable_config", return_value=mock_config)
    
        # 4. Create an empty state with no API key
        empty_state = {}
    
        # 5. Call the search function which should raise an error due to missing API key
        with pytest.raises(ValueError) as excinfo:
            await search(query="test query", state=empty_state)
    
        # 6. Verify the error message mentions the missing API key
        assert "JINA_API_KEY not found" in str(excinfo.value)
    
        # 7. Try with a different tool to ensure consistent behavior
        with pytest.raises(ValueError) as excinfo:
            await reader(url="https://example.com", state=empty_state)
    
        # 8. Verify the error message is consistent
        assert "JINA_API_KEY not found" in str(excinfo.value)
    
        # 9. Try with a None state to test that code path
        with pytest.raises(ValueError) as excinfo:
            await embeddings(model="jina-embeddings-v3", input_texts=["test"], state=None)
    
        # 10. Verify the error message is consistent
        assert "JINA_API_KEY not found" in str(excinfo.value)

    # Invalid URLs are provided to reader or other tools requiring URLs
    @pytest.mark.asyncio
    async def test_invalid_url_handling(self, mocker):
        # 1. Mock the is_valid_url function to properly validate URLs
        mock_is_valid = mocker.patch("react_agent.tools.jina.is_valid_url")
        mock_is_valid.side_effect = lambda url: url.startswith("https://valid")
    
        # 2. Mock the _get_jina_api_key function to return a test API key
        mocker.patch("react_agent.tools.jina._get_jina_api_key", return_value="test_api_key")
    
        # 3. Test with an invalid URL format
        with pytest.raises(ToolException) as excinfo:
            await reader(url="not-a-url")
    
        # 4. Verify the error message mentions invalid URL
        assert "Invalid" in str(excinfo.value)
    
        # 5. Test with a fake example URL that should be rejected
        mock_is_valid.return_value = False
        with pytest.raises(ToolException) as excinfo:
            await reader(url="https://example.com")
    
        # 6. Verify the error message mentions invalid URL
        assert "Invalid" in str(excinfo.value)
    
        # 7. Test with a URL containing template placeholders
        with pytest.raises(ToolException) as excinfo:
            await reader(url="https://{placeholder}.com")
    
        # 8. Verify the error message mentions invalid URL
        assert "Invalid" in str(excinfo.value)
    
        # 9. Mock _make_request_with_retry to verify it's not called with invalid URLs
        mock_request = mocker.patch("react_agent.tools.jina._make_request_with_retry")
    
        # 10. Try with an invalid URL and catch the exception
        try:
            await reader(url="invalid-url")
        except:
            pass
    
        # 11. Verify the request was never made
        mock_request.assert_not_called()
    
        # 12. Now test with a valid URL to ensure it passes validation
        mock_is_valid.return_value = True
        mock_request.return_value = {"content": "test"}
    
        # 13. Call with valid URL
        result = await reader(url="https://valid-url.com")
    
        # 14. Verify the request was made
        mock_request.assert_called_once()

    # create_jina_toolnode successfully creates a ToolNode with specified tools
    @pytest.mark.asyncio
    async def test_create_jina_toolnode_with_selected_tools(self, mocker):
        # 1. Mock the ToolNode class to verify it is instantiated correctly
        mock_toolnode = mocker.patch("react_agent.tools.jina.ToolNode")
    
        # 2. Define the tools to include in the ToolNode
        include_tools = ["search", "reader"]
    
        # 3. Call the create_jina_toolnode function with the selected tools
        create_jina_toolnode(include_tools=include_tools)
    
        # 4. Verify that ToolNode was called once with the correct tools
        mock_toolnode.assert_called_once()
    
        # 5. Extract the tools passed to ToolNode
        tools_passed = mock_toolnode.call_args[0][0]
    
        # 6. Check that the correct tools are included in the ToolNode
        assert len(tools_passed) == 2
        assert search in tools_passed
        assert reader in tools_passed

    # Tool functions correctly handle and transform custom headers for API requests
    @pytest.mark.asyncio
    async def test_reader_api_custom_headers(self, mocker):
        # 1. Mock the _make_request_with_retry function to return a successful response
        mock_response = {"content": "Sample content"}
        mock_request = mocker.patch("react_agent.tools.jina._make_request_with_retry", return_value=mock_response)

        # 2. Mock the _get_jina_api_key function to return a test API key
        mocker.patch("react_agent.tools.jina._get_jina_api_key", return_value="test_api_key")

        # 3. Call the reader function with test parameters and custom headers
        result = await reader(
            url="https://example.com",
            options="Markdown",
            with_links_summary=True,
            with_images_summary=False,
            return_format="html"
        )

        # 4. Verify the function called _make_request_with_retry with correct parameters
        mock_request.assert_called_once()
        call_args = mock_request.call_args[1]

        # 5. Check that the method and URL are correct
        assert call_args["method"] == "POST"
        assert call_args["url"] == "https://r.jina.ai/"

        # 6. Verify the headers contain the API key and custom headers
        assert call_args["headers"]["Authorization"] == "Bearer test_api_key"
        assert call_args["headers"]["x_with_links_summary"] == "true"
        assert call_args["headers"]["x_with_images_summary"] == "false"
        assert call_args["headers"]["x_return_format"] == "html"

        # 7. Check that the JSON data contains the URL and options
        assert call_args["json_data"]["url"] == "https://example.com"
        assert call_args["json_data"]["options"] == "Markdown"

        # 8. Verify the function returns the expected response
        assert result == mock_response